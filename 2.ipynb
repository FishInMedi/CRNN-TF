{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This file corresponses to the Figure 5. (How the combination of vertices and directions affect the classification results) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 1360, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 1360, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 1360, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 48, 340, 64)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 48, 340, 128) 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 48, 340, 128) 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 340, 128) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 85, 128)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 24, 85, 128)  147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 85, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 85, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 22, 128)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 12, 22, 128)  147584      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12, 22, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 22, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 6, 6, 128)    0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 6, 6, 128)    0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 6, 128)    0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 6, 128)    0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 6, 768)       0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 6, 768)       0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 6, 768)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 6, 768)       0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 6, 768)       0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 6, 768)       0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 6, 768)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 6, 768)       0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 32)           76896       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 32)           76896       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, 32)           76896       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     (None, 32)           76896       reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_5 (GRU)                     (None, 32)           76896       reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_6 (GRU)                     (None, 32)           76896       reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_7 (GRU)                     (None, 32)           76896       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_8 (GRU)                     (None, 32)           76896       reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           gru_1[0][0]                      \n",
      "                                                                 gru_2[0][0]                      \n",
      "                                                                 gru_3[0][0]                      \n",
      "                                                                 gru_4[0][0]                      \n",
      "                                                                 gru_5[0][0]                      \n",
      "                                                                 gru_6[0][0]                      \n",
      "                                                                 gru_7[0][0]                      \n",
      "                                                                 gru_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           3250        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,006,322\n",
      "Trainable params: 1,005,426\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "15244/15244 [==============================] - 311s 20ms/step - loss: 0.2096\n",
      "AUCs: 0.8153448406344347\n",
      "Epoch 2/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1727\n",
      "AUCs: 0.8163986202165369\n",
      "Epoch 3/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1623\n",
      "AUCs: 0.8495643610840912\n",
      "Epoch 4/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1560\n",
      "AUCs: 0.855120846481981\n",
      "Epoch 5/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1514\n",
      "AUCs: 0.8774353984340212\n",
      "Epoch 6/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1486\n",
      "AUCs: 0.8624555416494784\n",
      "Epoch 7/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1458\n",
      "AUCs: 0.871718822474174\n",
      "Epoch 8/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1440\n",
      "AUCs: 0.8761033036068073\n",
      "Epoch 9/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1429\n",
      "AUCs: 0.8834350687137237\n",
      "Epoch 10/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1406\n",
      "AUCs: 0.8935438187700712\n",
      "Epoch 11/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1395\n",
      "AUCs: 0.8969129500784454\n",
      "Epoch 12/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1379\n",
      "AUCs: 0.8980725695525479\n",
      "Epoch 13/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1368\n",
      "AUCs: 0.8932702169322675\n",
      "Epoch 14/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1354\n",
      "AUCs: 0.8898049761319596\n",
      "Epoch 15/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1346\n",
      "AUCs: 0.9052775750950278\n",
      "Epoch 16/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1334\n",
      "AUCs: 0.9001592814227155\n",
      "Epoch 17/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1320\n",
      "AUCs: 0.8939840125224388\n",
      "Epoch 18/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1306\n",
      "AUCs: 0.899849642114669\n",
      "Epoch 19/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1297\n",
      "AUCs: 0.8900591423189662\n",
      "Epoch 20/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1284\n",
      "AUCs: 0.9056792256299852\n",
      "Epoch 21/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1273\n",
      "AUCs: 0.9038753750314567\n",
      "Epoch 22/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1259\n",
      "AUCs: 0.8848757740311123\n",
      "Epoch 23/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1248\n",
      "AUCs: 0.905082797957805\n",
      "Epoch 24/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1234\n",
      "AUCs: 0.9068474552921113\n",
      "Epoch 25/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1224\n",
      "AUCs: 0.8981803640947242\n",
      "Epoch 26/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1211\n",
      "AUCs: 0.9021451555580395\n",
      "Epoch 27/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1192\n",
      "AUCs: 0.9008026825499426\n",
      "Epoch 28/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1177\n",
      "AUCs: 0.9013462153317235\n",
      "Epoch 29/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1163\n",
      "AUCs: 0.902877644655229\n",
      "Epoch 30/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1149\n",
      "AUCs: 0.9004669182704522\n",
      "Epoch 31/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1132\n",
      "AUCs: 0.9028838906033038\n",
      "Epoch 32/50\n",
      "15244/15244 [==============================] - 296s 19ms/step - loss: 0.1114\n",
      "AUCs: 0.9057977047594309\n",
      "Epoch 33/50\n",
      "15244/15244 [==============================] - 299s 20ms/step - loss: 0.1101\n",
      "AUCs: 0.8983605933686515\n",
      "Epoch 34/50\n",
      "15244/15244 [==============================] - 302s 20ms/step - loss: 0.1086\n",
      "AUCs: 0.897281023135569\n",
      "Epoch 35/50\n",
      "15244/15244 [==============================] - 299s 20ms/step - loss: 0.1060\n",
      "AUCs: 0.9022217430954202\n",
      "Epoch 36/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1051\n",
      "AUCs: 0.8988133774769291\n",
      "Epoch 37/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.1023\n",
      "AUCs: 0.9006410485086032\n",
      "Epoch 38/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.1005\n",
      "AUCs: 0.9019276400602065\n",
      "Epoch 39/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.0991\n",
      "AUCs: 0.8970880720414471\n",
      "Epoch 40/50\n",
      "15244/15244 [==============================] - 302s 20ms/step - loss: 0.0969\n",
      "AUCs: 0.8978631345368168\n",
      "Epoch 41/50\n",
      "15244/15244 [==============================] - 299s 20ms/step - loss: 0.0952\n",
      "AUCs: 0.8985302813168397\n",
      "Epoch 42/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.0931\n",
      "AUCs: 0.8991990639300096\n",
      "Epoch 43/50\n",
      "15244/15244 [==============================] - 300s 20ms/step - loss: 0.0913\n",
      "AUCs: 0.8992635511573386\n",
      "Epoch 44/50\n",
      "15244/15244 [==============================] - 299s 20ms/step - loss: 0.0896\n",
      "AUCs: 0.8970357525123331\n",
      "Epoch 45/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.0879\n",
      "AUCs: 0.8979491374024822\n",
      "Epoch 46/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.0859\n",
      "AUCs: 0.8976079182352974\n",
      "Epoch 47/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.0847\n",
      "AUCs: 0.8947373214836777\n",
      "Epoch 48/50\n",
      "15244/15244 [==============================] - 302s 20ms/step - loss: 0.0831\n",
      "AUCs: 0.8958932726631785\n",
      "Epoch 49/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.0811\n",
      "AUCs: 0.8933164406141123\n",
      "Epoch 50/50\n",
      "15244/15244 [==============================] - 301s 20ms/step - loss: 0.0791\n",
      "AUCs: 0.8949640654317925\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 50\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru1_in = Reshape((6, 128*6))(pool4)\n",
    "gru1 = GRU(32)(gru1_in)\n",
    "\n",
    "gru2_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(pool4)\n",
    "gru2_in = Reshape((6, 128*6))(gru2_in_perm)\n",
    "gru2 = GRU(32)(gru2_in)\n",
    "\n",
    "gru3_in_perm = Lambda(K.reverse,arguments={'axes':2})(pool4)\n",
    "gru3_in = Reshape((6, 128*6))(gru3_in_perm)\n",
    "gru3 = GRU(32)(gru3_in)\n",
    "\n",
    "gru4_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(gru3_in_perm)\n",
    "gru4_in = Reshape((6, 128*6))(gru4_in_perm)\n",
    "gru4 = GRU(32)(gru4_in)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1})(pool4)\n",
    "gru5_in = Reshape((6, 128*6))(gru5_in_perm)\n",
    "gru5 = GRU(32)(gru5_in)\n",
    "\n",
    "gru6_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(gru5_in_perm)\n",
    "gru6_in = Reshape((6, 128*6))(gru6_in_perm)\n",
    "gru6 = GRU(32)(gru6_in)\n",
    "\n",
    "gru7_in_perm = Lambda(K.reverse,arguments={'axes':2})(gru5_in_perm)\n",
    "gru7_in = Reshape((6, 128*6))(gru7_in_perm)\n",
    "gru7 = GRU(32)(gru7_in)\n",
    "\n",
    "gru8_in_perm = Lambda(K.reverse,arguments={'axes':1})(gru6_in_perm)\n",
    "gru8_in = Reshape((6, 128*6))(gru8_in_perm)\n",
    "gru8 = GRU(32)(gru8_in)\n",
    "\n",
    "gru = Concatenate()([gru1,gru2,gru3,gru4,gru5,gru6,gru7,gru8])\n",
    "gru_dropout = Dropout(0.5)(gru)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc_test = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc_test)\n",
    "        print(\"AUCs:\",auc_test)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn_losses(test).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 1360, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 1360, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1360, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 1360, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 340, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 340, 128)      73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 340, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 340, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 85, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 85, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 22, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 22, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 6, 768)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                76896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3250      \n",
      "=================================================================\n",
      "Total params: 453,714\n",
      "Trainable params: 452,818\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/35\n",
      "15244/15244 [==============================] - 255s 17ms/step - loss: 0.3142\n",
      "AUCs: 0.6040368963453885\n",
      "Epoch 2/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2295\n",
      "AUCs: 0.6894649455072294\n",
      "Epoch 3/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2161\n",
      "AUCs: 0.7035120950987286\n",
      "Epoch 4/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2137\n",
      "AUCs: 0.7063103080636506\n",
      "Epoch 5/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2125\n",
      "AUCs: 0.7195446752115301\n",
      "Epoch 6/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2105\n",
      "AUCs: 0.7112895272635953\n",
      "Epoch 7/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2102\n",
      "AUCs: 0.7307982728806747\n",
      "Epoch 8/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2104\n",
      "AUCs: 0.7375020215804439\n",
      "Epoch 9/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2094\n",
      "AUCs: 0.7514502890570078\n",
      "Epoch 10/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2088\n",
      "AUCs: 0.7698878637167436\n",
      "Epoch 11/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2082\n",
      "AUCs: 0.7660898620086748\n",
      "Epoch 12/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2084\n",
      "AUCs: 0.7626229335674498\n",
      "Epoch 13/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2074\n",
      "AUCs: 0.7368818139624739\n",
      "Epoch 14/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2069\n",
      "AUCs: 0.7846390687095479\n",
      "Epoch 15/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2052\n",
      "AUCs: 0.7871301357741582\n",
      "Epoch 16/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2054\n",
      "AUCs: 0.7924395951914184\n",
      "Epoch 17/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2050\n",
      "AUCs: 0.7923572456301669\n",
      "Epoch 18/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2041\n",
      "AUCs: 0.7731646780633364\n",
      "Epoch 19/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2041\n",
      "AUCs: 0.7981863211911245\n",
      "Epoch 20/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2024\n",
      "AUCs: 0.7938345357805844\n",
      "Epoch 21/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2024\n",
      "AUCs: 0.7937189963966965\n",
      "Epoch 22/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2019\n",
      "AUCs: 0.7082345113727995\n",
      "Epoch 23/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2011\n",
      "AUCs: 0.760385304584472\n",
      "Epoch 24/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2007\n",
      "AUCs: 0.7941736783956539\n",
      "Epoch 25/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2005\n",
      "AUCs: 0.7727137706713685\n",
      "Epoch 26/35\n",
      "15244/15244 [==============================] - 251s 16ms/step - loss: 0.2000\n",
      "AUCs: 0.7795773339012662\n",
      "Epoch 27/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1997\n",
      "AUCs: 0.787890034966926\n",
      "Epoch 28/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1990\n",
      "AUCs: 0.7940945450593069\n",
      "Epoch 29/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1991\n",
      "AUCs: 0.7684004534110145\n",
      "Epoch 30/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1985\n",
      "AUCs: 0.7816585713919967\n",
      "Epoch 31/35\n",
      "15244/15244 [==============================] - 251s 16ms/step - loss: 0.1979\n",
      "AUCs: 0.7926330753684876\n",
      "Epoch 32/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1973\n",
      "AUCs: 0.782257398324597\n",
      "Epoch 33/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1967\n",
      "AUCs: 0.7924742726614658\n",
      "Epoch 34/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1963\n",
      "AUCs: 0.7892151669057215\n",
      "Epoch 35/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1954\n",
      "AUCs: 0.7896561227411556\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru1_in = Reshape((6, 128*6))(pool4)\n",
    "gru1 = GRU(32)(gru1_in)\n",
    "\n",
    "gru_dropout = Dropout(0.1)(gru1)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc_test = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc_test)\n",
    "        print(\"AUCs:\",auc_test)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn1_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn1_losses(test).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 1360, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 1360, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1360, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 1360, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 340, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 340, 128)      73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 340, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 340, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 85, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 85, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 22, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 22, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 6, 768)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                76896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3250      \n",
      "=================================================================\n",
      "Total params: 453,714\n",
      "Trainable params: 452,818\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 15244 samples, validate on 1529 samples\n",
      "Epoch 1/50\n",
      "15244/15244 [==============================] - 272s 18ms/step - loss: 0.3065 - val_loss: 0.2604\n",
      "AUCs: [0.5442333448076883, 0.5679422882157847, 0.564483096460008]\n",
      "Epoch 2/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.2283 - val_loss: 0.2214\n",
      "AUCs: [0.6715985104242961, 0.6584978243752455, 0.662035624206942]\n",
      "Epoch 3/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.2184 - val_loss: 0.2121\n",
      "AUCs: [0.6858158356420649, 0.673117098466572, 0.6759156338778521]\n",
      "Epoch 4/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2154 - val_loss: 0.2220\n",
      "AUCs: [0.6893604034910635, 0.6788867777609637, 0.6692514342085873]\n",
      "Epoch 5/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2133 - val_loss: 0.2064\n",
      "AUCs: [0.7081717964748467, 0.6900099692281628, 0.6874155951614861]\n",
      "Epoch 6/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2130 - val_loss: 0.2011\n",
      "AUCs: [0.7282976469824096, 0.7259052584692038, 0.710293455172046]\n",
      "Epoch 7/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2113 - val_loss: 0.1989\n",
      "AUCs: [0.7377078558525055, 0.7290339352095746, 0.7233410102945959]\n",
      "Epoch 8/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2106 - val_loss: 0.2110\n",
      "AUCs: [0.7055290385753332, 0.6875984342132838, 0.6934616842444364]\n",
      "Epoch 9/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2103 - val_loss: 0.2062\n",
      "AUCs: [0.7428288647120003, 0.7222698066005877, 0.7255755308942501]\n",
      "Epoch 10/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2094 - val_loss: 0.1993\n",
      "AUCs: [0.7330150916168583, 0.735565777967032, 0.7149267898439388]\n",
      "Epoch 11/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2095 - val_loss: 0.1999\n",
      "AUCs: [0.7419208286606782, 0.7388163028850628, 0.724514336222053]\n",
      "Epoch 12/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2093 - val_loss: 0.2099\n",
      "AUCs: [0.7109029792482419, 0.7068610881000943, 0.7005122261795242]\n",
      "Epoch 13/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2088 - val_loss: 0.2024\n",
      "AUCs: [0.7453426798600559, 0.735551698766287, 0.7326325661706741]\n",
      "Epoch 14/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2083 - val_loss: 0.2192\n",
      "AUCs: [0.7006342323073705, 0.6972709400607556, 0.6810249537846699]\n",
      "Epoch 15/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2083 - val_loss: 0.1962\n",
      "AUCs: [0.7668901113114852, 0.77327836258324, 0.7540502988681156]\n",
      "Epoch 16/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2081 - val_loss: 0.2007\n",
      "AUCs: [0.7608069389909516, 0.7689957464393848, 0.7465035102019419]\n",
      "Epoch 17/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2081 - val_loss: 0.1932\n",
      "AUCs: [0.7832232699727332, 0.7908463867464559, 0.7697255309957447]\n",
      "Epoch 18/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2074 - val_loss: 0.1925\n",
      "AUCs: [0.7807488905701117, 0.7730910879934387, 0.7689514569121504]\n",
      "Epoch 19/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2076 - val_loss: 0.1917\n",
      "AUCs: [0.7887473041584042, 0.789635041028677, 0.777119870389233]\n",
      "Epoch 20/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2074 - val_loss: 0.1966\n",
      "AUCs: [0.7757387126602268, 0.7803962823836271, 0.7569065244581337]\n",
      "Epoch 21/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2058 - val_loss: 0.1951\n",
      "AUCs: [0.7756776791995551, 0.7767062996545507, 0.7592285937861418]\n",
      "Epoch 22/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2063 - val_loss: 0.1932\n",
      "AUCs: [0.7839088354275687, 0.7866417130519201, 0.771577463181402]\n",
      "Epoch 23/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2061 - val_loss: 0.1921\n",
      "AUCs: [0.787800087838666, 0.7918162946383169, 0.771427606267494]\n",
      "Epoch 24/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2060 - val_loss: 0.1920\n",
      "AUCs: [0.7973035157865134, 0.8038691302761835, 0.7838691594148627]\n",
      "Epoch 25/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2062 - val_loss: 0.2136\n",
      "AUCs: [0.729433972935756, 0.7268205870435342, 0.7130697695842152]\n",
      "Epoch 26/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2047 - val_loss: 0.1893\n",
      "AUCs: [0.7899312017422113, 0.7865705903768585, 0.7763807074771409]\n",
      "Epoch 27/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2050 - val_loss: 0.1907\n",
      "AUCs: [0.7969763468191674, 0.7901101620209192, 0.7824427913000176]\n",
      "Epoch 28/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2050 - val_loss: 0.1928\n",
      "AUCs: [0.7778506235080136, 0.7707604013449799, 0.766483733725483]\n",
      "Epoch 29/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2047 - val_loss: 0.1887\n",
      "AUCs: [0.8049410513351621, 0.8065065811952455, 0.7879893162199408]\n",
      "Epoch 30/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2043 - val_loss: 0.1906\n",
      "AUCs: [0.8036980257363581, 0.8122939734130351, 0.7911422708726498]\n",
      "Epoch 31/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2047 - val_loss: 0.1884\n",
      "AUCs: [0.806518113872672, 0.806362890211832, 0.7920644087613564]\n",
      "Epoch 32/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2043 - val_loss: 0.1892\n",
      "AUCs: [0.8003905507481004, 0.8046508489429682, 0.7857491535309542]\n",
      "Epoch 33/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.2037 - val_loss: 0.1873\n",
      "AUCs: [0.8117374424568744, 0.8122217669764208, 0.7952426910838798]\n",
      "Epoch 34/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2037 - val_loss: 0.1881\n",
      "AUCs: [0.8083398977054663, 0.8089861341278061, 0.7942628825243697]\n",
      "Epoch 35/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2031 - val_loss: 0.1921\n",
      "AUCs: [0.7993330035118178, 0.8018010397134943, 0.7823226764424528]\n",
      "Epoch 36/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2022 - val_loss: 0.1854\n",
      "AUCs: [0.81769113836301, 0.8158472127301354, 0.7968274099507745]\n",
      "Epoch 37/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.2019 - val_loss: 0.1887\n",
      "AUCs: [0.8041525868974548, 0.8045722222604482, 0.7822666014843648]\n",
      "Epoch 38/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2031 - val_loss: 0.1869\n",
      "AUCs: [0.8151734425217374, 0.8128828886823226, 0.7988103903658059]\n",
      "Epoch 39/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.2019 - val_loss: 0.1852\n",
      "AUCs: [0.8166008832918391, 0.8133020474569612, 0.8000762668709249]\n",
      "Epoch 40/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.2010 - val_loss: 0.1867\n",
      "AUCs: [0.8122243256974423, 0.8110258823370864, 0.7920984017406034]\n",
      "Epoch 41/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2008 - val_loss: 0.1870\n",
      "AUCs: [0.8104178313175042, 0.8088976548516841, 0.7895452179150633]\n",
      "Epoch 42/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2005 - val_loss: 0.1979\n",
      "AUCs: [0.7980469424191317, 0.7989297528942704, 0.7836816859606164]\n",
      "Epoch 43/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2001 - val_loss: 0.1885\n",
      "AUCs: [0.7993157216386028, 0.7957327448228781, 0.7847537276769436]\n",
      "Epoch 44/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1999 - val_loss: 0.1873\n",
      "AUCs: [0.8194161985015271, 0.8151244768205288, 0.8015657054207359]\n",
      "Epoch 45/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1996 - val_loss: 0.1938\n",
      "AUCs: [0.8104548406418772, 0.8136066894735342, 0.7956528654199773]\n",
      "Epoch 46/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1985 - val_loss: 0.1922\n",
      "AUCs: [0.8049658751600439, 0.7980123122288674, 0.789358335286792]\n",
      "Epoch 47/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1986 - val_loss: 0.1913\n",
      "AUCs: [0.8183492061247076, 0.8134823995486539, 0.7962163180341071]\n",
      "Epoch 48/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1977 - val_loss: 0.1964\n",
      "AUCs: [0.7721050863715476, 0.7727764570357452, 0.7584175889178073]\n",
      "Epoch 49/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1974 - val_loss: 0.1912\n",
      "AUCs: [0.796539988927515, 0.7914568285740238, 0.780138404068007]\n",
      "Epoch 50/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1976 - val_loss: 0.1895\n",
      "AUCs: [0.8068562594780773, 0.8052072547231152, 0.7901511917495838]\n",
      "[[0.5442333448076883, 0.5679422882157847, 0.564483096460008], [0.6715985104242961, 0.6584978243752455, 0.662035624206942], [0.6858158356420649, 0.673117098466572, 0.6759156338778521], [0.6893604034910635, 0.6788867777609637, 0.6692514342085873], [0.7081717964748467, 0.6900099692281628, 0.6874155951614861], [0.7282976469824096, 0.7259052584692038, 0.710293455172046], [0.7377078558525055, 0.7290339352095746, 0.7233410102945959], [0.7055290385753332, 0.6875984342132838, 0.6934616842444364], [0.7428288647120003, 0.7222698066005877, 0.7255755308942501], [0.7330150916168583, 0.735565777967032, 0.7149267898439388], [0.7419208286606782, 0.7388163028850628, 0.724514336222053], [0.7109029792482419, 0.7068610881000943, 0.7005122261795242], [0.7453426798600559, 0.735551698766287, 0.7326325661706741], [0.7006342323073705, 0.6972709400607556, 0.6810249537846699], [0.7668901113114852, 0.77327836258324, 0.7540502988681156], [0.7608069389909516, 0.7689957464393848, 0.7465035102019419], [0.7832232699727332, 0.7908463867464559, 0.7697255309957447], [0.7807488905701117, 0.7730910879934387, 0.7689514569121504], [0.7887473041584042, 0.789635041028677, 0.777119870389233], [0.7757387126602268, 0.7803962823836271, 0.7569065244581337], [0.7756776791995551, 0.7767062996545507, 0.7592285937861418], [0.7839088354275687, 0.7866417130519201, 0.771577463181402], [0.787800087838666, 0.7918162946383169, 0.771427606267494], [0.7973035157865134, 0.8038691302761835, 0.7838691594148627], [0.729433972935756, 0.7268205870435342, 0.7130697695842152], [0.7899312017422113, 0.7865705903768585, 0.7763807074771409], [0.7969763468191674, 0.7901101620209192, 0.7824427913000176], [0.7778506235080136, 0.7707604013449799, 0.766483733725483], [0.8049410513351621, 0.8065065811952455, 0.7879893162199408], [0.8036980257363581, 0.8122939734130351, 0.7911422708726498], [0.806518113872672, 0.806362890211832, 0.7920644087613564], [0.8003905507481004, 0.8046508489429682, 0.7857491535309542], [0.8117374424568744, 0.8122217669764208, 0.7952426910838798], [0.8083398977054663, 0.8089861341278061, 0.7942628825243697], [0.7993330035118178, 0.8018010397134943, 0.7823226764424528], [0.81769113836301, 0.8158472127301354, 0.7968274099507745], [0.8041525868974548, 0.8045722222604482, 0.7822666014843648], [0.8151734425217374, 0.8128828886823226, 0.7988103903658059], [0.8166008832918391, 0.8133020474569612, 0.8000762668709249], [0.8122243256974423, 0.8110258823370864, 0.7920984017406034], [0.8104178313175042, 0.8088976548516841, 0.7895452179150633], [0.7980469424191317, 0.7989297528942704, 0.7836816859606164], [0.7993157216386028, 0.7957327448228781, 0.7847537276769436], [0.8194161985015271, 0.8151244768205288, 0.8015657054207359], [0.8104548406418772, 0.8136066894735342, 0.7956528654199773], [0.8049658751600439, 0.7980123122288674, 0.789358335286792], [0.8183492061247076, 0.8134823995486539, 0.7962163180341071], [0.7721050863715476, 0.7727764570357452, 0.7584175889178073], [0.796539988927515, 0.7914568285740238, 0.780138404068007], [0.8068562594780773, 0.8052072547231152, 0.7901511917495838]]\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output  \n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru2_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(pool4)\n",
    "gru2_in = Reshape((6, 128*6))(gru2_in_perm)\n",
    "gru2 = GRU(32)(gru2_in)\n",
    "\n",
    "gru_dropout = Dropout(0.1)(gru2)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc_test = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc_test)\n",
    "        print(\"AUCs:\",auc)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn2_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn2_losses(test).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 1360, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 1360, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1360, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 1360, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 340, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 340, 128)      73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 340, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 340, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 85, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 85, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 22, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 22, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 6, 768)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                76896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3250      \n",
      "=================================================================\n",
      "Total params: 453,714\n",
      "Trainable params: 452,818\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 15244 samples, validate on 1529 samples\n",
      "Epoch 1/50\n",
      "15244/15244 [==============================] - 266s 17ms/step - loss: 0.3144 - val_loss: 0.2247\n",
      "AUCs: [0.6250911722727538, 0.6318412114675168, 0.6238126414770697]\n",
      "Epoch 2/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2297 - val_loss: 0.2118\n",
      "AUCs: [0.6895764791315684, 0.6734014576670296, 0.6870144078927579]\n",
      "Epoch 3/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2179 - val_loss: 0.2232\n",
      "AUCs: [0.6679785949840487, 0.664272928115649, 0.6578439500815924]\n",
      "Epoch 4/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2156 - val_loss: 0.2025\n",
      "AUCs: [0.7224822798739021, 0.7067807603841206, 0.7092142638688875]\n",
      "Epoch 5/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2128 - val_loss: 0.2150\n",
      "AUCs: [0.7129311703028353, 0.7314705533125171, 0.6995335385422713]\n",
      "Epoch 6/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2121 - val_loss: 0.2118\n",
      "AUCs: [0.7311767029466131, 0.7225822970864678, 0.7182107957418624]\n",
      "Epoch 7/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2107 - val_loss: 0.2125\n",
      "AUCs: [0.7473913548645544, 0.7408862300898632, 0.7356889607682272]\n",
      "Epoch 8/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2091 - val_loss: 0.2017\n",
      "AUCs: [0.763977201194708, 0.7602015109106531, 0.7557351284411833]\n",
      "Epoch 9/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2076 - val_loss: 0.2243\n",
      "AUCs: [0.7380412200981781, 0.7419555664784322, 0.7250852682495247]\n",
      "Epoch 10/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2072 - val_loss: 0.2235\n",
      "AUCs: [0.7310932555847568, 0.7412709090769094, 0.7208566463570701]\n",
      "Epoch 11/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2069 - val_loss: 0.1987\n",
      "AUCs: [0.7868532372175426, 0.7824449091358638, 0.7804815032460162]\n",
      "Epoch 12/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2057 - val_loss: 0.1953\n",
      "AUCs: [0.8010992588159154, 0.7981923290253125, 0.7857344918746405]\n",
      "Epoch 13/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2055 - val_loss: 0.2064\n",
      "AUCs: [0.784923139673093, 0.7824129759196987, 0.7769119306476162]\n",
      "Epoch 14/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2043 - val_loss: 0.1924\n",
      "AUCs: [0.8044371709691701, 0.8093483203453294, 0.7917056771534855]\n",
      "Epoch 15/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2040 - val_loss: 0.1899\n",
      "AUCs: [0.8043590977468109, 0.8028406943982251, 0.7901192710161264]\n",
      "Epoch 16/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2035 - val_loss: 0.1917\n",
      "AUCs: [0.7979937360407992, 0.7965382571759065, 0.7852227537028523]\n",
      "Epoch 17/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2045 - val_loss: 0.2096\n",
      "AUCs: [0.7784426565544581, 0.7873269035780788, 0.7609463114433938]\n",
      "Epoch 18/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2020 - val_loss: 0.1914\n",
      "AUCs: [0.8032817371140384, 0.8058439246466372, 0.7895187834572804]\n",
      "Epoch 19/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2029 - val_loss: 0.1913\n",
      "AUCs: [0.8115840306323829, 0.8076554781758852, 0.7981777299979261]\n",
      "Epoch 20/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2020 - val_loss: 0.2181\n",
      "AUCs: [0.7341353747658763, 0.7323375796931524, 0.7267903047200386]\n",
      "Epoch 21/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2010 - val_loss: 0.1895\n",
      "AUCs: [0.8045722585753695, 0.8001646066920378, 0.7908513579369272]\n",
      "Epoch 22/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2013 - val_loss: 0.1918\n",
      "AUCs: [0.7993339384081176, 0.796181754819401, 0.7886862967526036]\n",
      "Epoch 23/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2013 - val_loss: 0.1874\n",
      "AUCs: [0.8188413747512692, 0.8128247450858239, 0.8066430920825663]\n",
      "Epoch 24/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2005 - val_loss: 0.1870\n",
      "AUCs: [0.8225106805235424, 0.8227379535535064, 0.8089124531621272]\n",
      "Epoch 25/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2002 - val_loss: 0.1925\n",
      "AUCs: [0.8131018562326507, 0.8138405331236833, 0.7991503013361851]\n",
      "Epoch 26/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2005 - val_loss: 0.1947\n",
      "AUCs: [0.7857755155905707, 0.7848879235548134, 0.7716276914464576]\n",
      "Epoch 27/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2002 - val_loss: 0.1915\n",
      "AUCs: [0.8051855268941986, 0.8006267810574005, 0.7919078891934507]\n",
      "Epoch 28/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1994 - val_loss: 0.1977\n",
      "AUCs: [0.8026824064850726, 0.8006872855003224, 0.7861376378652762]\n",
      "Epoch 29/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1991 - val_loss: 0.1960\n",
      "AUCs: [0.7879351279880877, 0.7758161276237564, 0.7713441586059772]\n",
      "Epoch 30/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1982 - val_loss: 0.1957\n",
      "AUCs: [0.8158791759411058, 0.810613964095723, 0.8001247351812178]\n",
      "Epoch 31/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.1980 - val_loss: 0.2169\n",
      "AUCs: [0.7650649042715304, 0.7756665118073717, 0.7588281141165786]\n",
      "Epoch 32/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1979 - val_loss: 0.1963\n",
      "AUCs: [0.8042213006385583, 0.7941312893328142, 0.7840354852695106]\n",
      "Epoch 33/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1974 - val_loss: 0.1949\n",
      "AUCs: [0.810641537166254, 0.79831452138061, 0.790022513030054]\n",
      "Epoch 34/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1973 - val_loss: 0.2009\n",
      "AUCs: [0.7968030245496551, 0.7942585972622263, 0.771982566873115]\n",
      "Epoch 35/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1966 - val_loss: 0.2279\n",
      "AUCs: [0.7800226239717393, 0.7808198332497481, 0.7688575091198274]\n",
      "Epoch 36/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1963 - val_loss: 0.1939\n",
      "AUCs: [0.8175036993859299, 0.8097796243273053, 0.7936098658620528]\n",
      "Epoch 37/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1949 - val_loss: 0.1961\n",
      "AUCs: [0.8163597630913391, 0.8007666770320989, 0.7947346567991818]\n",
      "Epoch 38/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1955 - val_loss: 0.1980\n",
      "AUCs: [0.802049013682571, 0.7897620776073676, 0.7811481832069147]\n",
      "Epoch 39/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1960 - val_loss: 0.1964\n",
      "AUCs: [0.8171865969193669, 0.8066129446367194, 0.7948051203688441]\n",
      "Epoch 40/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1948 - val_loss: 0.2093\n",
      "AUCs: [0.7614381071513988, 0.749927653902108, 0.7480013007571799]\n",
      "Epoch 41/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1940 - val_loss: 0.2063\n",
      "AUCs: [0.7896260329364094, 0.7751841028438236, 0.7682646017507974]\n",
      "Epoch 42/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1933 - val_loss: 0.2038\n",
      "AUCs: [0.8121070126801351, 0.8060240304266663, 0.7881049380137963]\n",
      "Epoch 43/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1925 - val_loss: 0.2102\n",
      "AUCs: [0.7891966417709598, 0.7709574867557678, 0.7673247919541966]\n",
      "Epoch 44/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1923 - val_loss: 0.2055\n",
      "AUCs: [0.7993075500819407, 0.7881493255720278, 0.7698386908625668]\n",
      "Epoch 45/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1926 - val_loss: 0.2093\n",
      "AUCs: [0.7906299522429511, 0.7771536688077069, 0.7691458760939779]\n",
      "Epoch 46/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1912 - val_loss: 0.2104\n",
      "AUCs: [0.7853503031600788, 0.766606946455359, 0.7626682099655863]\n",
      "Epoch 47/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.1912 - val_loss: 0.2158\n",
      "AUCs: [0.7544919387300275, 0.7385337456166048, 0.7366695082766195]\n",
      "Epoch 48/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1905 - val_loss: 0.2212\n",
      "AUCs: [0.7740677741109658, 0.7627237976445648, 0.7482890951979627]\n",
      "Epoch 49/50\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.1898 - val_loss: 0.2133\n",
      "AUCs: [0.7870948277916091, 0.7725418202647724, 0.7631865354834069]\n",
      "Epoch 50/50\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1894 - val_loss: 0.2147\n",
      "AUCs: [0.7613686791160045, 0.7547830868784788, 0.7413969360721265]\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output  \n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru3_in_perm = Lambda(K.reverse,arguments={'axes':2})(pool4)\n",
    "gru3_in = Reshape((6, 128*6))(gru3_in_perm)\n",
    "gru3 = GRU(32)(gru3_in)\n",
    "\n",
    "gru_dropout = Dropout(0.1)(gru3)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc_test = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc_test)\n",
    "        print(\"AUCs:\",auc_test)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn3_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn3_losses(test).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 1360, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 1360, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1360, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 1360, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 340, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 340, 128)      73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 340, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 340, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 85, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 85, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 22, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 22, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 6, 768)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                76896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3250      \n",
      "=================================================================\n",
      "Total params: 453,714\n",
      "Trainable params: 452,818\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 15244 samples, validate on 1529 samples\n",
      "Epoch 1/50\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.3152 - val_loss: 0.2263\n",
      "AUCs: [0.6678585633108169, 0.6555528427192853, 0.6591343349203456]\n",
      "Epoch 2/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2293 - val_loss: 0.2218\n",
      "AUCs: [0.6277291454101679, 0.6372353589769807, 0.6278245633236893]\n",
      "Epoch 3/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2198 - val_loss: 0.2049\n",
      "AUCs: [0.6885610011336815, 0.6673215573246969, 0.67328868849443]\n",
      "Epoch 4/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2171 - val_loss: 0.2010\n",
      "AUCs: [0.7043106381163021, 0.6804613593126752, 0.6893068303686049]\n",
      "Epoch 5/50\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.2146 - val_loss: 0.2035\n",
      "AUCs: [0.7093446757910437, 0.6919146709838216, 0.6941828763772827]\n",
      "Epoch 6/50\n",
      "15244/15244 [==============================] - 265s 17ms/step - loss: 0.2128 - val_loss: 0.2124\n",
      "AUCs: [0.6922005966609239, 0.6669288271940266, 0.6790049938057947]\n",
      "Epoch 7/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2120 - val_loss: 0.2127\n",
      "AUCs: [0.6919572628837898, 0.6765225844350095, 0.6779419340399344]\n",
      "Epoch 8/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2111 - val_loss: 0.2061\n",
      "AUCs: [0.7199655072154634, 0.7025611343534115, 0.7101539810075381]\n",
      "Epoch 9/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2107 - val_loss: 0.2079\n",
      "AUCs: [0.7117660953052726, 0.7059977498047506, 0.6957232321932271]\n",
      "Epoch 10/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2101 - val_loss: 0.2407\n",
      "AUCs: [0.6640576913529596, 0.6689178687816707, 0.6629389115327455]\n",
      "Epoch 11/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2099 - val_loss: 0.2105\n",
      "AUCs: [0.7040234519990729, 0.6901785615599723, 0.6894997570067151]\n",
      "Epoch 12/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2103 - val_loss: 0.2009\n",
      "AUCs: [0.7301224705956468, 0.7284197199289784, 0.7100707762784129]\n",
      "Epoch 13/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2098 - val_loss: 0.1976\n",
      "AUCs: [0.7379878799784627, 0.7314077934869446, 0.7238572375395026]\n",
      "Epoch 14/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2102 - val_loss: 0.1976\n",
      "AUCs: [0.7304741975014007, 0.7404391673227069, 0.7100035095423192]\n",
      "Epoch 15/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2096 - val_loss: 0.1965\n",
      "AUCs: [0.7309111855576543, 0.7197769451915473, 0.7135359819104445]\n",
      "Epoch 16/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2087 - val_loss: 0.1972\n",
      "AUCs: [0.7308948271624309, 0.728389784965994, 0.7146742543993022]\n",
      "Epoch 17/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2088 - val_loss: 0.1966\n",
      "AUCs: [0.7420193977272924, 0.7404324831935427, 0.7282586512733232]\n",
      "Epoch 18/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2090 - val_loss: 0.1984\n",
      "AUCs: [0.7492595646194777, 0.7450453229586691, 0.7383225668127456]\n",
      "Epoch 19/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2088 - val_loss: 0.1964\n",
      "AUCs: [0.7479436100047415, 0.7537994676996069, 0.7351687444052278]\n",
      "Epoch 20/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2080 - val_loss: 0.1947\n",
      "AUCs: [0.7546330360702838, 0.7546153094345162, 0.7457285419888116]\n",
      "Epoch 21/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2085 - val_loss: 0.1985\n",
      "AUCs: [0.7338934711093951, 0.7328930207012576, 0.7232085959441423]\n",
      "Epoch 22/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2085 - val_loss: 0.1946\n",
      "AUCs: [0.7567546139927458, 0.7597599990109808, 0.74879545858944]\n",
      "Epoch 23/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2074 - val_loss: 0.1946\n",
      "AUCs: [0.7616156930758033, 0.7583723821771591, 0.7509255813166223]\n",
      "Epoch 24/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2082 - val_loss: 0.2136\n",
      "AUCs: [0.6626712963644465, 0.6647244087245652, 0.6636793622504209]\n",
      "Epoch 25/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2082 - val_loss: 0.1950\n",
      "AUCs: [0.7518798226632429, 0.7516102935618975, 0.7404405945301944]\n",
      "Epoch 26/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2075 - val_loss: 0.1976\n",
      "AUCs: [0.7393821296969254, 0.7467059070678057, 0.7230314074369071]\n",
      "Epoch 27/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2075 - val_loss: 0.1938\n",
      "AUCs: [0.7664370979415999, 0.7795313962343416, 0.7497778590661087]\n",
      "Epoch 28/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2067 - val_loss: 0.2168\n",
      "AUCs: [0.7229753487121049, 0.7204963040681043, 0.7069396637189191]\n",
      "Epoch 29/50\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2077 - val_loss: 0.1944\n",
      "AUCs: [0.764828370695657, 0.7639164700477526, 0.752713723987744]\n",
      "Epoch 30/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2077 - val_loss: 0.1992\n",
      "AUCs: [0.7520706859571191, 0.7649764553353589, 0.7422391175228387]\n",
      "Epoch 31/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2071 - val_loss: 0.1929\n",
      "AUCs: [0.7786115608787793, 0.7800885448291889, 0.7693935218646398]\n",
      "Epoch 32/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2071 - val_loss: 0.1927\n",
      "AUCs: [0.7771579417284251, 0.7849668476319716, 0.7633059912762468]\n",
      "Epoch 33/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2064 - val_loss: 0.1973\n",
      "AUCs: [0.7656372424383531, 0.768278801687963, 0.751388684216597]\n",
      "Epoch 34/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2064 - val_loss: 0.1936\n",
      "AUCs: [0.7719204668358032, 0.7788402718078002, 0.7613761679368625]\n",
      "Epoch 35/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2066 - val_loss: 0.1925\n",
      "AUCs: [0.7762041353641896, 0.783998964142606, 0.7633089534429587]\n",
      "Epoch 36/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2058 - val_loss: 0.1918\n",
      "AUCs: [0.7822502371333117, 0.7857137959669762, 0.7658999918976463]\n",
      "Epoch 37/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2059 - val_loss: 0.1944\n",
      "AUCs: [0.7622261141703618, 0.7664107454878227, 0.7452545259155116]\n",
      "Epoch 38/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2055 - val_loss: 0.1910\n",
      "AUCs: [0.7832827212850976, 0.7832497791488039, 0.7684116950704651]\n",
      "Epoch 39/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2055 - val_loss: 0.1912\n",
      "AUCs: [0.783804386491937, 0.7826962959714646, 0.7665897979585599]\n",
      "Epoch 40/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2046 - val_loss: 0.2025\n",
      "AUCs: [0.7327114727142235, 0.7462376185294148, 0.7084700483322497]\n",
      "Epoch 41/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2042 - val_loss: 0.1926\n",
      "AUCs: [0.7812178849043149, 0.7717517683381315, 0.7675080643429472]\n",
      "Epoch 42/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2041 - val_loss: 0.1946\n",
      "AUCs: [0.778785927052186, 0.7795132368770608, 0.7604038307467837]\n",
      "Epoch 43/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2028 - val_loss: 0.1941\n",
      "AUCs: [0.7838200374161945, 0.7795770646437131, 0.7691481333317598]\n",
      "Epoch 44/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2031 - val_loss: 0.1990\n",
      "AUCs: [0.7746485024225273, 0.7722104501855459, 0.7542220706030862]\n",
      "Epoch 45/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2023 - val_loss: 0.2076\n",
      "AUCs: [0.7638501139355881, 0.7537935692858548, 0.7465375069027145]\n",
      "Epoch 46/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2010 - val_loss: 0.1986\n",
      "AUCs: [0.7797905489969108, 0.7719732870862582, 0.7667856918021567]\n",
      "Epoch 47/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2009 - val_loss: 0.2002\n",
      "AUCs: [0.762846902701476, 0.7543349607275348, 0.7516176089123604]\n",
      "Epoch 48/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.2004 - val_loss: 0.2012\n",
      "AUCs: [0.761503901451815, 0.7544510552076886, 0.7504450551818443]\n",
      "Epoch 49/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.1991 - val_loss: 0.2094\n",
      "AUCs: [0.7572557684403419, 0.7484822079359195, 0.7457201860436077]\n",
      "Epoch 50/50\n",
      "15244/15244 [==============================] - 262s 17ms/step - loss: 0.1982 - val_loss: 0.2066\n",
      "AUCs: [0.7773005886146067, 0.7682064428356675, 0.7640752013078247]\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru3_in_perm = Lambda(K.reverse,arguments={'axes':2})(pool4)\n",
    "gru4_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(gru3_in_perm)\n",
    "gru4_in = Reshape((6, 128*6))(gru4_in_perm)\n",
    "gru4 = GRU(32)(gru4_in)\n",
    "\n",
    "gru_dropout = Dropout(0.1)(gru4)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc_test = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc_test)\n",
    "        print(\"AUCs:\",auc_test)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn4_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn4_losses(test).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 1360, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 1360, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1360, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 1360, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 340, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 340, 128)      73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 340, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 340, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 85, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 85, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 22, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 22, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 6, 768)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                76896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3250      \n",
      "=================================================================\n",
      "Total params: 453,714\n",
      "Trainable params: 452,818\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/35\n",
      "15244/15244 [==============================] - 255s 17ms/step - loss: 0.3170\n",
      "AUCs: 0.5810377858143237\n",
      "Epoch 2/35\n",
      "15244/15244 [==============================] - 246s 16ms/step - loss: 0.2303\n",
      "AUCs: 0.6984200571280862\n",
      "Epoch 3/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2164\n",
      "AUCs: 0.6730605246027046\n",
      "Epoch 4/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2137\n",
      "AUCs: 0.719918689221103\n",
      "Epoch 5/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2117\n",
      "AUCs: 0.7385444160931044\n",
      "Epoch 6/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2109\n",
      "AUCs: 0.6802344798187744\n",
      "Epoch 7/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2093\n",
      "AUCs: 0.7711790800104733\n",
      "Epoch 8/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2086\n",
      "AUCs: 0.7633776087487663\n",
      "Epoch 9/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2092\n",
      "AUCs: 0.7312619674387748\n",
      "Epoch 10/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2079\n",
      "AUCs: 0.7843549488614039\n",
      "Epoch 11/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2066\n",
      "AUCs: 0.7483796744445719\n",
      "Epoch 12/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2064\n",
      "AUCs: 0.7333415532335349\n",
      "Epoch 13/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2065\n",
      "AUCs: 0.7854472313771204\n",
      "Epoch 14/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2051\n",
      "AUCs: 0.7599987741544514\n",
      "Epoch 15/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2048\n",
      "AUCs: 0.7821702075299554\n",
      "Epoch 16/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2049\n",
      "AUCs: 0.7918460369277276\n",
      "Epoch 17/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2038\n",
      "AUCs: 0.7864981324543043\n",
      "Epoch 18/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2032\n",
      "AUCs: 0.7984694263846868\n",
      "Epoch 19/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2030\n",
      "AUCs: 0.7708636921923748\n",
      "Epoch 20/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2039\n",
      "AUCs: 0.7812903068937548\n",
      "Epoch 21/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2028\n",
      "AUCs: 0.7783406360581457\n",
      "Epoch 22/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2027\n",
      "AUCs: 0.7136617206099747\n",
      "Epoch 23/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2019\n",
      "AUCs: 0.7927648089876737\n",
      "Epoch 24/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2024\n",
      "AUCs: 0.8020678258335218\n",
      "Epoch 25/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2012\n",
      "AUCs: 0.7790032475861567\n",
      "Epoch 26/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2007\n",
      "AUCs: 0.7616804613793897\n",
      "Epoch 27/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2012\n",
      "AUCs: 0.7446045256087857\n",
      "Epoch 28/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2010\n",
      "AUCs: 0.7358635543766288\n",
      "Epoch 29/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2002\n",
      "AUCs: 0.7938283327518161\n",
      "Epoch 30/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.1998\n",
      "AUCs: 0.7473860281647987\n",
      "Epoch 31/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.1989\n",
      "AUCs: 0.7766379749580595\n",
      "Epoch 32/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2002\n",
      "AUCs: 0.7971625485995645\n",
      "Epoch 33/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.1990\n",
      "AUCs: 0.7909765863711045\n",
      "Epoch 34/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.1985\n",
      "AUCs: 0.7940653405638826\n",
      "Epoch 35/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.1983\n",
      "AUCs: 0.7628637731806153\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1})(pool4)\n",
    "gru5_in = Reshape((6, 128*6))(gru5_in_perm)\n",
    "gru5 = GRU(32)(gru5_in)\n",
    "\n",
    "gru_dropout = Dropout(0.1)(gru5)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"AUCs:\",auc)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn5_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn5_losses(train).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 1360, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 1360, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1360, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 1360, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 340, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 340, 128)      73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 340, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 340, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 85, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 85, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 22, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 22, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 6, 768)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                76896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3250      \n",
      "=================================================================\n",
      "Total params: 453,714\n",
      "Trainable params: 452,818\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/35\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.3121\n",
      "AUCs: 0.5728010331229005\n",
      "Epoch 2/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2358\n",
      "AUCs: 0.6679314868355712\n",
      "Epoch 3/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2222\n",
      "AUCs: 0.6580223670666006\n",
      "Epoch 4/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2181\n",
      "AUCs: 0.6794683631701756\n",
      "Epoch 5/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2158\n",
      "AUCs: 0.6694232781416722\n",
      "Epoch 6/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2135\n",
      "AUCs: 0.7011978702560248\n",
      "Epoch 7/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2127\n",
      "AUCs: 0.710564130803969\n",
      "Epoch 8/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2122\n",
      "AUCs: 0.6892339199872762\n",
      "Epoch 9/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2117\n",
      "AUCs: 0.7229186114031855\n",
      "Epoch 10/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2111\n",
      "AUCs: 0.6749457747813723\n",
      "Epoch 11/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2109\n",
      "AUCs: 0.705727202833434\n",
      "Epoch 12/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2106\n",
      "AUCs: 0.711952259395801\n",
      "Epoch 13/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2099\n",
      "AUCs: 0.7216781684876962\n",
      "Epoch 14/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2096\n",
      "AUCs: 0.7325256154842158\n",
      "Epoch 15/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2090\n",
      "AUCs: 0.7257188854944053\n",
      "Epoch 16/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2095\n",
      "AUCs: 0.7230934152176204\n",
      "Epoch 17/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2087\n",
      "AUCs: 0.7455559371532439\n",
      "Epoch 18/35\n",
      "15244/15244 [==============================] - 246s 16ms/step - loss: 0.2086\n",
      "AUCs: 0.7223504669362658\n",
      "Epoch 19/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2087\n",
      "AUCs: 0.727233950003109\n",
      "Epoch 20/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2081\n",
      "AUCs: 0.734181222847471\n",
      "Epoch 21/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2077\n",
      "AUCs: 0.7621840107196212\n",
      "Epoch 22/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2069\n",
      "AUCs: 0.7430916367232353\n",
      "Epoch 23/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2068\n",
      "AUCs: 0.7660877093998526\n",
      "Epoch 24/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2062\n",
      "AUCs: 0.763000991102121\n",
      "Epoch 25/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2062\n",
      "AUCs: 0.7611755093191763\n",
      "Epoch 26/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2058\n",
      "AUCs: 0.7574530723370111\n",
      "Epoch 27/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2055\n",
      "AUCs: 0.7553356765493742\n",
      "Epoch 28/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2056\n",
      "AUCs: 0.7773718885599478\n",
      "Epoch 29/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2059\n",
      "AUCs: 0.7552110104888573\n",
      "Epoch 30/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2050\n",
      "AUCs: 0.7819900371065645\n",
      "Epoch 31/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2052\n",
      "AUCs: 0.7856772950516127\n",
      "Epoch 32/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2043\n",
      "AUCs: 0.7561579902446914\n",
      "Epoch 33/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2042\n",
      "AUCs: 0.7709672393352452\n",
      "Epoch 34/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2037\n",
      "AUCs: 0.7587670272142449\n",
      "Epoch 35/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2041\n",
      "AUCs: 0.7781728434149499\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1})(pool4)\n",
    "gru6_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(gru5_in_perm)\n",
    "gru6_in = Reshape((6, 128*6))(gru6_in_perm)\n",
    "gru6 = GRU(32)(gru6_in)\n",
    "\n",
    "gru_dropout = Dropout(0.1)(gru6)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"AUCs:\",auc)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn6_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn6_losses(train).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 1360, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 1360, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1360, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 1360, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 340, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 340, 128)      73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 340, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 340, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 85, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 85, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 22, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 22, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 6, 768)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                76896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3250      \n",
      "=================================================================\n",
      "Total params: 453,714\n",
      "Trainable params: 452,818\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/35\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.3186\n",
      "AUCs: 0.604252092023034\n",
      "Epoch 2/35\n",
      "15244/15244 [==============================] - 251s 16ms/step - loss: 0.2317\n",
      "AUCs: 0.6817405552956799\n",
      "Epoch 3/35\n",
      "15244/15244 [==============================] - 251s 16ms/step - loss: 0.2172\n",
      "AUCs: 0.7030796541027133\n",
      "Epoch 4/35\n",
      "15244/15244 [==============================] - 251s 16ms/step - loss: 0.2138\n",
      "AUCs: 0.6950648506426897\n",
      "Epoch 5/35\n",
      "15244/15244 [==============================] - 251s 16ms/step - loss: 0.2111\n",
      "AUCs: 0.72445680019228\n",
      "Epoch 6/35\n",
      "15244/15244 [==============================] - 251s 16ms/step - loss: 0.2092\n",
      "AUCs: 0.7714789424956835\n",
      "Epoch 7/35\n",
      "15244/15244 [==============================] - 251s 16ms/step - loss: 0.2084\n",
      "AUCs: 0.7614274767253967\n",
      "Epoch 8/35\n",
      "15244/15244 [==============================] - 251s 16ms/step - loss: 0.2073\n",
      "AUCs: 0.6446228220185636\n",
      "Epoch 9/35\n",
      "15244/15244 [==============================] - 251s 16ms/step - loss: 0.2060\n",
      "AUCs: 0.731381670874941\n",
      "Epoch 10/35\n",
      "15244/15244 [==============================] - 251s 16ms/step - loss: 0.2059\n",
      "AUCs: 0.7928275465750935\n",
      "Epoch 11/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2050\n",
      "AUCs: 0.7758638613189559\n",
      "Epoch 12/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2047\n",
      "AUCs: 0.797869906710153\n",
      "Epoch 13/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2038\n",
      "AUCs: 0.7885572083753513\n",
      "Epoch 14/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2028\n",
      "AUCs: 0.7654839837530824\n",
      "Epoch 15/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2025\n",
      "AUCs: 0.7881569170536973\n",
      "Epoch 16/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2022\n",
      "AUCs: 0.7655775014985113\n",
      "Epoch 17/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2011\n",
      "AUCs: 0.802925862575024\n",
      "Epoch 18/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.2005\n",
      "AUCs: 0.7198516858841459\n",
      "Epoch 19/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1998\n",
      "AUCs: 0.7700793703028481\n",
      "Epoch 20/35\n",
      "15244/15244 [==============================] - 251s 16ms/step - loss: 0.1988\n",
      "AUCs: 0.8140168857014813\n",
      "Epoch 21/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1984\n",
      "AUCs: 0.7966590849880145\n",
      "Epoch 22/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1976\n",
      "AUCs: 0.7690888712883374\n",
      "Epoch 23/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1969\n",
      "AUCs: 0.8166370029853282\n",
      "Epoch 24/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1966\n",
      "AUCs: 0.8066443702833692\n",
      "Epoch 25/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1961\n",
      "AUCs: 0.7773565689640715\n",
      "Epoch 26/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.1947\n",
      "AUCs: 0.8155100827433721\n",
      "Epoch 27/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1951\n",
      "AUCs: 0.8039008189205673\n",
      "Epoch 28/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1947\n",
      "AUCs: 0.8186535870084728\n",
      "Epoch 29/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1938\n",
      "AUCs: 0.7874897811026291\n",
      "Epoch 30/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1930\n",
      "AUCs: 0.8167343847059183\n",
      "Epoch 31/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1924\n",
      "AUCs: 0.7987840822963388\n",
      "Epoch 32/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1918\n",
      "AUCs: 0.7947941459288621\n",
      "Epoch 33/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1916\n",
      "AUCs: 0.7603900472955785\n",
      "Epoch 34/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1907\n",
      "AUCs: 0.802487121893259\n",
      "Epoch 35/35\n",
      "15244/15244 [==============================] - 250s 16ms/step - loss: 0.1897\n",
      "AUCs: 0.813809448721576\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1})(pool4)\n",
    "gru7_in_perm = Lambda(K.reverse,arguments={'axes':2})(gru5_in_perm)\n",
    "gru7_in = Reshape((6, 128*6))(gru7_in_perm)\n",
    "gru7 = GRU(32)(gru7_in)\n",
    "\n",
    "gru_dropout = Dropout(0.1)(gru7)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"AUCs:\",auc)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn7_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn7_losses(train).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 1360, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 1360, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1360, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 1360, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 340, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 340, 128)      73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 340, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 340, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 85, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 85, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 85, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 22, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 22, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 6, 768)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                76896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3250      \n",
      "=================================================================\n",
      "Total params: 453,714\n",
      "Trainable params: 452,818\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/35\n",
      "15244/15244 [==============================] - 260s 17ms/step - loss: 0.3166\n",
      "AUCs: 0.63030552687989\n",
      "Epoch 2/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2304\n",
      "AUCs: 0.4057542742884742\n",
      "Epoch 3/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2176\n",
      "AUCs: 0.6683212246207962\n",
      "Epoch 4/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2149\n",
      "AUCs: 0.6963015910895914\n",
      "Epoch 5/35\n",
      "15244/15244 [==============================] - 246s 16ms/step - loss: 0.2138\n",
      "AUCs: 0.7184364629638871\n",
      "Epoch 6/35\n",
      "15244/15244 [==============================] - 245s 16ms/step - loss: 0.2124\n",
      "AUCs: 0.7028319573145684\n",
      "Epoch 7/35\n",
      "15244/15244 [==============================] - 246s 16ms/step - loss: 0.2119\n",
      "AUCs: 0.7286391970332692\n",
      "Epoch 8/35\n",
      "15244/15244 [==============================] - 245s 16ms/step - loss: 0.2107\n",
      "AUCs: 0.722923799993727\n",
      "Epoch 9/35\n",
      "15244/15244 [==============================] - 246s 16ms/step - loss: 0.2105\n",
      "AUCs: 0.7298455741849778\n",
      "Epoch 10/35\n",
      "15244/15244 [==============================] - 246s 16ms/step - loss: 0.2095\n",
      "AUCs: 0.7247416831133775\n",
      "Epoch 11/35\n",
      "15244/15244 [==============================] - 246s 16ms/step - loss: 0.2097\n",
      "AUCs: 0.737053074237863\n",
      "Epoch 12/35\n",
      "15244/15244 [==============================] - 246s 16ms/step - loss: 0.2086\n",
      "AUCs: 0.7474702198146171\n",
      "Epoch 13/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2081\n",
      "AUCs: 0.7261904488531288\n",
      "Epoch 14/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2090\n",
      "AUCs: 0.7433168025786092\n",
      "Epoch 15/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2083\n",
      "AUCs: 0.7546720511323047\n",
      "Epoch 16/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2079\n",
      "AUCs: 0.7019296012317262\n",
      "Epoch 17/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2072\n",
      "AUCs: 0.736280692734177\n",
      "Epoch 18/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2067\n",
      "AUCs: 0.7123600185083834\n",
      "Epoch 19/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2067\n",
      "AUCs: 0.7633494828193966\n",
      "Epoch 20/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2063\n",
      "AUCs: 0.7511469483030727\n",
      "Epoch 21/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2058\n",
      "AUCs: 0.7627452182477004\n",
      "Epoch 22/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2057\n",
      "AUCs: 0.7531923765546203\n",
      "Epoch 23/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2059\n",
      "AUCs: 0.7663370322592508\n",
      "Epoch 24/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2057\n",
      "AUCs: 0.7749511019934952\n",
      "Epoch 25/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2046\n",
      "AUCs: 0.7579584712185938\n",
      "Epoch 26/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2038\n",
      "AUCs: 0.7916816543144815\n",
      "Epoch 27/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2038\n",
      "AUCs: 0.7820077362382514\n",
      "Epoch 28/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2042\n",
      "AUCs: 0.7747209396841717\n",
      "Epoch 29/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2036\n",
      "AUCs: 0.7856572110464747\n",
      "Epoch 30/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2033\n",
      "AUCs: 0.7953078726879067\n",
      "Epoch 31/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2038\n",
      "AUCs: 0.7834500087984747\n",
      "Epoch 32/35\n",
      "15244/15244 [==============================] - 247s 16ms/step - loss: 0.2027\n",
      "AUCs: 0.7947226428391163\n",
      "Epoch 33/35\n",
      "15244/15244 [==============================] - 248s 16ms/step - loss: 0.2022\n",
      "AUCs: 0.7891987948210952\n",
      "Epoch 34/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2026\n",
      "AUCs: 0.7788132052976547\n",
      "Epoch 35/35\n",
      "15244/15244 [==============================] - 249s 16ms/step - loss: 0.2016\n",
      "AUCs: 0.7974781249611376\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1})(pool4)\n",
    "gru6_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(gru5_in_perm)\n",
    "gru8_in_perm = Lambda(K.reverse,arguments={'axes':1})(gru6_in_perm)\n",
    "gru8_in = Reshape((6, 128*6))(gru8_in_perm)\n",
    "gru8 = GRU(32)(gru8_in)\n",
    "\n",
    "gru_dropout = Dropout(0.1)(gru8)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"AUCs:\",auc)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn8_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn8_losses(train).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 1360, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 1360, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 1360, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 48, 340, 64)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 48, 340, 128) 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 48, 340, 128) 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 340, 128) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 85, 128)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 24, 85, 128)  147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 85, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 85, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 22, 128)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 12, 22, 128)  147584      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12, 22, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 22, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 6, 768)       0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 6, 768)       0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 32)           76896       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 32)           76896       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           gru_1[0][0]                      \n",
      "                                                                 gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           3250        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 532,658\n",
      "Trainable params: 531,762\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/35\n",
      "15244/15244 [==============================] - 261s 17ms/step - loss: 0.2583\n",
      "AUCs: 0.672725663330898\n",
      "Epoch 2/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.2147\n",
      "AUCs: 0.667400126439798\n",
      "Epoch 3/35\n",
      "15244/15244 [==============================] - 255s 17ms/step - loss: 0.2050\n",
      "AUCs: 0.7699635510892591\n",
      "Epoch 4/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.2001\n",
      "AUCs: 0.7914857990360181\n",
      "Epoch 5/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1948\n",
      "AUCs: 0.7844891605964296\n",
      "Epoch 6/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1919\n",
      "AUCs: 0.8084230425518267\n",
      "Epoch 7/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1890\n",
      "AUCs: 0.8024666463684491\n",
      "Epoch 8/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1872\n",
      "AUCs: 0.831006167196184\n",
      "Epoch 9/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1852\n",
      "AUCs: 0.8093025267449265\n",
      "Epoch 10/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1833\n",
      "AUCs: 0.8305412005048138\n",
      "Epoch 11/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1821\n",
      "AUCs: 0.8417074740326577\n",
      "Epoch 12/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1807\n",
      "AUCs: 0.8380439674733676\n",
      "Epoch 13/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1798\n",
      "AUCs: 0.8450358435508434\n",
      "Epoch 14/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1784\n",
      "AUCs: 0.8285471336660433\n",
      "Epoch 15/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1780\n",
      "AUCs: 0.8388054774421981\n",
      "Epoch 16/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1766\n",
      "AUCs: 0.838931012898201\n",
      "Epoch 17/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1761\n",
      "AUCs: 0.7996217252435552\n",
      "Epoch 18/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1757\n",
      "AUCs: 0.852960573212652\n",
      "Epoch 19/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1749\n",
      "AUCs: 0.8388847815755259\n",
      "Epoch 20/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1737\n",
      "AUCs: 0.8536251465280768\n",
      "Epoch 21/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1732\n",
      "AUCs: 0.8548425095101091\n",
      "Epoch 22/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1727\n",
      "AUCs: 0.8349758993749279\n",
      "Epoch 23/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1719\n",
      "AUCs: 0.8550854087379828\n",
      "Epoch 24/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1714\n",
      "AUCs: 0.841471061661256\n",
      "Epoch 25/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1709\n",
      "AUCs: 0.848632817679417\n",
      "Epoch 26/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1703\n",
      "AUCs: 0.8491882309617809\n",
      "Epoch 27/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1694\n",
      "AUCs: 0.8430900042753267\n",
      "Epoch 28/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1689\n",
      "AUCs: 0.8620914081157565\n",
      "Epoch 29/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1680\n",
      "AUCs: 0.8181154574615441\n",
      "Epoch 30/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1678\n",
      "AUCs: 0.8627967746186517\n",
      "Epoch 31/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1668\n",
      "AUCs: 0.8558754865287399\n",
      "Epoch 32/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1664\n",
      "AUCs: 0.857193887456294\n",
      "Epoch 33/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1664\n",
      "AUCs: 0.838670634106441\n",
      "Epoch 34/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1652\n",
      "AUCs: 0.8640489395853146\n",
      "Epoch 35/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1648\n",
      "AUCs: 0.8663498529972972\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru1_in = Reshape((6, 128*6))(pool4)\n",
    "gru1 = GRU(32)(gru1_in)\n",
    "\n",
    "gru2_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(pool4)\n",
    "gru2_in = Reshape((6, 128*6))(gru2_in_perm)\n",
    "gru2 = GRU(32)(gru2_in)\n",
    "\n",
    "gru = Concatenate()([gru1,gru2])\n",
    "gru_dropout = Dropout(0.2)(gru)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"AUCs:\",auc)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn12_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn12_losses(train).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 1360, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 1360, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 1360, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 48, 340, 64)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 48, 340, 128) 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 48, 340, 128) 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 340, 128) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 85, 128)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 24, 85, 128)  147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 85, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 85, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 22, 128)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 12, 22, 128)  147584      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12, 22, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 22, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 6, 6, 128)    0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 6, 768)       0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 6, 768)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 32)           76896       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 32)           76896       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           gru_1[0][0]                      \n",
      "                                                                 gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           3250        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 532,658\n",
      "Trainable params: 531,762\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/35\n",
      "15244/15244 [==============================] - 267s 17ms/step - loss: 0.2606\n",
      "AUCs: 0.7112452549228095\n",
      "Epoch 2/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.2154\n",
      "AUCs: 0.7305059677955559\n",
      "Epoch 3/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.2045\n",
      "AUCs: 0.7780375999756265\n",
      "Epoch 4/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1977\n",
      "AUCs: 0.7410529321697519\n",
      "Epoch 5/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1935\n",
      "AUCs: 0.8062665515057784\n",
      "Epoch 6/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1901\n",
      "AUCs: 0.700157909586488\n",
      "Epoch 7/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1877\n",
      "AUCs: 0.8374174421603929\n",
      "Epoch 8/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1851\n",
      "AUCs: 0.8233411907005269\n",
      "Epoch 9/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1835\n",
      "AUCs: 0.7913655894976099\n",
      "Epoch 10/35\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1814\n",
      "AUCs: 0.8316930298006391\n",
      "Epoch 11/35\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1801\n",
      "AUCs: 0.848039216247871\n",
      "Epoch 12/35\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1786\n",
      "AUCs: 0.7958226546158346\n",
      "Epoch 13/35\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1778\n",
      "AUCs: 0.8422716052226359\n",
      "Epoch 14/35\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1768\n",
      "AUCs: 0.8430263247921016\n",
      "Epoch 15/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1755\n",
      "AUCs: 0.8405365583245724\n",
      "Epoch 16/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1750\n",
      "AUCs: 0.7954142762496396\n",
      "Epoch 17/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1740\n",
      "AUCs: 0.8456456212646795\n",
      "Epoch 18/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1729\n",
      "AUCs: 0.8322100784741635\n",
      "Epoch 19/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1720\n",
      "AUCs: 0.8478912114355759\n",
      "Epoch 20/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1715\n",
      "AUCs: 0.8533877803386636\n",
      "Epoch 21/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1707\n",
      "AUCs: 0.8104784420823401\n",
      "Epoch 22/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1698\n",
      "AUCs: 0.8696322131441806\n",
      "Epoch 23/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1689\n",
      "AUCs: 0.8486844740653303\n",
      "Epoch 24/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1680\n",
      "AUCs: 0.8480567236888399\n",
      "Epoch 25/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1676\n",
      "AUCs: 0.8642366781668417\n",
      "Epoch 26/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1673\n",
      "AUCs: 0.8661288963831325\n",
      "Epoch 27/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1669\n",
      "AUCs: 0.8734639939286185\n",
      "Epoch 28/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1665\n",
      "AUCs: 0.8654265724666483\n",
      "Epoch 29/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1651\n",
      "AUCs: 0.8569018454620071\n",
      "Epoch 30/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1650\n",
      "AUCs: 0.8756426246728425\n",
      "Epoch 31/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1648\n",
      "AUCs: 0.8626680557222102\n",
      "Epoch 32/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1639\n",
      "AUCs: 0.8766732028349701\n",
      "Epoch 33/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1629\n",
      "AUCs: 0.8680878723795327\n",
      "Epoch 34/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1626\n",
      "AUCs: 0.8766440569272145\n",
      "Epoch 35/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1623\n",
      "AUCs: 0.8515321437501604\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru3_in_perm = Lambda(K.reverse,arguments={'axes':2})(pool4)\n",
    "gru3_in = Reshape((6, 128*6))(gru3_in_perm)\n",
    "gru3 = GRU(32)(gru3_in)\n",
    "\n",
    "gru4_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(gru3_in_perm)\n",
    "gru4_in = Reshape((6, 128*6))(gru4_in_perm)\n",
    "gru4 = GRU(32)(gru4_in)\n",
    "\n",
    "gru = Concatenate()([gru3,gru4])\n",
    "gru_dropout = Dropout(0.2)(gru)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"AUCs:\",auc)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn34_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn34_losses(train).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 1360, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 1360, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 1360, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 48, 340, 64)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 48, 340, 128) 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 48, 340, 128) 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 340, 128) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 85, 128)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 24, 85, 128)  147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 85, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 85, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 22, 128)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 12, 22, 128)  147584      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12, 22, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 22, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 6, 6, 128)    0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 6, 768)       0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 6, 768)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 32)           76896       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 32)           76896       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           gru_1[0][0]                      \n",
      "                                                                 gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           3250        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 532,658\n",
      "Trainable params: 531,762\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/35\n",
      "15244/15244 [==============================] - 272s 18ms/step - loss: 0.2640\n",
      "AUCs: 0.7181786660255136\n",
      "Epoch 2/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.2153\n",
      "AUCs: 0.7120178407098589\n",
      "Epoch 3/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.2054\n",
      "AUCs: 0.757161955959773\n",
      "Epoch 4/35\n",
      "15244/15244 [==============================] - 255s 17ms/step - loss: 0.1992\n",
      "AUCs: 0.7850438425869917\n",
      "Epoch 5/35\n",
      "15244/15244 [==============================] - 255s 17ms/step - loss: 0.1945\n",
      "AUCs: 0.7687979627608155\n",
      "Epoch 6/35\n",
      "15244/15244 [==============================] - 255s 17ms/step - loss: 0.1922\n",
      "AUCs: 0.7777194511034458\n",
      "Epoch 7/35\n",
      "15244/15244 [==============================] - 255s 17ms/step - loss: 0.1891\n",
      "AUCs: 0.8051020344235539\n",
      "Epoch 8/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1868\n",
      "AUCs: 0.8381826708459983\n",
      "Epoch 9/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1842\n",
      "AUCs: 0.7636537916293941\n",
      "Epoch 10/35\n",
      "15244/15244 [==============================] - 255s 17ms/step - loss: 0.1826\n",
      "AUCs: 0.8333119049602808\n",
      "Epoch 11/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1808\n",
      "AUCs: 0.8135418263432241\n",
      "Epoch 12/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1797\n",
      "AUCs: 0.8399773232292637\n",
      "Epoch 13/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1790\n",
      "AUCs: 0.8242803060924486\n",
      "Epoch 14/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1781\n",
      "AUCs: 0.8405284381786258\n",
      "Epoch 15/35\n",
      "15244/15244 [==============================] - 255s 17ms/step - loss: 0.1772\n",
      "AUCs: 0.8231676413959922\n",
      "Epoch 16/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1760\n",
      "AUCs: 0.8385283332346031\n",
      "Epoch 17/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1755\n",
      "AUCs: 0.8476311827168628\n",
      "Epoch 18/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1751\n",
      "AUCs: 0.8494106408698981\n",
      "Epoch 19/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1738\n",
      "AUCs: 0.8573607428405746\n",
      "Epoch 20/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1738\n",
      "AUCs: 0.857332157613759\n",
      "Epoch 21/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1732\n",
      "AUCs: 0.8566395381930851\n",
      "Epoch 22/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1726\n",
      "AUCs: 0.831171732989835\n",
      "Epoch 23/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1722\n",
      "AUCs: 0.8089006496027937\n",
      "Epoch 24/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1712\n",
      "AUCs: 0.8530393517947057\n",
      "Epoch 25/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1706\n",
      "AUCs: 0.8423561284707468\n",
      "Epoch 26/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1704\n",
      "AUCs: 0.8499972657799855\n",
      "Epoch 27/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1698\n",
      "AUCs: 0.8359506592580123\n",
      "Epoch 28/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1696\n",
      "AUCs: 0.80545506428103\n",
      "Epoch 29/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1692\n",
      "AUCs: 0.845481725161856\n",
      "Epoch 30/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1681\n",
      "AUCs: 0.8649105873784344\n",
      "Epoch 31/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1674\n",
      "AUCs: 0.8308561598875827\n",
      "Epoch 32/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1677\n",
      "AUCs: 0.8393731122433272\n",
      "Epoch 33/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1667\n",
      "AUCs: 0.8672503672317763\n",
      "Epoch 34/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1662\n",
      "AUCs: 0.8602430084886424\n",
      "Epoch 35/35\n",
      "15244/15244 [==============================] - 254s 17ms/step - loss: 0.1661\n",
      "AUCs: 0.8623254642911473\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1})(pool4)\n",
    "gru5_in = Reshape((6, 128*6))(gru5_in_perm)\n",
    "gru5 = GRU(32)(gru5_in)\n",
    "\n",
    "gru6_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(gru5_in_perm)\n",
    "gru6_in = Reshape((6, 128*6))(gru6_in_perm)\n",
    "gru6 = GRU(32)(gru6_in)\n",
    "\n",
    "gru = Concatenate()([gru5,gru6])\n",
    "gru_dropout = Dropout(0.2)(gru)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"AUCs:\",auc)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn56_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn56_losses(train).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 1360, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 1360, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 1360, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 48, 340, 64)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 48, 340, 128) 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 48, 340, 128) 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 340, 128) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 85, 128)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 24, 85, 128)  147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 85, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 85, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 22, 128)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 12, 22, 128)  147584      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12, 22, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 22, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 6, 6, 128)    0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 6, 6, 128)    0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 6, 6, 128)    0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 6, 768)       0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 6, 768)       0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 32)           76896       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 32)           76896       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           gru_1[0][0]                      \n",
      "                                                                 gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           3250        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 532,658\n",
      "Trainable params: 531,762\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.2592\n",
      "AUCs: 0.7055375807072997\n",
      "Epoch 2/35\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.2128\n",
      "AUCs: 0.7513623016688454\n",
      "Epoch 3/35\n",
      "15244/15244 [==============================] - 259s 17ms/step - loss: 0.2037\n",
      "AUCs: 0.759924606148707\n",
      "Epoch 4/35\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1986\n",
      "AUCs: 0.8011148705765591\n",
      "Epoch 5/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1946\n",
      "AUCs: 0.805471255718278\n",
      "Epoch 6/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1908\n",
      "AUCs: 0.8076738558167671\n",
      "Epoch 7/35\n",
      "15244/15244 [==============================] - 258s 17ms/step - loss: 0.1878\n",
      "AUCs: 0.7969122545322938\n",
      "Epoch 8/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1857\n",
      "AUCs: 0.8055219048680733\n",
      "Epoch 9/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1827\n",
      "AUCs: 0.8311059596542789\n",
      "Epoch 10/35\n",
      "15244/15244 [==============================] - 255s 17ms/step - loss: 0.1815\n",
      "AUCs: 0.8230496298939077\n",
      "Epoch 11/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1801\n",
      "AUCs: 0.8471392881313465\n",
      "Epoch 12/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1783\n",
      "AUCs: 0.8491081688996447\n",
      "Epoch 13/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1774\n",
      "AUCs: 0.7861288627176926\n",
      "Epoch 14/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1758\n",
      "AUCs: 0.8457131674222983\n",
      "Epoch 15/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1750\n",
      "AUCs: 0.844371748970448\n",
      "Epoch 16/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1751\n",
      "AUCs: 0.8549068733620342\n",
      "Epoch 17/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1737\n",
      "AUCs: 0.8580771016153304\n",
      "Epoch 18/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1734\n",
      "AUCs: 0.859729866185519\n",
      "Epoch 19/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1719\n",
      "AUCs: 0.8460926155972888\n",
      "Epoch 20/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1719\n",
      "AUCs: 0.8481241563557692\n",
      "Epoch 21/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1708\n",
      "AUCs: 0.8547975005269676\n",
      "Epoch 22/35\n",
      "15244/15244 [==============================] - 255s 17ms/step - loss: 0.1698\n",
      "AUCs: 0.8383374550971203\n",
      "Epoch 23/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1700\n",
      "AUCs: 0.8558463765366376\n",
      "Epoch 24/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1690\n",
      "AUCs: 0.8666794798939668\n",
      "Epoch 25/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1681\n",
      "AUCs: 0.8679855606641447\n",
      "Epoch 26/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1675\n",
      "AUCs: 0.8528587183741766\n",
      "Epoch 27/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1668\n",
      "AUCs: 0.8705031036322198\n",
      "Epoch 28/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1666\n",
      "AUCs: 0.8645730961954027\n",
      "Epoch 29/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1655\n",
      "AUCs: 0.8481389423617748\n",
      "Epoch 30/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1652\n",
      "AUCs: 0.8633352979337963\n",
      "Epoch 31/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1651\n",
      "AUCs: 0.8675319860840952\n",
      "Epoch 32/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1641\n",
      "AUCs: 0.8588704367510445\n",
      "Epoch 33/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1643\n",
      "AUCs: 0.8648348081593003\n",
      "Epoch 34/35\n",
      "15244/15244 [==============================] - 256s 17ms/step - loss: 0.1632\n",
      "AUCs: 0.867955845832452\n",
      "Epoch 35/35\n",
      "15244/15244 [==============================] - 257s 17ms/step - loss: 0.1626\n",
      "AUCs: 0.8678945089772094\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1})(pool4)\n",
    "gru6_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(gru5_in_perm)\n",
    "gru7_in_perm = Lambda(K.reverse,arguments={'axes':2})(gru5_in_perm)\n",
    "gru7_in = Reshape((6, 128*6))(gru7_in_perm)\n",
    "gru7 = GRU(32)(gru7_in)\n",
    "\n",
    "gru8_in_perm = Lambda(K.reverse,arguments={'axes':1})(gru6_in_perm)\n",
    "gru8_in = Reshape((6, 128*6))(gru8_in_perm)\n",
    "gru8 = GRU(32)(gru8_in)\n",
    "\n",
    "gru = Concatenate()([gru7,gru8])\n",
    "gru_dropout = Dropout(0.2)(gru)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"AUCs:\",auc)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn78_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn78_losses(train).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 1360, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 1360, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 1360, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 48, 340, 64)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 48, 340, 128) 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 48, 340, 128) 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 340, 128) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 85, 128)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 24, 85, 128)  147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 85, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 85, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 22, 128)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 12, 22, 128)  147584      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12, 22, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 22, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 6, 6, 128)    0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 6, 768)       0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 6, 768)       0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 6, 768)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 6, 768)       0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 32)           76896       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 32)           76896       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, 32)           76896       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     (None, 32)           76896       reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128)          0           gru_1[0][0]                      \n",
      "                                                                 gru_2[0][0]                      \n",
      "                                                                 gru_3[0][0]                      \n",
      "                                                                 gru_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           3250        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 690,546\n",
      "Trainable params: 689,650\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/35\n",
      "15244/15244 [==============================] - 281s 18ms/step - loss: 0.2328\n",
      "AUCs: 0.7407933079101447\n",
      "Epoch 2/35\n",
      "15244/15244 [==============================] - 267s 18ms/step - loss: 0.1961\n",
      "AUCs: 0.7771475431087917\n",
      "Epoch 3/35\n",
      "15244/15244 [==============================] - 267s 18ms/step - loss: 0.1830\n",
      "AUCs: 0.8058958957681875\n",
      "Epoch 4/35\n",
      "15244/15244 [==============================] - 267s 18ms/step - loss: 0.1766\n",
      "AUCs: 0.8436376903115194\n",
      "Epoch 5/35\n",
      "15244/15244 [==============================] - 267s 18ms/step - loss: 0.1720\n",
      "AUCs: 0.8397533751377424\n",
      "Epoch 6/35\n",
      "15244/15244 [==============================] - 267s 18ms/step - loss: 0.1687\n",
      "AUCs: 0.776376380832909\n",
      "Epoch 7/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1670\n",
      "AUCs: 0.8658734307958639\n",
      "Epoch 8/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1641\n",
      "AUCs: 0.8550640373268951\n",
      "Epoch 9/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1623\n",
      "AUCs: 0.842944652119976\n",
      "Epoch 10/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1601\n",
      "AUCs: 0.8665366907092321\n",
      "Epoch 11/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1586\n",
      "AUCs: 0.8737894112516774\n",
      "Epoch 12/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1572\n",
      "AUCs: 0.8286199949022989\n",
      "Epoch 13/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1564\n",
      "AUCs: 0.8484567110134239\n",
      "Epoch 14/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1546\n",
      "AUCs: 0.8703626125592077\n",
      "Epoch 15/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1534\n",
      "AUCs: 0.8810317777451013\n",
      "Epoch 16/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1522\n",
      "AUCs: 0.8835924931992274\n",
      "Epoch 17/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1517\n",
      "AUCs: 0.8654162736528336\n",
      "Epoch 18/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1511\n",
      "AUCs: 0.8589358157462149\n",
      "Epoch 19/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1498\n",
      "AUCs: 0.8865545529373652\n",
      "Epoch 20/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1486\n",
      "AUCs: 0.8838230016443521\n",
      "Epoch 21/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1481\n",
      "AUCs: 0.8601840145185404\n",
      "Epoch 22/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1465\n",
      "AUCs: 0.87518796311697\n",
      "Epoch 23/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1468\n",
      "AUCs: 0.8837003077270852\n",
      "Epoch 24/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1451\n",
      "AUCs: 0.8814524615126667\n",
      "Epoch 25/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1445\n",
      "AUCs: 0.8827597075670199\n",
      "Epoch 26/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1441\n",
      "AUCs: 0.8909526468415954\n",
      "Epoch 27/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1429\n",
      "AUCs: 0.8943334299461588\n",
      "Epoch 28/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1418\n",
      "AUCs: 0.8817195383365255\n",
      "Epoch 29/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1410\n",
      "AUCs: 0.8952426455986453\n",
      "Epoch 30/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1408\n",
      "AUCs: 0.8820179085887319\n",
      "Epoch 31/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1397\n",
      "AUCs: 0.8816030077513085\n",
      "Epoch 32/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1386\n",
      "AUCs: 0.8925797638725049\n",
      "Epoch 33/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1389\n",
      "AUCs: 0.8824300839247424\n",
      "Epoch 34/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1380\n",
      "AUCs: 0.8745270688560379\n",
      "Epoch 35/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1369\n",
      "AUCs: 0.8951418098397016\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru1_in = Reshape((6, 128*6))(pool4)\n",
    "gru1 = GRU(32)(gru1_in)\n",
    "\n",
    "gru3_in_perm = Lambda(K.reverse,arguments={'axes':2})(pool4)\n",
    "gru3_in = Reshape((6, 128*6))(gru3_in_perm)\n",
    "gru3 = GRU(32)(gru3_in)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1})(pool4)\n",
    "gru5_in = Reshape((6, 128*6))(gru5_in_perm)\n",
    "gru5 = GRU(32)(gru5_in)\n",
    "\n",
    "gru7_in_perm = Lambda(K.reverse,arguments={'axes':2})(gru5_in_perm)\n",
    "gru7_in = Reshape((6, 128*6))(gru7_in_perm)\n",
    "gru7 = GRU(32)(gru7_in)\n",
    "\n",
    "gru = Concatenate()([gru1,gru3,gru5,gru7])\n",
    "gru_dropout = Dropout(0.3)(gru)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"AUCs:\",auc)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn1357_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn1357_losses(train).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 1360, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 1360, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 1360, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 48, 340, 64)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 48, 340, 128) 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 48, 340, 128) 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 340, 128) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 85, 128)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 24, 85, 128)  147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 85, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 85, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 22, 128)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 12, 22, 128)  147584      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12, 22, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 22, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 6, 6, 128)    0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 6, 6, 128)    0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 6, 128)    0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 6, 768)       0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 6, 768)       0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 6, 768)       0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 6, 768)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 32)           76896       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 32)           76896       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, 32)           76896       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     (None, 32)           76896       reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128)          0           gru_1[0][0]                      \n",
      "                                                                 gru_2[0][0]                      \n",
      "                                                                 gru_3[0][0]                      \n",
      "                                                                 gru_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           3250        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 690,546\n",
      "Trainable params: 689,650\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/35\n",
      "15244/15244 [==============================] - 284s 19ms/step - loss: 0.2315\n",
      "AUCs: 0.7257094676316024\n",
      "Epoch 2/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1951\n",
      "AUCs: 0.7812970191852657\n",
      "Epoch 3/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1817\n",
      "AUCs: 0.812169895925215\n",
      "Epoch 4/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1747\n",
      "AUCs: 0.8420107144115271\n",
      "Epoch 5/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1696\n",
      "AUCs: 0.8175291394246333\n",
      "Epoch 6/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1654\n",
      "AUCs: 0.8621410246720008\n",
      "Epoch 7/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1632\n",
      "AUCs: 0.8688240989308561\n",
      "Epoch 8/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1608\n",
      "AUCs: 0.8613025885113765\n",
      "Epoch 9/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1589\n",
      "AUCs: 0.8792835114356494\n",
      "Epoch 10/35\n",
      "15244/15244 [==============================] - 270s 18ms/step - loss: 0.1568\n",
      "AUCs: 0.8552889326651504\n",
      "Epoch 11/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1557\n",
      "AUCs: 0.8839530463933497\n",
      "Epoch 12/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1537\n",
      "AUCs: 0.8787057687230622\n",
      "Epoch 13/35\n",
      "15244/15244 [==============================] - 267s 18ms/step - loss: 0.1526\n",
      "AUCs: 0.8541476754927563\n",
      "Epoch 14/35\n",
      "15244/15244 [==============================] - 267s 18ms/step - loss: 0.1510\n",
      "AUCs: 0.8590266283693364\n",
      "Epoch 15/35\n",
      "15244/15244 [==============================] - 267s 18ms/step - loss: 0.1504\n",
      "AUCs: 0.8855135911540841\n",
      "Epoch 16/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1489\n",
      "AUCs: 0.8822984590444277\n",
      "Epoch 17/35\n",
      "15244/15244 [==============================] - 267s 18ms/step - loss: 0.1477\n",
      "AUCs: 0.8902263403696267\n",
      "Epoch 18/35\n",
      "15244/15244 [==============================] - 267s 18ms/step - loss: 0.1466\n",
      "AUCs: 0.8911358336794217\n",
      "Epoch 19/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1458\n",
      "AUCs: 0.894658917340828\n",
      "Epoch 20/35\n",
      "15244/15244 [==============================] - 267s 18ms/step - loss: 0.1452\n",
      "AUCs: 0.8715168150534361\n",
      "Epoch 21/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1440\n",
      "AUCs: 0.8928837094034988\n",
      "Epoch 22/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1433\n",
      "AUCs: 0.8919617126632712\n",
      "Epoch 23/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1420\n",
      "AUCs: 0.8873084790451796\n",
      "Epoch 24/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1410\n",
      "AUCs: 0.8831711472872967\n",
      "Epoch 25/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1399\n",
      "AUCs: 0.8937208264932908\n",
      "Epoch 26/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1393\n",
      "AUCs: 0.9014170952161134\n",
      "Epoch 27/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1379\n",
      "AUCs: 0.8978697224333446\n",
      "Epoch 28/35\n",
      "15244/15244 [==============================] - 267s 18ms/step - loss: 0.1375\n",
      "AUCs: 0.9031653302546401\n",
      "Epoch 29/35\n",
      "15244/15244 [==============================] - 268s 18ms/step - loss: 0.1368\n",
      "AUCs: 0.90173787770618\n",
      "Epoch 30/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1354\n",
      "AUCs: 0.8870045296566338\n",
      "Epoch 31/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1349\n",
      "AUCs: 0.8983924380042432\n",
      "Epoch 32/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1335\n",
      "AUCs: 0.9009804559508509\n",
      "Epoch 33/35\n",
      "15244/15244 [==============================] - 270s 18ms/step - loss: 0.1331\n",
      "AUCs: 0.8998309127976334\n",
      "Epoch 34/35\n",
      "15244/15244 [==============================] - 269s 18ms/step - loss: 0.1322\n",
      "AUCs: 0.9022659615078537\n",
      "Epoch 35/35\n",
      "15244/15244 [==============================] - 270s 18ms/step - loss: 0.1314\n",
      "AUCs: 0.8980052789815289\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 35\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru2_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(pool4)\n",
    "gru2_in = Reshape((6, 128*6))(gru2_in_perm)\n",
    "gru2 = GRU(32)(gru2_in)\n",
    "\n",
    "gru3_in_perm = Lambda(K.reverse,arguments={'axes':2})(pool4)\n",
    "gru4_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(gru3_in_perm)\n",
    "gru4_in = Reshape((6, 128*6))(gru4_in_perm)\n",
    "gru4 = GRU(32)(gru4_in)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1})(pool4)\n",
    "gru6_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(gru5_in_perm)\n",
    "gru6_in = Reshape((6, 128*6))(gru6_in_perm)\n",
    "gru6 = GRU(32)(gru6_in)\n",
    "\n",
    "gru8_in_perm = Lambda(K.reverse,arguments={'axes':1})(gru6_in_perm)\n",
    "gru8_in = Reshape((6, 128*6))(gru8_in_perm)\n",
    "gru8 = GRU(32)(gru8_in)\n",
    "\n",
    "gru = Concatenate()([gru2,gru4,gru6,gru8])\n",
    "gru_dropout = Dropout(0.3)(gru)\n",
    "fc = Dense(64, activation='elu')(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"AUCs:\",auc)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "pickle.dump(histories.aucs,open(os.path.join(save_path,'cGrnn2468_aucs(test).pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(save_path,'cGrnn2468_losses(train).pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8952426455986453 29\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "save_path = 'C:/DT/Diff_directions'\n",
    "cGrnn_5 = pickle.load(open(os.path.join(save_path,'cGrnn1357_aucs(test).pkl'),'rb'))\n",
    "\n",
    "max_auc = 0\n",
    "idx = -1\n",
    "for i in range(len(cGrnn_5)):\n",
    "    if max_auc < cGrnn_5[i]:\n",
    "        max_auc = cGrnn_5[i]\n",
    "        idx = i\n",
    "print(max_auc,idx+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
