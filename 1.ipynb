{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Table 1, 2 and figure 6 are based on the below result \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some useful functions for metrics calculation\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x,1)[:,np.newaxis])\n",
    "    return e_x/e_x.sum(1)[:,np.newaxis]\n",
    "\n",
    "def recall(label_true,label_pred,k):  # Recall@k\n",
    "    '''the previous two inputs are 2 dimensional array\n",
    "    '''\n",
    "    idx = np.argpartition(label_pred, -k, 1)[:,-k:]\n",
    "    r = label_true[np.repeat(np.arange(label_true.shape[0]),k),idx.flatten()].reshape(-1,k)\n",
    "    recall = (np.sum(r,1)/np.sum(label_true,1)).mean()\n",
    "    return recall\n",
    "\n",
    "def dcg_score(y_true, y_score, k, gains=\"exponential\"):\n",
    "\n",
    "    order = np.argsort(y_score,axis = 1)[:,::-1][:,:k]\n",
    "    \n",
    "    y_t = y_true[np.repeat(np.arange(y_true.shape[0]),k),order.flatten()].reshape(-1,k)\n",
    "\n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_t - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_t\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")\n",
    "    discounts = np.log2(np.arange(len(y_t[0,:])) + 2)[np.newaxis,:]\n",
    "    dcg = np.sum(gains / discounts,1)\n",
    "    return dcg\n",
    "\n",
    "def ndcg_score(y_true, y_score, k, gains=\"exponential\"): # Normalized Discounted Cummulative Gain\n",
    "   \n",
    "    best = dcg_score(y_true, y_true, k, gains)\n",
    "    actual = dcg_score(y_true, y_score, k, gains)\n",
    "    return (actual / best).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 1360, 128)     1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1360, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 1360, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 340, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 340, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 340, 384)      442752    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 340, 384)      1536      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 340, 384)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 85, 384)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 85, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 85, 768)       2654976   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 85, 768)       3072      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 85, 768)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 22, 768)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 22, 768)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 8, 2048)        14157824  \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 8, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 8, 2048)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                102450    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 17,372,594\n",
      "Trainable params: 17,365,938\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n",
      "Train on 15244 samples, validate on 1529 samples\n",
      "Epoch 1/30\n",
      "15244/15244 [==============================] - 752s 49ms/step - loss: 0.2733 - val_loss: 0.1997\n",
      "Average AUC: 0.7846587448914991\n",
      "Recalls: 0.16105459957606774 0.3427475225605419 0.4560411310757571 0.6121890331377866\n",
      "NDCG: 0.6159693421858493\n",
      "AUCs: [0.81112178 0.86735406 0.67587183 0.92064985 0.76539149 0.82558495\n",
      " 0.80572631 0.9674988  0.80372239 0.87506614 0.84518777 0.91904784\n",
      " 0.7846096  0.68693838 0.70054821 0.73942442 0.71032644 0.93477176\n",
      " 0.75711577 0.65406599 0.67345504 0.58791789 0.92815957 0.89828419\n",
      " 0.87278542 0.8476937  0.72848962 0.75586793 0.55833962 0.82053177\n",
      " 0.79222941 0.64894776 0.83058657 0.7182326  0.79841092 0.96786176\n",
      " 0.53479445 0.75172472 0.9033981  0.64866244 0.72858941 0.8854617\n",
      " 0.8699239  0.8682282  0.54539766 0.64920748 0.73912617 0.67808524\n",
      " 0.97500854 0.97751172]\n",
      "Epoch 2/30\n",
      "15244/15244 [==============================] - 744s 49ms/step - loss: 0.2058 - val_loss: 0.1824\n",
      "Average AUC: 0.8447549603256581\n",
      "Recalls: 0.20364637862906562 0.39794860930595005 0.5233219246896532 0.7166689407340376\n",
      "NDCG: 0.6740284732372981\n",
      "AUCs: [0.81287359 0.88857229 0.813457   0.9336957  0.80678048 0.84022902\n",
      " 0.8281045  0.97825144 0.84513311 0.93467926 0.93038116 0.92219099\n",
      " 0.88010526 0.81552742 0.78083231 0.85669065 0.79740619 0.97045927\n",
      " 0.82914693 0.82410751 0.75070484 0.63682458 0.96259644 0.90671298\n",
      " 0.88189255 0.90540457 0.8473345  0.8333302  0.61538723 0.88578509\n",
      " 0.82190826 0.84047884 0.87963654 0.81380881 0.83238017 0.96597619\n",
      " 0.68601886 0.86416077 0.92928227 0.78767377 0.81258389 0.89565868\n",
      " 0.90015416 0.83217764 0.61132058 0.64905302 0.86727441 0.77735381\n",
      " 0.97970344 0.97654684]\n",
      "Epoch 3/30\n",
      "15244/15244 [==============================] - 745s 49ms/step - loss: 0.1816 - val_loss: 0.1732\n",
      "Average AUC: 0.8610236053288061\n",
      "Recalls: 0.22204281496179004 0.44085137571979677 0.5899118553550687 0.7700485898373709\n",
      "NDCG: 0.7123105096728836\n",
      "AUCs: [0.80933262 0.88757326 0.82885872 0.94085758 0.8100868  0.85557546\n",
      " 0.84286124 0.97854177 0.85887544 0.92186564 0.93168149 0.92428084\n",
      " 0.88688431 0.84099587 0.80099647 0.88513888 0.79051738 0.97861797\n",
      " 0.88738603 0.85544098 0.82563348 0.66052741 0.96867413 0.91288206\n",
      " 0.90420326 0.92597033 0.88035996 0.88363343 0.59591636 0.90385811\n",
      " 0.82819596 0.77288277 0.82167031 0.88841412 0.85222859 0.97289981\n",
      " 0.79471915 0.85933705 0.93745572 0.8284802  0.85141269 0.90014118\n",
      " 0.88764509 0.90431354 0.63763046 0.65127169 0.87599692 0.84767835\n",
      " 0.98144876 0.97933062]\n",
      "Epoch 4/30\n",
      "15244/15244 [==============================] - 741s 49ms/step - loss: 0.1700 - val_loss: 0.1584\n",
      "Average AUC: 0.871701148577547\n",
      "Recalls: 0.24271270306588869 0.46415006969023587 0.5911207245867911 0.7653256728395232\n",
      "NDCG: 0.7252971577865153\n",
      "AUCs: [0.84976553 0.88010949 0.82316827 0.94596163 0.83269871 0.86556299\n",
      " 0.85960021 0.9805501  0.86550204 0.93785939 0.93624575 0.93111311\n",
      " 0.89813592 0.85295261 0.82329176 0.90150273 0.82528901 0.98231132\n",
      " 0.88694467 0.85958276 0.82101655 0.64936608 0.97511197 0.91736177\n",
      " 0.90067849 0.92834473 0.89630305 0.8883807  0.66752466 0.90227297\n",
      " 0.83196071 0.89082418 0.86343776 0.89041202 0.86263511 0.97616908\n",
      " 0.79129887 0.85319557 0.93955773 0.82946536 0.88760636 0.90659518\n",
      " 0.90948013 0.88857839 0.60860719 0.63505418 0.90229392 0.86878749\n",
      " 0.98241304 0.98217618]\n",
      "Epoch 5/30\n",
      "15244/15244 [==============================] - 739s 48ms/step - loss: 0.1634 - val_loss: 0.1551\n",
      "Average AUC: 0.8734219551422379\n",
      "Recalls: 0.2630805085444975 0.49917345594284657 0.6390088020628186 0.8042278256267177\n",
      "NDCG: 0.7537415963251427\n",
      "AUCs: [0.84796826 0.88881565 0.82980419 0.95364928 0.83285081 0.87149426\n",
      " 0.87203572 0.98138157 0.8654686  0.94268389 0.94464561 0.93147101\n",
      " 0.90095225 0.83041125 0.81169718 0.89667389 0.84350345 0.98276638\n",
      " 0.89127819 0.85564713 0.81275808 0.61283213 0.97944898 0.91784097\n",
      " 0.89011406 0.93261095 0.90606308 0.89738792 0.59457906 0.92127364\n",
      " 0.83675382 0.86658323 0.8745017  0.90161932 0.85726498 0.97657598\n",
      " 0.80213116 0.87281342 0.94806432 0.84750399 0.88385666 0.90989949\n",
      " 0.91148544 0.91011132 0.61716859 0.66763457 0.90558345 0.87879453\n",
      " 0.98337006 0.97927429]\n",
      "Epoch 6/30\n",
      "15244/15244 [==============================] - 739s 48ms/step - loss: 0.1586 - val_loss: 0.1562\n",
      "Average AUC: 0.8744543256099925\n",
      "Recalls: 0.24633890206951153 0.48304896985644913 0.6067224173179852 0.7629940862974103\n",
      "NDCG: 0.7318417811488155\n",
      "AUCs: [0.87225522 0.90072917 0.82835009 0.94153158 0.84151428 0.87587859\n",
      " 0.84832781 0.98287511 0.86926497 0.94588619 0.93651781 0.9292208\n",
      " 0.87986564 0.82973699 0.81321839 0.88336917 0.83694913 0.97951117\n",
      " 0.88517736 0.85107501 0.8117783  0.67816821 0.98005816 0.91661275\n",
      " 0.90391694 0.93485508 0.87926559 0.88801052 0.66650627 0.91719237\n",
      " 0.83354727 0.90685811 0.88239159 0.89750174 0.85143189 0.97059322\n",
      " 0.7860281  0.86127493 0.94544775 0.839317   0.88129045 0.89093919\n",
      " 0.92520785 0.9083256  0.6543402  0.66689683 0.90357474 0.84619635\n",
      " 0.98395183 0.97998296]\n",
      "Epoch 7/30\n",
      "15244/15244 [==============================] - 739s 49ms/step - loss: 0.1554 - val_loss: 0.1552\n",
      "Average AUC: 0.8798016982589462\n",
      "Recalls: 0.2629384401891327 0.5056273648378911 0.6339414894124035 0.8015160745943294\n",
      "NDCG: 0.7556381990341858\n",
      "AUCs: [0.86602785 0.89366115 0.82935045 0.95432508 0.85407445 0.88215063\n",
      " 0.8833436  0.98269818 0.86374509 0.95223981 0.93826187 0.92958016\n",
      " 0.92514549 0.8451246  0.8364015  0.905084   0.83655383 0.97744373\n",
      " 0.88258507 0.84332215 0.8159303  0.67651388 0.97659723 0.91359408\n",
      " 0.89892302 0.94716375 0.90464118 0.88855855 0.66068966 0.92366306\n",
      " 0.83659153 0.8793121  0.88109093 0.89417309 0.8517032  0.98173468\n",
      " 0.76025245 0.86609704 0.94776559 0.84606518 0.89517318 0.90089583\n",
      " 0.92296732 0.93101809 0.67017274 0.68969947 0.92029536 0.85878743\n",
      " 0.98422526 0.98467104]\n",
      "Epoch 8/30\n",
      "15244/15244 [==============================] - 738s 48ms/step - loss: 0.1522 - val_loss: 0.1641\n",
      "Average AUC: 0.8857472819304992\n",
      "Recalls: 0.23241338852488433 0.46669186973896115 0.5973030995884182 0.7775692112084079\n",
      "NDCG: 0.7267243564363914\n",
      "AUCs: [0.87172627 0.89939149 0.82518026 0.95684732 0.85374188 0.88381387\n",
      " 0.87786915 0.98302098 0.87355468 0.94607511 0.94364694 0.93162263\n",
      " 0.89267954 0.86692091 0.832483   0.90825008 0.849621   0.98066712\n",
      " 0.89924503 0.87275414 0.84548201 0.66129939 0.98258042 0.91729499\n",
      " 0.89776982 0.94425053 0.90819764 0.90282927 0.70267462 0.93208957\n",
      " 0.83980399 0.88538683 0.8880886  0.90604929 0.8642145  0.98310939\n",
      " 0.8080759  0.87459304 0.9503978  0.84481329 0.90700503 0.9093146\n",
      " 0.92421789 0.93347635 0.66076278 0.67908223 0.92900737 0.88465075\n",
      " 0.98465432 0.9870805 ]\n",
      "Epoch 9/30\n",
      "15244/15244 [==============================] - 737s 48ms/step - loss: 0.1503 - val_loss: 0.1478\n",
      "Average AUC: 0.8867074051114305\n",
      "Recalls: 0.2781705995348655 0.5345808424928924 0.6665653713783908 0.8293746573524967\n",
      "NDCG: 0.779259781557691\n",
      "AUCs: [0.87790768 0.90194557 0.83112265 0.94807746 0.86601137 0.88114558\n",
      " 0.86375414 0.98286852 0.87702198 0.94595101 0.94451537 0.93138718\n",
      " 0.9137424  0.86580069 0.82922175 0.91123879 0.82137052 0.98146416\n",
      " 0.91363953 0.8759626  0.8521478  0.65038075 0.98001857 0.91871182\n",
      " 0.902899   0.94846049 0.91549216 0.914555   0.6938821  0.92274035\n",
      " 0.84378562 0.89085663 0.88104119 0.92028874 0.86755308 0.98338921\n",
      " 0.81847793 0.86017518 0.94439205 0.87313968 0.88923029 0.90188242\n",
      " 0.91905146 0.94559369 0.66783354 0.68496777 0.91460167 0.89536588\n",
      " 0.98515464 0.98515257]\n",
      "Epoch 10/30\n",
      "15244/15244 [==============================] - 739s 48ms/step - loss: 0.1476 - val_loss: 0.1558\n",
      "Average AUC: 0.8805701127579459\n",
      "Recalls: 0.24815927890720132 0.484808447169943 0.6120824447174862 0.7666847708052694\n",
      "NDCG: 0.7350669083313386\n",
      "AUCs: [0.88571065 0.88146883 0.83258854 0.94962408 0.85489426 0.88177431\n",
      " 0.87479187 0.98164272 0.87709674 0.93316288 0.93902322 0.93301416\n",
      " 0.89164083 0.85216863 0.81662199 0.90515109 0.81725299 0.97953487\n",
      " 0.89476625 0.85684033 0.82260923 0.66910263 0.9775972  0.91644579\n",
      " 0.90622532 0.93254285 0.90403297 0.89613422 0.68594756 0.91781594\n",
      " 0.84201022 0.89213369 0.85412663 0.90257768 0.85445502 0.97953206\n",
      " 0.79555111 0.86592909 0.95015382 0.84922316 0.90239094 0.91595516\n",
      " 0.92070309 0.91258117 0.65223614 0.70288245 0.92257003 0.87938494\n",
      " 0.98427762 0.98260865]\n",
      "Epoch 11/30\n",
      "15244/15244 [==============================] - 738s 48ms/step - loss: 0.1460 - val_loss: 0.1520\n",
      "Average AUC: 0.8872926526252144\n",
      "Recalls: 0.2699438840886209 0.523807445119772 0.64535449994245 0.7923304899932323\n",
      "NDCG: 0.7616433825562308\n",
      "AUCs: [0.88565445 0.90218656 0.8338324  0.95753588 0.88016025 0.87851691\n",
      " 0.8937685  0.98016095 0.88153308 0.94750894 0.94910357 0.93231949\n",
      " 0.92007123 0.84798917 0.83888586 0.90411876 0.86124795 0.9824691\n",
      " 0.89309625 0.85222791 0.83416776 0.66791569 0.98376173 0.91800792\n",
      " 0.90382808 0.9477307  0.90702712 0.89991266 0.68720562 0.92626712\n",
      " 0.84210661 0.91906782 0.88841339 0.91044573 0.86582404 0.98473312\n",
      " 0.78991059 0.86562064 0.95772983 0.85741794 0.90292725 0.90632626\n",
      " 0.92534661 0.92286642 0.64694432 0.70719621 0.93202219 0.86944372\n",
      " 0.98552843 0.98654991]\n",
      "Epoch 12/30\n",
      "15244/15244 [==============================] - 739s 48ms/step - loss: 0.1444 - val_loss: 0.1536\n",
      "Average AUC: 0.8864458766363177\n",
      "Recalls: 0.27488918693904846 0.5008482828600557 0.6314802784678131 0.7925645607086049\n",
      "NDCG: 0.758886612126698\n",
      "AUCs: [0.8871841  0.90291309 0.83197945 0.95674924 0.87655036 0.88618709\n",
      " 0.8852194  0.9808409  0.88405451 0.94795604 0.94704086 0.93354992\n",
      " 0.91878763 0.84376311 0.84567716 0.90354646 0.86545947 0.98267429\n",
      " 0.89469548 0.84021026 0.83207688 0.65754932 0.98000708 0.9208858\n",
      " 0.90698754 0.94607129 0.91192495 0.90193564 0.66165585 0.92057667\n",
      " 0.83714825 0.91829138 0.891234   0.8945649  0.86448904 0.9849218\n",
      " 0.79100642 0.87095628 0.94877906 0.84115689 0.90625899 0.90654812\n",
      " 0.92609459 0.9580821  0.64154821 0.70690548 0.93977008 0.86970701\n",
      " 0.98424562 0.98587577]\n",
      "Epoch 13/30\n",
      "15244/15244 [==============================] - 740s 49ms/step - loss: 0.1424 - val_loss: 0.1406\n",
      "Average AUC: 0.8961123639140323\n",
      "Recalls: 0.2858609777931108 0.5538043315051626 0.6921565456191495 0.8537120575382349\n",
      "NDCG: 0.7932239243606535\n",
      "AUCs: [0.89300517 0.91288684 0.84141767 0.95753073 0.88211311 0.8907573\n",
      " 0.89573049 0.98408255 0.87917328 0.95365037 0.95011304 0.92975584\n",
      " 0.91954766 0.87099065 0.85627641 0.91544717 0.85028445 0.98035968\n",
      " 0.91838369 0.88142395 0.84636809 0.69096238 0.98250507 0.92083255\n",
      " 0.91285425 0.95178524 0.91304178 0.91044254 0.69315494 0.92906362\n",
      " 0.84293382 0.92447736 0.89571926 0.92023756 0.85226734 0.98617201\n",
      " 0.81298195 0.89045301 0.95303314 0.8775515  0.90924017 0.91746781\n",
      " 0.93257419 0.959891   0.6497487  0.75995356 0.93130829 0.90204788\n",
      " 0.98531027 0.98830885]\n",
      "Epoch 14/30\n",
      "15244/15244 [==============================] - 740s 49ms/step - loss: 0.1406 - val_loss: 0.1476\n",
      "Average AUC: 0.8926375766803225\n",
      "Recalls: 0.28542484626279646 0.5343160174185105 0.6653491271219802 0.8154919225383214\n",
      "NDCG: 0.7791928306974021\n",
      "AUCs: [0.87929551 0.91035599 0.83850594 0.96109599 0.88088983 0.89641788\n",
      " 0.89858335 0.98336166 0.88735992 0.95171625 0.9517418  0.92977625\n",
      " 0.91640092 0.85227717 0.8501522  0.90561943 0.86540971 0.97944548\n",
      " 0.91236107 0.87168018 0.84582436 0.68712343 0.98338691 0.9179258\n",
      " 0.90312016 0.93268496 0.90853933 0.90804649 0.67888864 0.93140247\n",
      " 0.84545579 0.92560608 0.88945256 0.91437447 0.8628612  0.98654938\n",
      " 0.80830952 0.87607068 0.9533131  0.84629103 0.89010067 0.91079028\n",
      " 0.92758207 0.96318414 0.66428793 0.76465981 0.93766338 0.87226013\n",
      " 0.98581204 0.98786548]\n",
      "Epoch 15/30\n",
      "15244/15244 [==============================] - 739s 48ms/step - loss: 0.1393 - val_loss: 0.1392\n",
      "Average AUC: 0.89888347105623\n",
      "Recalls: 0.3097417606247246 0.5700890291610513 0.6991133898162984 0.8550305758927642\n",
      "NDCG: 0.8099328359226097\n",
      "AUCs: [0.89780669 0.91136959 0.84092505 0.96162355 0.889824   0.89484657\n",
      " 0.90010543 0.98457334 0.88833185 0.95741002 0.95398159 0.93277434\n",
      " 0.92005962 0.86294969 0.86158663 0.91847507 0.8927286  0.9820269\n",
      " 0.91813694 0.87357788 0.84712372 0.68713542 0.98434281 0.92264826\n",
      " 0.91263309 0.95594487 0.91718888 0.91288919 0.69067406 0.93406204\n",
      " 0.84247448 0.94882724 0.89854063 0.92782499 0.86698678 0.98485763\n",
      " 0.80113449 0.88666849 0.95591872 0.87422024 0.90450174 0.90805741\n",
      " 0.94185277 0.96599026 0.66760657 0.76737636 0.93250162 0.88829493\n",
      " 0.98526227 0.98752024]\n",
      "Epoch 16/30\n",
      "15244/15244 [==============================] - 742s 49ms/step - loss: 0.1380 - val_loss: 0.1419\n",
      "Average AUC: 0.8968354639628525\n",
      "Recalls: 0.2944956026327217 0.5579116616685869 0.6905152262839244 0.8533744219512918\n",
      "NDCG: 0.7991357932813234\n",
      "AUCs: [0.8964744  0.90697221 0.83773605 0.95878334 0.87363783 0.89643362\n",
      " 0.89055247 0.98478838 0.88485533 0.9534548  0.95151478 0.93109853\n",
      " 0.91028373 0.86382039 0.84938213 0.91367746 0.87690949 0.98013892\n",
      " 0.92199465 0.87650924 0.85113563 0.6548309  0.98370427 0.92255351\n",
      " 0.91091909 0.94106048 0.91372271 0.91803701 0.6901721  0.94113779\n",
      " 0.84341874 0.92832939 0.88936364 0.93580247 0.86377848 0.98359458\n",
      " 0.82772866 0.88416781 0.95331622 0.8791558  0.90509797 0.91365928\n",
      " 0.93622775 0.9682282  0.67270722 0.75559073 0.94233172 0.90248072\n",
      " 0.98558806 0.98491453]\n",
      "Epoch 17/30\n",
      "15244/15244 [==============================] - 742s 49ms/step - loss: 0.1368 - val_loss: 0.1434\n",
      "Average AUC: 0.8961623314552124\n",
      "Recalls: 0.2958468259195406 0.5499720501105543 0.6810035135173639 0.8396516674563765\n",
      "NDCG: 0.7939801853410186\n",
      "AUCs: [0.89829629 0.90861429 0.83822797 0.9582045  0.88226263 0.89803642\n",
      " 0.89588554 0.98322708 0.88390867 0.95160655 0.95144065 0.93483065\n",
      " 0.91372498 0.85754854 0.85050959 0.91392126 0.89437755 0.98013011\n",
      " 0.91279592 0.86947347 0.85212065 0.6802245  0.98259958 0.92295329\n",
      " 0.90853764 0.94914883 0.91277234 0.91421085 0.68782458 0.9326274\n",
      " 0.84452923 0.93930608 0.89389713 0.92077763 0.86187072 0.98548144\n",
      " 0.81468453 0.88037278 0.9564145  0.86597874 0.8998472  0.90760698\n",
      " 0.9405819  0.96044759 0.66528578 0.76214678 0.94430894 0.87195894\n",
      " 0.98489721 0.98768014]\n",
      "Epoch 18/30\n",
      "15244/15244 [==============================] - 741s 49ms/step - loss: 0.1355 - val_loss: 0.1471\n",
      "Average AUC: 0.8939140396836432\n",
      "Recalls: 0.28158485353776214 0.535913969968679 0.6697231861705546 0.8431892412501831\n",
      "NDCG: 0.7825371325519229\n",
      "AUCs: [0.8906735  0.90429685 0.8375654  0.95471156 0.86814147 0.8941734\n",
      " 0.89158471 0.98427454 0.88315735 0.94881534 0.95011459 0.93023766\n",
      " 0.91322779 0.86360684 0.84886345 0.90901204 0.8891128  0.98193955\n",
      " 0.91366095 0.87114194 0.84508362 0.68329247 0.97555895 0.92333863\n",
      " 0.90628851 0.93324896 0.91154519 0.90737265 0.6847738  0.93583468\n",
      " 0.8421253  0.9349117  0.88173147 0.91990575 0.86282245 0.98478831\n",
      " 0.83070187 0.86559965 0.95048226 0.86012616 0.89850342 0.91515177\n",
      " 0.92926585 0.96356679 0.64957592 0.75376637 0.9522493  0.89427283\n",
      " 0.98561715 0.98588849]\n",
      "Epoch 19/30\n",
      "15244/15244 [==============================] - 737s 48ms/step - loss: 0.1345 - val_loss: 0.1436\n",
      "Average AUC: 0.8967005789660104\n",
      "Recalls: 0.29852614682947093 0.5575592721887735 0.6865866474245975 0.8443206557472486\n",
      "NDCG: 0.7985333810744724\n",
      "AUCs: [0.88760792 0.90067758 0.84295394 0.95663012 0.88404534 0.89466526\n",
      " 0.8906476  0.98497755 0.88281881 0.95579557 0.95309463 0.92989798\n",
      " 0.92849806 0.86237984 0.85128951 0.91838738 0.87974159 0.982012\n",
      " 0.91866955 0.87196903 0.84741266 0.67472174 0.97892027 0.92367524\n",
      " 0.90872228 0.94153122 0.91509873 0.91422676 0.68451968 0.93481699\n",
      " 0.84805743 0.92449822 0.89048194 0.92477519 0.86263511 0.98822702\n",
      " 0.82210831 0.89418506 0.95439538 0.87476928 0.90132281 0.91041211\n",
      " 0.93483165 0.95863868 0.65745845 0.7769724  0.94408847 0.89447429\n",
      " 0.98540626 0.98688607]\n",
      "Epoch 20/30\n",
      "15244/15244 [==============================] - 738s 48ms/step - loss: 0.1333 - val_loss: 0.1370\n",
      "Average AUC: 0.9022723894388792\n",
      "Recalls: 0.3124728290587016 0.5745277325782867 0.7075395006142928 0.8694955071859504\n",
      "NDCG: 0.8144814552710259\n",
      "AUCs: [0.91023398 0.91211778 0.83669029 0.95787467 0.89065219 0.89759763\n",
      " 0.89776712 0.98465286 0.88569353 0.9610018  0.9521181  0.93028723\n",
      " 0.92905648 0.87360864 0.8663176  0.92110041 0.89941838 0.98271289\n",
      " 0.92258593 0.88766621 0.8627896  0.65944183 0.98703493 0.92726785\n",
      " 0.91239317 0.96627587 0.92173819 0.91922852 0.69504831 0.93885446\n",
      " 0.84961448 0.95208594 0.8969084  0.9312013  0.87252056 0.98640434\n",
      " 0.82004941 0.88608147 0.95579047 0.8910167  0.92034246 0.90268412\n",
      " 0.94332333 0.95749072 0.66803393 0.78356662 0.94781894 0.88851634\n",
      " 0.98508047 0.98586305]\n",
      "Epoch 21/30\n",
      "15244/15244 [==============================] - 738s 48ms/step - loss: 0.1323 - val_loss: 0.1398\n",
      "Average AUC: 0.8998647293483946\n",
      "Recalls: 0.29788381632218197 0.5561362011846777 0.6837928973663047 0.8492608345793942\n",
      "NDCG: 0.7972735775409507\n",
      "AUCs: [0.8936723  0.91060486 0.83886169 0.95693017 0.88937026 0.90212467\n",
      " 0.88935704 0.98466463 0.87648442 0.95672634 0.95391467 0.92945114\n",
      " 0.92127039 0.8678217  0.85570472 0.91808313 0.8946996  0.9822111\n",
      " 0.92377499 0.87949014 0.85249103 0.68055707 0.9807976  0.92546568\n",
      " 0.90972738 0.95115759 0.91901348 0.91792277 0.69883253 0.93732237\n",
      " 0.84626333 0.94279655 0.89746001 0.9321773  0.87295551 0.98780986\n",
      " 0.82915056 0.88870084 0.95325679 0.87837701 0.9043774  0.90843894\n",
      " 0.93821275 0.97261132 0.66926282 0.77057898 0.94437543 0.88641001\n",
      " 0.98520191 0.98631369]\n",
      "Epoch 22/30\n",
      "15244/15244 [==============================] - 738s 48ms/step - loss: 0.1310 - val_loss: 0.1408\n",
      "Average AUC: 0.8996514214358868\n",
      "Recalls: 0.3057333927486282 0.5627389654051703 0.6977954825773385 0.8630489316777405\n",
      "NDCG: 0.8066395301800604\n",
      "AUCs: [0.90267631 0.90833667 0.84000878 0.95577743 0.88705068 0.89496439\n",
      " 0.89186169 0.9844764  0.86833148 0.9578056  0.95618946 0.92515628\n",
      " 0.93122995 0.86818272 0.85803992 0.91870027 0.89037059 0.9823357\n",
      " 0.92310271 0.88025846 0.84973908 0.68201315 0.97849116 0.9257328\n",
      " 0.91118468 0.95343577 0.9208088  0.91952062 0.69889669 0.9374741\n",
      " 0.84601546 0.93686784 0.90160466 0.93205729 0.85759657 0.98806015\n",
      " 0.83640459 0.8898555  0.95192896 0.88423348 0.90493768 0.90799355\n",
      " 0.93349308 0.96575835 0.65136712 0.77901481 0.9410334  0.89980592\n",
      " 0.98515901 0.98723132]\n",
      "Epoch 23/30\n",
      "15244/15244 [==============================] - 738s 48ms/step - loss: 0.1298 - val_loss: 0.1366\n",
      "Average AUC: 0.9014094290306702\n",
      "Recalls: 0.3157236544875049 0.581062835287212 0.7121012522155182 0.8713210522421049\n",
      "NDCG: 0.8186813147856598\n",
      "AUCs: [0.90329138 0.91000907 0.83581625 0.96033959 0.88449585 0.90040659\n",
      " 0.89763152 0.98382751 0.87519922 0.96016909 0.95366243 0.93061452\n",
      " 0.92372888 0.87196753 0.8657285  0.92088351 0.8974377  0.98223209\n",
      " 0.92703491 0.88731102 0.85832239 0.66488967 0.98467486 0.92753137\n",
      " 0.91205057 0.95642005 0.91968612 0.92277704 0.69010668 0.93699424\n",
      " 0.84489218 0.94706809 0.90248031 0.93732207 0.86009646 0.98646467\n",
      " 0.82878248 0.89030121 0.95381045 0.89345625 0.9107053  0.91613163\n",
      " 0.93941763 0.96720779 0.65604552 0.77119225 0.9445784  0.9036017\n",
      " 0.98583386 0.98584307]\n",
      "Epoch 24/30\n",
      "15244/15244 [==============================] - 740s 49ms/step - loss: 0.1290 - val_loss: 0.1378\n",
      "Average AUC: 0.8974016551586097\n",
      "Recalls: 0.3130645862294062 0.5695132942362858 0.6986330196683381 0.8540491460678441\n",
      "NDCG: 0.8105275403774523\n",
      "AUCs: [0.90865077 0.90513206 0.83814493 0.95980128 0.88813217 0.89830508\n",
      " 0.89142546 0.98441335 0.87707832 0.95787873 0.95284496 0.92896495\n",
      " 0.9134368  0.85931353 0.84722336 0.91314967 0.8957003  0.98026623\n",
      " 0.9239575  0.86894279 0.85174153 0.67676855 0.98180139 0.92451451\n",
      " 0.91105435 0.96184386 0.91506847 0.91908826 0.69331597 0.93789351\n",
      " 0.84919546 0.94671348 0.8968677  0.93118718 0.85717885 0.98683177\n",
      " 0.81543749 0.88433334 0.9508107  0.88232935 0.90020524 0.90394803\n",
      " 0.94222507 0.95249304 0.64057081 0.76390936 0.94515931 0.88388481\n",
      " 0.98472995 0.9862192 ]\n",
      "Epoch 25/30\n",
      "15244/15244 [==============================] - 739s 48ms/step - loss: 0.1279 - val_loss: 0.1380\n",
      "Average AUC: 0.8998693426889102\n",
      "Recalls: 0.308931621241178 0.5662054249484997 0.6972342734981238 0.8579939829074178\n",
      "NDCG: 0.8087390271182546\n",
      "AUCs: [0.90665432 0.91085551 0.83939758 0.95961968 0.88423998 0.89721928\n",
      " 0.89166092 0.98506036 0.88545449 0.95606317 0.95321251 0.9293418\n",
      " 0.92344386 0.85932828 0.85996585 0.9190962  0.91038325 0.98031295\n",
      " 0.92551995 0.87801648 0.85556081 0.68091959 0.9834348  0.92425822\n",
      " 0.90987252 0.9615626  0.91683157 0.92164626 0.69901117 0.93789104\n",
      " 0.84445546 0.94327632 0.89994077 0.93142721 0.8679708  0.98831045\n",
      " 0.8067456  0.88653041 0.95406851 0.89118998 0.90979896 0.91030959\n",
      " 0.94340118 0.95876623 0.6345531  0.78038853 0.94129237 0.88271796\n",
      " 0.98560261 0.98688607]\n",
      "Epoch 26/30\n",
      "15244/15244 [==============================] - 740s 49ms/step - loss: 0.1269 - val_loss: 0.1407\n",
      "Average AUC: 0.897295440947521\n",
      "Recalls: 0.2927515511829916 0.5462181228282337 0.6816385740554716 0.846093425785254\n",
      "NDCG: 0.7913035633266906\n",
      "AUCs: [0.89907616 0.9076062  0.83216682 0.95689837 0.87869851 0.89756513\n",
      " 0.88148409 0.98432889 0.87859255 0.95381824 0.94964408 0.93077124\n",
      " 0.91478269 0.86083371 0.85022564 0.92092437 0.89039547 0.98069082\n",
      " 0.9199359  0.87153071 0.85097977 0.67879039 0.98379494 0.92512636\n",
      " 0.90864823 0.96323534 0.9187909  0.91929649 0.68605576 0.93273596\n",
      " 0.8443453  0.93231354 0.90197391 0.93668317 0.86374618 0.98785606\n",
      " 0.82227134 0.87539081 0.95263588 0.87962112 0.91134198 0.91502572\n",
      " 0.94627799 0.96754406 0.6248814  0.77242241 0.94263267 0.88781622\n",
      " 0.98474304 0.98782551]\n",
      "Epoch 27/30\n",
      "15244/15244 [==============================] - 739s 49ms/step - loss: 0.1256 - val_loss: 0.1362\n",
      "Average AUC: 0.8987378924135873\n",
      "Recalls: 0.305485614211376 0.5742049392845792 0.7073831338201145 0.8588473840205142\n",
      "NDCG: 0.8112845559216048\n",
      "AUCs: [0.91331377 0.9157587  0.83694364 0.96170416 0.88306634 0.89922684\n",
      " 0.90101364 0.98447358 0.88631744 0.95998017 0.95302874 0.92944531\n",
      " 0.91185657 0.86341571 0.86202505 0.91762277 0.91375302 0.98012808\n",
      " 0.91606608 0.8730346  0.84779354 0.68086466 0.98567482 0.92335668\n",
      " 0.91138708 0.96593392 0.91167211 0.91051339 0.6971568  0.92688514\n",
      " 0.83975776 0.94941362 0.90071243 0.92532409 0.85115843 0.98681123\n",
      " 0.8024068  0.88081365 0.9532912  0.8762373  0.90070709 0.91792833\n",
      " 0.94014699 0.95735158 0.6536368  0.77487548 0.93974559 0.89129286\n",
      " 0.98523027 0.98664077]\n",
      "Epoch 28/30\n",
      "15244/15244 [==============================] - 741s 49ms/step - loss: 0.1242 - val_loss: 0.1361\n",
      "Average AUC: 0.9001488673077579\n",
      "Recalls: 0.31681409989928 0.5792960745523072 0.7115391745066261 0.8712361193490001\n",
      "NDCG: 0.8186421143027365\n",
      "AUCs: [0.91045349 0.91178858 0.83789879 0.9575361  0.88193974 0.89935837\n",
      " 0.89326342 0.98374799 0.87821873 0.95491577 0.95320994 0.92915884\n",
      " 0.92222676 0.86740051 0.85498463 0.91922906 0.90654147 0.98055877\n",
      " 0.92846701 0.88208562 0.85027931 0.66872563 0.98418701 0.91894916\n",
      " 0.90695594 0.96077804 0.91740951 0.92289562 0.69520179 0.93633058\n",
      " 0.85047907 0.95090623 0.89534097 0.94051659 0.87227725 0.98739013\n",
      " 0.82720428 0.88351862 0.95276882 0.89727814 0.90813609 0.90554136\n",
      " 0.94174108 0.96411178 0.63887162 0.77915109 0.93990306 0.88694258\n",
      " 0.98514882 0.98551962]\n",
      "Epoch 29/30\n",
      "15244/15244 [==============================] - 743s 49ms/step - loss: 0.1234 - val_loss: 0.1423\n",
      "Average AUC: 0.8988540761749126\n",
      "Recalls: 0.3061090661159913 0.5684106822437847 0.6966223719340063 0.8519729244798496\n",
      "NDCG: 0.8070432227847394\n",
      "AUCs: [0.90793438 0.90882693 0.83289924 0.96170192 0.87716716 0.89775456\n",
      " 0.89591602 0.9828704  0.88406399 0.95546426 0.95217472 0.92549669\n",
      " 0.91601457 0.86597471 0.86008587 0.91762543 0.89834165 0.98167274\n",
      " 0.92347237 0.88305379 0.85469749 0.66377713 0.98596217 0.92405336\n",
      " 0.90100925 0.94579596 0.9182276  0.92206416 0.68405797 0.93674629\n",
      " 0.83815251 0.94524406 0.89519176 0.93589601 0.86057879 0.98774311\n",
      " 0.82569498 0.88711097 0.95495842 0.89617616 0.90440286 0.90648593\n",
      " 0.94400361 0.95803571 0.65621728 0.78124801 0.94624416 0.88499782\n",
      " 0.98413363 0.98528522]\n",
      "Epoch 30/30\n",
      "15244/15244 [==============================] - 740s 49ms/step - loss: 0.1216 - val_loss: 0.1386\n",
      "Average AUC: 0.8996795353705128\n",
      "Recalls: 0.3119273315429826 0.5730628296244639 0.7086259987575777 0.8657413384040807\n",
      "NDCG: 0.8145636760797365\n",
      "AUCs: [0.91024621 0.90825122 0.83532117 0.96151159 0.88669234 0.89838786\n",
      " 0.89315305 0.98435688 0.88731253 0.95662717 0.95330517 0.92534726\n",
      " 0.9197915  0.87017128 0.85738192 0.92256454 0.8914404  0.98163414\n",
      " 0.92815508 0.88247776 0.86392435 0.66659742 0.98612947 0.92553066\n",
      " 0.90855245 0.95094591 0.91698679 0.91689465 0.68799945 0.93609743\n",
      " 0.84280399 0.94105595 0.88879695 0.92962698 0.86763059 0.98825654\n",
      " 0.82863794 0.88592644 0.95328025 0.88329504 0.90938624 0.90678174\n",
      " 0.9404939  0.96759045 0.64854434 0.77749391 0.94494934 0.89334134\n",
      " 0.98498593 0.98731127]\n"
     ]
    }
   ],
   "source": [
    "#  FCN-4 + output  (MTAT)\n",
    "import numpy as np \n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Flatten,Dense,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 30\n",
    "input_shape = (96,1360,1)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,4),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(384,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4,5),strides=(2,4),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(768,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,8),strides=(2,4),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2048,(3,3),strides=(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4,8),strides=(4,8),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(50, activation='sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "filepath='C:/DT/model_save/FCN/'+\"{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_val = np.load(path+'\\\\x_validation_MelSpec.npy')\n",
    "y_val = np.load(path+'\\\\y_validation.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "        self.aucs_all = []\n",
    "        self.recalls_1 = []\n",
    "        self.recalls_3 = []\n",
    "        self.recalls_5 = []\n",
    "        self.recalls_10 = []\n",
    "        self.ndcgs_50 = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        \n",
    "        recall_1 = recall(y_test,y_pred,1)\n",
    "        recall_3 = recall(y_test,y_pred,3)\n",
    "        recall_5 = recall(y_test,y_pred,5)\n",
    "        recall_10 = recall(y_test,y_pred,10)\n",
    "        self.recalls_1.append(recall_1)\n",
    "        self.recalls_3.append(recall_3)\n",
    "        self.recalls_5.append(recall_5)\n",
    "        self.recalls_10.append(recall_10)\n",
    "        \n",
    "        ndcg_50 = ndcg_score(y_test,y_pred,k=50,gains=\"exponential\")\n",
    "        self.ndcgs_50.append(ndcg_50)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        auc_all = roc_auc_score(y_test, y_pred,average = None )\n",
    "        self.aucs_all.append(auc_all)\n",
    "        \n",
    "        print(\"Average AUC:\",auc)\n",
    "        print(\"Recalls:\",recall_1,recall_3,recall_5,recall_10)\n",
    "        print(\"NDCG:\",ndcg_50)\n",
    "        print(\"AUCs:\",auc_all)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, batch_size = 16, epochs = epochs, validation_data=(x_val,y_val), callbacks=[histories,checkpoint])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "pickle.dump(histories.aucs,open(os.path.join(path,'fcn_aucs.pkl'),'wb'))\n",
    "pickle.dump(histories.aucs_all,open(os.path.join(path,'fcn_aucs_all.pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(path,'fcn_losses.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_1,open(os.path.join(path,'fcn_recalls_1.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_3,open(os.path.join(path,'fcn_recalls_3.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_5,open(os.path.join(path,'fcn_recalls_5.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_10,open(os.path.join(path,'fcn_recalls_10.pkl'),'wb'))\n",
    "pickle.dump(histories.ndcgs_50,open(os.path.join(path,'fcn_ndcgs_10.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 1360, 10) 970         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 96, 1360, 6)  1734        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 96, 1360, 3)  1443        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 96, 1360, 3)  2019        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 96, 1360, 15) 1140        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 96, 1360, 6)  1356        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 96, 1360, 3)  1128        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 96, 1360, 3)  1578        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 96, 1360, 15) 390         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 96, 1360, 10) 760         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 96, 1360, 5)  630         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 96, 1360, 5)  880         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 1360, 10) 40          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 96, 1360, 6)  24          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 96, 1360, 3)  12          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 96, 1360, 3)  12          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 96, 1360, 15) 60          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 96, 1360, 6)  24          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 96, 1360, 3)  12          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 96, 1360, 3)  12          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 96, 1360, 15) 60          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 96, 1360, 10) 40          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 96, 1360, 5)  20          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 96, 1360, 5)  20          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 1360, 10) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 96, 1360, 6)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 96, 1360, 3)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 96, 1360, 3)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 96, 1360, 15) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 96, 1360, 6)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 96, 1360, 3)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 96, 1360, 3)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 96, 1360, 15) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 96, 1360, 10) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 96, 1360, 5)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 96, 1360, 5)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 24, 340, 10)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 340, 6)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 24, 340, 3)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 24, 340, 3)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 24, 340, 15)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 24, 340, 6)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 24, 340, 3)   0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 24, 340, 3)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 24, 340, 15)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 24, 340, 10)  0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 24, 340, 5)   0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 24, 340, 5)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 24, 340, 84)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 24, 340, 32)  172064      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 24, 340, 32)  128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 24, 340, 32)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 6, 85, 32)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16320)        0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16320)        0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          1632100     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           5050        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,823,706\n",
      "Trainable params: 1,823,474\n",
      "Non-trainable params: 232\n",
      "__________________________________________________________________________________________________\n",
      "Train on 15244 samples, validate on 1529 samples\n",
      "Epoch 1/30\n",
      "15244/15244 [==============================] - 1027s 67ms/step - loss: 0.2297 - val_loss: 0.1895\n",
      "Average AUC: 0.785994945332265\n",
      "Recalls: 0.16547475172821433 0.36288302725283333 0.5090652070049577 0.6958399057083268\n",
      "NDCG: 0.6458287087611081\n",
      "AUCs: [0.78916484 0.87434154 0.74286952 0.91353297 0.82456502 0.835509\n",
      " 0.80475872 0.97453829 0.81596312 0.85053367 0.73989778 0.89123985\n",
      " 0.87071678 0.73816346 0.73323793 0.76650584 0.73201915 0.95197287\n",
      " 0.766362   0.76492949 0.75457753 0.57752905 0.95420209 0.89521048\n",
      " 0.87872026 0.88707849 0.75075244 0.75257101 0.51916264 0.82805777\n",
      " 0.75806877 0.70892783 0.68342158 0.64728245 0.82986951 0.97325023\n",
      " 0.63703486 0.74845373 0.88457069 0.64101086 0.74415823 0.894383\n",
      " 0.76592868 0.76977041 0.49281473 0.67716156 0.7845392  0.54525309\n",
      " 0.97380282 0.96136144]\n",
      "Epoch 2/30\n",
      "15244/15244 [==============================] - 1004s 66ms/step - loss: 0.1850 - val_loss: 0.1814\n",
      "Average AUC: 0.8301232698566418\n",
      "Recalls: 0.20237300147272444 0.41721718634807275 0.5462188325934862 0.7355683194152723\n",
      "NDCG: 0.6837595467833201\n",
      "AUCs: [0.75188413 0.87550458 0.77667529 0.93877019 0.83267615 0.81828399\n",
      " 0.83231809 0.9732725  0.84001995 0.89976038 0.87203952 0.90215997\n",
      " 0.86600776 0.81006492 0.76397104 0.83736799 0.78945171 0.9586939\n",
      " 0.81699275 0.82820856 0.79519044 0.60727344 0.94715891 0.88724284\n",
      " 0.89770268 0.9047562  0.82055703 0.76555044 0.54879479 0.87819248\n",
      " 0.7969758  0.80922449 0.80897112 0.7980674  0.84536842 0.97778639\n",
      " 0.71054153 0.81923253 0.92530502 0.72628792 0.82849952 0.90325221\n",
      " 0.84497682 0.840109   0.57979045 0.70925498 0.86691047 0.72790702\n",
      " 0.96971588 0.98144389]\n",
      "Epoch 3/30\n",
      "15244/15244 [==============================] - 1004s 66ms/step - loss: 0.1703 - val_loss: 0.1830\n",
      "Average AUC: 0.8311217572762101\n",
      "Recalls: 0.21773368854393782 0.4270091103366726 0.5456056011803935 0.7185091467986204\n",
      "NDCG: 0.6940281853549779\n",
      "AUCs: [0.78495905 0.8459157  0.789489   0.94305514 0.85001985 0.82607503\n",
      " 0.84579924 0.97918172 0.84682109 0.88654565 0.90288028 0.9145292\n",
      " 0.88419254 0.81527317 0.75984962 0.83254048 0.7140618  0.96488877\n",
      " 0.83579806 0.8195799  0.80028019 0.62888402 0.95295054 0.88845752\n",
      " 0.90339563 0.89022412 0.77989537 0.80664039 0.58287037 0.90116276\n",
      " 0.79772925 0.72093821 0.79651157 0.81346817 0.8169308  0.96091119\n",
      " 0.72666308 0.81000659 0.9287552  0.77282816 0.75070709 0.90125382\n",
      " 0.84710398 0.83351113 0.59075443 0.72447491 0.89148746 0.73799484\n",
      " 0.97921621 0.97862559]\n",
      "Epoch 4/30\n",
      "15244/15244 [==============================] - 1003s 66ms/step - loss: 0.1620 - val_loss: 0.1825\n",
      "Average AUC: 0.8498570253973622\n",
      "Recalls: 0.22737265171475698 0.4408920674329262 0.5671965909846797 0.756759788892753\n",
      "NDCG: 0.7111290083624484\n",
      "AUCs: [0.8342834  0.8764536  0.80184106 0.94315814 0.86646189 0.81448217\n",
      " 0.84708429 0.98145215 0.85101945 0.91068974 0.92003107 0.91476902\n",
      " 0.90209441 0.83871472 0.77969803 0.87365304 0.75070906 0.96249696\n",
      " 0.85322621 0.84633244 0.80265388 0.62690462 0.97215039 0.89846378\n",
      " 0.90886248 0.91411167 0.8538529  0.82999497 0.57791742 0.88149104\n",
      " 0.79905416 0.7670375  0.85684251 0.83515033 0.83819388 0.97152125\n",
      " 0.74640996 0.86939628 0.93962968 0.79899731 0.81379734 0.9092272\n",
      " 0.89813024 0.87106911 0.61206897 0.71856937 0.86363843 0.7913501\n",
      " 0.9788046  0.97890906]\n",
      "Epoch 5/30\n",
      "15244/15244 [==============================] - 1006s 66ms/step - loss: 0.1551 - val_loss: 0.1577\n",
      "Average AUC: 0.860501150994564\n",
      "Recalls: 0.24702227084498557 0.47518602447619074 0.6156924562049215 0.7915994503598381\n",
      "NDCG: 0.7377754607351971\n",
      "AUCs: [0.8510636  0.88163146 0.80547306 0.95012343 0.84964217 0.83177929\n",
      " 0.85838901 0.97697859 0.85698002 0.91240613 0.93650391 0.90549993\n",
      " 0.90272038 0.82848817 0.81246952 0.88520664 0.75960619 0.9748657\n",
      " 0.87426626 0.83899271 0.81876718 0.63039203 0.95730415 0.88152769\n",
      " 0.90156808 0.92665423 0.87817903 0.84607465 0.63295466 0.90143168\n",
      " 0.81550301 0.84341074 0.8540573  0.87771865 0.84519616 0.97211426\n",
      " 0.80457831 0.87173305 0.93479067 0.78188933 0.85358042 0.88627685\n",
      " 0.87829713 0.90445269 0.61783313 0.7324492  0.89285927 0.83332702\n",
      " 0.97749126 0.97955957]\n",
      "Epoch 6/30\n",
      "15244/15244 [==============================] - 1006s 66ms/step - loss: 0.1501 - val_loss: 0.1602\n",
      "Average AUC: 0.867427977664682\n",
      "Recalls: 0.251043746317292 0.46322480996996235 0.5949656882309237 0.7804045670908553\n",
      "NDCG: 0.7319761567203114\n",
      "AUCs: [0.85318468 0.88202091 0.79553308 0.9435518  0.86583027 0.83249283\n",
      " 0.8455827  0.9797111  0.86156114 0.92294822 0.92477396 0.91045374\n",
      " 0.91260288 0.84658166 0.80808005 0.89061476 0.79859763 0.9656594\n",
      " 0.88801641 0.85371416 0.82279835 0.63297963 0.97068428 0.88705694\n",
      " 0.90293948 0.93194629 0.9031524  0.8707986  0.61921925 0.89585842\n",
      " 0.82169481 0.86309507 0.86442645 0.89241698 0.84788769 0.98038435\n",
      " 0.79246697 0.85987158 0.93507688 0.83253767 0.88091593 0.89647215\n",
      " 0.90555919 0.92721475 0.60674238 0.73652765 0.9003412  0.84477617\n",
      " 0.98040157 0.98364439]\n",
      "Epoch 7/30\n",
      "15244/15244 [==============================] - 1007s 66ms/step - loss: 0.1462 - val_loss: 0.1612\n",
      "Average AUC: 0.8678270138940679\n",
      "Recalls: 0.23588183835760013 0.4614819743455477 0.5983347459455493 0.7828054915485665\n",
      "NDCG: 0.7247144849983504\n",
      "AUCs: [0.8739295  0.88044263 0.80836016 0.95037063 0.86717987 0.82899725\n",
      " 0.84606729 0.98106394 0.82819227 0.9146771  0.92411479 0.91408382\n",
      " 0.91205291 0.8456095  0.79692881 0.89776667 0.80183886 0.96321342\n",
      " 0.88161296 0.8572459  0.82948866 0.64533039 0.96351595 0.89120184\n",
      " 0.90726103 0.93281523 0.90440102 0.86583733 0.64305681 0.9032623\n",
      " 0.83302399 0.85759051 0.86787329 0.88202508 0.84109211 0.97951024\n",
      " 0.8047531  0.85604426 0.93835971 0.81510455 0.87891749 0.86190796\n",
      " 0.91422856 0.91398423 0.62078985 0.74465549 0.90954489 0.84474625\n",
      " 0.98375403 0.98352628]\n",
      "Epoch 8/30\n",
      "15244/15244 [==============================] - 1006s 66ms/step - loss: 0.1425 - val_loss: 0.1573\n",
      "Average AUC: 0.8743541689177654\n",
      "Recalls: 0.25619598097091173 0.4928706809246975 0.6370158254334154 0.8082673879419031\n",
      "NDCG: 0.751784458498712\n",
      "AUCs: [0.86387933 0.88444504 0.8133071  0.94812381 0.86317554 0.85358466\n",
      " 0.85865653 0.98251137 0.85810937 0.9118521  0.93259367 0.91404883\n",
      " 0.91556489 0.85970051 0.79863023 0.90574432 0.81313546 0.97122855\n",
      " 0.90223027 0.86578219 0.83704141 0.64767231 0.9701926  0.89411582\n",
      " 0.90416871 0.93923824 0.91312574 0.89110643 0.62109752 0.90434784\n",
      " 0.82349284 0.85490196 0.85543935 0.90362781 0.84137849 0.98262163\n",
      " 0.80892635 0.86518139 0.94843342 0.851248   0.89490053 0.91125752\n",
      " 0.91578035 0.92018785 0.61786176 0.75808741 0.89254081 0.86586735\n",
      " 0.98267775 0.98488546]\n",
      "Epoch 9/30\n",
      "15244/15244 [==============================] - 1007s 66ms/step - loss: 0.1387 - val_loss: 0.1711\n",
      "Average AUC: 0.8666044126281099\n",
      "Recalls: 0.2401522082616265 0.45568677372693994 0.593600844241426 0.7705509908937886\n",
      "NDCG: 0.7213574782407804\n",
      "AUCs: [0.88328807 0.88475495 0.80985737 0.94308761 0.87101082 0.83054393\n",
      " 0.84251068 0.9812644  0.83985174 0.91938525 0.90549328 0.91054267\n",
      " 0.90443256 0.83603656 0.79809035 0.88489375 0.78911999 0.9726486\n",
      " 0.88863096 0.84395276 0.8275151  0.62811004 0.96485434 0.89076957\n",
      " 0.91483286 0.93955798 0.88722493 0.87317296 0.58377868 0.89533168\n",
      " 0.82217481 0.86479627 0.86472486 0.89157158 0.85000861 0.98280133\n",
      " 0.79132072 0.84677148 0.9314703  0.83565671 0.86731783 0.89113752\n",
      " 0.9087     0.93453154 0.62764285 0.76545388 0.91188956 0.83275057\n",
      " 0.98000305 0.98495269]\n",
      "Epoch 10/30\n",
      "15244/15244 [==============================] - 1006s 66ms/step - loss: 0.1357 - val_loss: 0.1500\n",
      "Average AUC: 0.878364617583896\n",
      "Recalls: 0.27422708677902585 0.5214639443863821 0.6567540640082191 0.8284125090565533\n",
      "NDCG: 0.7725202090245291\n",
      "AUCs: [0.87432208 0.88616903 0.82160632 0.95394396 0.85425427 0.85616102\n",
      " 0.8637431  0.98249584 0.87453872 0.90168952 0.94336948 0.92220047\n",
      " 0.91204975 0.86307445 0.81968864 0.91096842 0.80008901 0.97559299\n",
      " 0.90827337 0.87479543 0.84760704 0.65608725 0.96558101 0.8912984\n",
      " 0.90437111 0.93801255 0.9072009  0.89127706 0.64057468 0.9230142\n",
      " 0.82632563 0.87303806 0.87311664 0.9059734  0.85338056 0.97938445\n",
      " 0.81866365 0.86148326 0.94741995 0.84743487 0.89259648 0.91383576\n",
      " 0.91868594 0.92302876 0.620751   0.75941206 0.88375357 0.88960141\n",
      " 0.98364494 0.98265044]\n",
      "Epoch 11/30\n",
      "15244/15244 [==============================] - 1007s 66ms/step - loss: 0.1329 - val_loss: 0.1549\n",
      "Average AUC: 0.8701446309355236\n",
      "Recalls: 0.2762880689127226 0.5174226800438712 0.6488915606297877 0.8154292774271998\n",
      "NDCG: 0.7702353001450599\n",
      "AUCs: [0.852422   0.88768746 0.80971275 0.94711975 0.83626058 0.84163934\n",
      " 0.84892382 0.98185824 0.86648502 0.91877471 0.93892181 0.92216694\n",
      " 0.89841143 0.86204714 0.80239577 0.90784485 0.75642716 0.97662299\n",
      " 0.89846474 0.86485769 0.83830838 0.64616629 0.97458708 0.89299228\n",
      " 0.90001896 0.94006276 0.90884197 0.88657896 0.63153746 0.91380931\n",
      " 0.81877153 0.81060817 0.84615837 0.8940919  0.85353344 0.98160632\n",
      " 0.82126962 0.8713487  0.94448433 0.84156964 0.87967402 0.90441191\n",
      " 0.87931078 0.92380566 0.6049021  0.76213043 0.8687477  0.88113223\n",
      " 0.98255267 0.98517438]\n",
      "Epoch 12/30\n",
      "15244/15244 [==============================] - 1007s 66ms/step - loss: 0.1300 - val_loss: 0.1573\n",
      "Average AUC: 0.8771924807569559\n",
      "Recalls: 0.2574616551243975 0.49468386786600077 0.6368332658671993 0.8139788138403097\n",
      "NDCG: 0.7529339961755999\n",
      "AUCs: [0.86753238 0.88455885 0.80840872 0.94876423 0.84060811 0.86114717\n",
      " 0.85235902 0.97921325 0.86203816 0.90309232 0.94092223 0.91967181\n",
      " 0.89980165 0.8647719  0.82262278 0.91369473 0.81313408 0.97650245\n",
      " 0.90978182 0.87245941 0.84060678 0.65913224 0.95884178 0.88523762\n",
      " 0.89987382 0.92856382 0.9194772  0.89566427 0.64468473 0.9207395\n",
      " 0.82819448 0.87416215 0.85823812 0.90830134 0.85340209 0.97838454\n",
      " 0.83331204 0.86476151 0.94473926 0.84754098 0.89815586 0.90075801\n",
      " 0.90090214 0.93527365 0.62432728 0.76115465 0.89743312 0.88829493\n",
      " 0.98374821 0.98463288]\n",
      "Epoch 13/30\n",
      "15244/15244 [==============================] - 1008s 66ms/step - loss: 0.1273 - val_loss: 0.1515\n",
      "Average AUC: 0.8786225966669438\n",
      "Recalls: 0.2631574552973445 0.5066118278202765 0.6426743238550717 0.820777981252358\n",
      "NDCG: 0.7614605175885758\n",
      "AUCs: [0.86800314 0.88544368 0.82149583 0.9497759  0.86794876 0.84997379\n",
      " 0.85552459 0.98051998 0.86935922 0.92039635 0.93059325 0.92050935\n",
      " 0.9054206  0.86552167 0.81721033 0.91364823 0.79246764 0.97250301\n",
      " 0.90662897 0.87460818 0.83815953 0.65821445 0.96725273 0.8929616\n",
      " 0.91075618 0.94174882 0.9153262  0.89931256 0.65254881 0.92033489\n",
      " 0.83018825 0.87054652 0.85703241 0.90890318 0.85205633 0.97810729\n",
      " 0.83405325 0.87267131 0.94260753 0.84921927 0.9010906  0.90403711\n",
      " 0.90963412 0.91827458 0.63041451 0.76122188 0.90022572 0.87930715\n",
      " 0.98265593 0.98471465]\n",
      "Epoch 14/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1246 - val_loss: 0.1631\n",
      "Average AUC: 0.8672797614801229\n",
      "Recalls: 0.2419074269836043 0.45740714156572876 0.5940804264730858 0.7836475261683018\n",
      "NDCG: 0.7279507146782398\n",
      "AUCs: [0.8581872  0.87924789 0.79868671 0.94372018 0.86675256 0.84476114\n",
      " 0.8398854  0.97982309 0.85931191 0.90539653 0.93222972 0.90936545\n",
      " 0.91249943 0.84562602 0.79472082 0.89314377 0.79610832 0.97030555\n",
      " 0.90096392 0.85364111 0.83165134 0.63313842 0.9670867  0.88508691\n",
      " 0.89679828 0.92753945 0.90434147 0.8818664  0.6229846  0.89917178\n",
      " 0.81961055 0.85956983 0.85580408 0.89171984 0.8515008  0.9761832\n",
      " 0.80756496 0.85141433 0.93645632 0.82647093 0.87263603 0.88587516\n",
      " 0.89218369 0.94174397 0.61105681 0.73480324 0.89931935 0.85174939\n",
      " 0.98293955 0.98134395]\n",
      "Epoch 15/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1225 - val_loss: 0.1509\n",
      "Average AUC: 0.8793807626024882\n",
      "Recalls: 0.28489318916950496 0.5338065091008304 0.6644839681197021 0.8290326715707602\n",
      "NDCG: 0.7815807753417203\n",
      "AUCs: [0.88583727 0.89485392 0.82242019 0.94717036 0.86103255 0.8652664\n",
      " 0.84804873 0.98032658 0.86935632 0.92313548 0.94117602 0.9225868\n",
      " 0.89589172 0.86678229 0.81905638 0.9142667  0.78733144 0.97541625\n",
      " 0.90922034 0.87310513 0.83842045 0.64173412 0.97023347 0.89102677\n",
      " 0.90568327 0.94036326 0.910731   0.89528252 0.65483343 0.92834939\n",
      " 0.83202465 0.86682891 0.87075494 0.91453684 0.85653288 0.97897113\n",
      " 0.82991697 0.87292969 0.94353654 0.84074024 0.89275827 0.90270765\n",
      " 0.90524105 0.94231215 0.61308521 0.75946203 0.91405575 0.8865257\n",
      " 0.98385438 0.98332458]\n",
      "Epoch 16/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1195 - val_loss: 0.1560\n",
      "Average AUC: 0.87780361982591\n",
      "Recalls: 0.26681921302766176 0.5138689751051246 0.6534940615965547 0.812598835452021\n",
      "NDCG: 0.7647574747405295\n",
      "AUCs: [0.88367321 0.89104328 0.81937757 0.94609375 0.86320068 0.8631659\n",
      " 0.85436569 0.98074961 0.87379134 0.92529121 0.93897149 0.92213851\n",
      " 0.90235409 0.86106377 0.82183757 0.90984043 0.80233092 0.97298042\n",
      " 0.90117622 0.86693341 0.82894055 0.66163195 0.96385565 0.88299957\n",
      " 0.90413514 0.94814371 0.90492722 0.88964017 0.67152904 0.92759814\n",
      " 0.82225252 0.87288741 0.86270831 0.90909909 0.85980578 0.97523335\n",
      " 0.81557867 0.86098748 0.94238075 0.82680776 0.88787602 0.89849911\n",
      " 0.90784372 0.9416628  0.6359558  0.73998012 0.89503596 0.88563211\n",
      " 0.98443761 0.98173645]\n",
      "Epoch 17/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1172 - val_loss: 0.1546\n",
      "Average AUC: 0.871461298625321\n",
      "Recalls: 0.2806683627493877 0.5262468628119598 0.6546738676066931 0.8224352869609102\n",
      "NDCG: 0.7757769192604395\n",
      "AUCs: [0.87722435 0.89092908 0.80753256 0.9423986  0.859924   0.84182268\n",
      " 0.83173311 0.97873611 0.87036168 0.92025397 0.93543214 0.91685011\n",
      " 0.90596634 0.86933775 0.79652371 0.9083391  0.80460599 0.97427181\n",
      " 0.90844842 0.87494741 0.83934769 0.63862021 0.96781848 0.88600469\n",
      " 0.89486608 0.93596086 0.90655364 0.89233554 0.6050473  0.91813914\n",
      " 0.82271383 0.86014231 0.8552585  0.90179405 0.85014211 0.9786143\n",
      " 0.82445628 0.86728238 0.93919958 0.84926405 0.87795572 0.89884702\n",
      " 0.88062566 0.92086039 0.60728628 0.73449433 0.8715928  0.86504158\n",
      " 0.98254103 0.98462016]\n",
      "Epoch 18/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1150 - val_loss: 0.1610\n",
      "Average AUC: 0.879269528560211\n",
      "Recalls: 0.263603488309167 0.5066968273339465 0.6435348591338896 0.8150564604165712\n",
      "NDCG: 0.760803407275493\n",
      "AUCs: [0.86155692 0.89034983 0.82323829 0.94651852 0.86261353 0.86323903\n",
      " 0.85550777 0.97857047 0.86506451 0.93078387 0.93830665 0.9249828\n",
      " 0.90519681 0.86711145 0.82226538 0.91057183 0.83252199 0.97565665\n",
      " 0.90825475 0.87107728 0.84346817 0.66169787 0.96446866 0.89198967\n",
      " 0.89852414 0.93198626 0.91266885 0.89675312 0.64686116 0.92715899\n",
      " 0.82808825 0.8797965  0.85683798 0.91592584 0.83113346 0.9771292\n",
      " 0.81817876 0.8648907  0.9368833  0.84422725 0.89817234 0.90513967\n",
      " 0.90965273 0.95481215 0.64465624 0.75171306 0.88817693 0.88794388\n",
      " 0.98207125 0.97908168]\n",
      "Epoch 19/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1127 - val_loss: 0.1577\n",
      "Average AUC: 0.8701706005571478\n",
      "Recalls: 0.2770082622056306 0.5115753763780079 0.6400031972746655 0.8134705661887103\n",
      "NDCG: 0.7680986914810944\n",
      "AUCs: [0.87830638 0.88818914 0.81420578 0.94059246 0.85151382 0.85151057\n",
      " 0.83150764 0.97654427 0.8674659  0.9216878  0.92771616 0.91367489\n",
      " 0.8933034  0.87028926 0.79705602 0.90439777 0.7886459  0.97170732\n",
      " 0.90627142 0.87447551 0.83832939 0.64627615 0.97287067 0.87885646\n",
      " 0.89323698 0.93553454 0.89884227 0.89651886 0.62739344 0.91543392\n",
      " 0.81610596 0.84706346 0.85025478 0.90493562 0.85279704 0.98051271\n",
      " 0.80005546 0.86029146 0.93414474 0.83448464 0.87033797 0.88573902\n",
      " 0.90115259 0.92896568 0.60576907 0.74179176 0.89086805 0.86673701\n",
      " 0.98137313 0.98279581]\n",
      "Epoch 20/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1103 - val_loss: 0.1557\n",
      "Average AUC: 0.8747895872264716\n",
      "Recalls: 0.266751609809089 0.5185648563245516 0.6528373468124161 0.8225505796142915\n",
      "NDCG: 0.7675811760513214\n",
      "AUCs: [0.88420844 0.88645255 0.80761613 0.94199644 0.86825039 0.85801978\n",
      " 0.84538245 0.97691459 0.86661981 0.90978889 0.9316995  0.92146643\n",
      " 0.90593362 0.86548568 0.81999455 0.90468674 0.82228276 0.97127054\n",
      " 0.90457395 0.87265926 0.83563961 0.64169118 0.97180685 0.88761916\n",
      " 0.89233654 0.93906504 0.90625296 0.89623689 0.6300473  0.92065562\n",
      " 0.81532596 0.8740509  0.85128567 0.91218066 0.84411093 0.97758487\n",
      " 0.80801876 0.85075384 0.93678633 0.84350298 0.88494727 0.90241521\n",
      " 0.89952296 0.9346359  0.6248814  0.7530359  0.89954681 0.87449012\n",
      " 0.98309517 0.98265408]\n",
      "Epoch 21/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1089 - val_loss: 0.1696\n",
      "Average AUC: 0.8739021432070021\n",
      "Recalls: 0.2707564051573747 0.5193666764650143 0.6530752597407722 0.8165008019578657\n",
      "NDCG: 0.7696610275658816\n",
      "AUCs: [0.87404141 0.89530165 0.81252278 0.94479187 0.85559484 0.85483044\n",
      " 0.8495624  0.98071573 0.86044864 0.91794643 0.93791954 0.91489804\n",
      " 0.91057719 0.86934011 0.82044281 0.90211654 0.80136546 0.97169852\n",
      " 0.90645764 0.87146018 0.83787584 0.65286398 0.97272891 0.90151222\n",
      " 0.89019502 0.94692394 0.89717874 0.89430646 0.64363049 0.92308451\n",
      " 0.82398268 0.87547165 0.84118932 0.90003089 0.83982817 0.97370205\n",
      " 0.79312918 0.8463613  0.93532868 0.84570694 0.87798118 0.89679149\n",
      " 0.90857816 0.92627551 0.63295205 0.7559814  0.87878777 0.86710602\n",
      " 0.98206834 0.98152203]\n",
      "Epoch 22/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1068 - val_loss: 0.1774\n",
      "Average AUC: 0.8681820143794091\n",
      "Recalls: 0.2487360848856693 0.48879166514208056 0.6270538249070106 0.7973117365603515\n",
      "NDCG: 0.7455261385288404\n",
      "AUCs: [0.85052308 0.88630843 0.81121171 0.93822965 0.86995189 0.85626767\n",
      " 0.83652273 0.97176296 0.86078402 0.91170749 0.92733986 0.9214176\n",
      " 0.90381081 0.86375196 0.80989051 0.89641813 0.81868908 0.96998998\n",
      " 0.90217719 0.86378205 0.83371421 0.63762552 0.96238955 0.89674553\n",
      " 0.8812893  0.92260562 0.90194673 0.89462603 0.64618559 0.90564432\n",
      " 0.82777448 0.86896352 0.83031679 0.90808602 0.82338401 0.97474688\n",
      " 0.79101314 0.83148481 0.9344372  0.84910245 0.87782538 0.89568389\n",
      " 0.87974569 0.92810761 0.62214143 0.74129569 0.84828262 0.85929705\n",
      " 0.9814633  0.98263954]\n",
      "Epoch 23/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1048 - val_loss: 0.1565\n",
      "Average AUC: 0.8743121727675266\n",
      "Recalls: 0.2755483807769126 0.5186168869860005 0.6528632122468687 0.8205955158517485\n",
      "NDCG: 0.7716892330151436\n",
      "AUCs: [0.87210711 0.88963983 0.79923616 0.94471327 0.86401727 0.84809218\n",
      " 0.85038704 0.97670849 0.85258054 0.92413883 0.9306195  0.91501977\n",
      " 0.91433934 0.86820454 0.83005656 0.90498037 0.81400624 0.97340231\n",
      " 0.9093088  0.87535131 0.83433675 0.63553228 0.96518511 0.89243097\n",
      " 0.89330215 0.94193682 0.90346382 0.89664611 0.64840605 0.92012642\n",
      " 0.81523645 0.89047884 0.83896553 0.90196878 0.8415486  0.97812654\n",
      " 0.81033144 0.85224278 0.93487825 0.83857716 0.87646063 0.89912602\n",
      " 0.91073239 0.92910482 0.63043905 0.74558947 0.89700793 0.87171859\n",
      " 0.98136585 0.98343361]\n",
      "Epoch 24/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1029 - val_loss: 0.1646\n",
      "Average AUC: 0.8733188853194735\n",
      "Recalls: 0.2701573280520649 0.5158360254447513 0.6481974576157401 0.8121730948081364\n",
      "NDCG: 0.7672516796983697\n",
      "AUCs: [0.87225356 0.88551456 0.80740166 0.94282898 0.86265478 0.85604676\n",
      " 0.84251383 0.97800016 0.86331019 0.91788216 0.9324799  0.9101352\n",
      " 0.90501419 0.86160176 0.80829812 0.89777929 0.80846644 0.97172763\n",
      " 0.90570715 0.87381719 0.83542334 0.63740082 0.96348274 0.89163321\n",
      " 0.88476371 0.93232229 0.90032519 0.8969946  0.66654967 0.92100842\n",
      " 0.812084   0.86667362 0.85258935 0.90629991 0.84888248 0.97686735\n",
      " 0.82272009 0.8424936  0.93490953 0.84502745 0.87388093 0.88903829\n",
      " 0.9013692  0.92990492 0.65148776 0.74062882 0.90280485 0.87064049\n",
      " 0.98131204 0.98299205]\n",
      "Epoch 25/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1014 - val_loss: 0.1611\n",
      "Average AUC: 0.871211606808731\n",
      "Recalls: 0.26785131547943175 0.5075075022443444 0.6427065541158339 0.8140226860448468\n",
      "NDCG: 0.7616783777261179\n",
      "AUCs: [0.87649572 0.87752548 0.79577411 0.94076846 0.86170993 0.84881639\n",
      " 0.84309775 0.97428372 0.84895239 0.91977362 0.92113115 0.9189283\n",
      " 0.89976893 0.86829303 0.80782412 0.90848856 0.82047625 0.97066784\n",
      " 0.90028512 0.87369544 0.83923649 0.64729081 0.96528983 0.87923188\n",
      " 0.88384944 0.93393581 0.91210946 0.89917519 0.63979972 0.91294705\n",
      " 0.81399022 0.89155426 0.85138665 0.9113635  0.82445631 0.97848851\n",
      " 0.81059195 0.84395186 0.9331297  0.83416144 0.89764352 0.88823658\n",
      " 0.8855687  0.92634508 0.61736079 0.73967122 0.88234677 0.87655855\n",
      " 0.98374821 0.98040452]\n",
      "Epoch 26/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.1001 - val_loss: 0.1645\n",
      "Average AUC: 0.8728925382757198\n",
      "Recalls: 0.27115159002278116 0.5188944673362956 0.6488388221248332 0.8220417509544934\n",
      "NDCG: 0.7690819237124311\n",
      "AUCs: [0.87384437 0.88310854 0.80701848 0.94319621 0.86101708 0.85467046\n",
      " 0.84125927 0.97461782 0.85699529 0.92052267 0.93497914 0.92121422\n",
      " 0.90648992 0.8633461  0.82150591 0.90068829 0.82696146 0.96673883\n",
      " 0.90539149 0.87342757 0.83495666 0.6454732  0.96737405 0.88544698\n",
      " 0.89084962 0.93822127 0.89774887 0.89852449 0.65453653 0.91348118\n",
      " 0.81361744 0.90177769 0.84670094 0.90603165 0.82415271 0.98143561\n",
      " 0.80156308 0.84676664 0.93329392 0.83881469 0.88602289 0.89606037\n",
      " 0.89221077 0.92459416 0.63357979 0.74905829 0.87244668 0.86774829\n",
      " 0.98118114 0.9839642 ]\n",
      "Epoch 27/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.0981 - val_loss: 0.1623\n",
      "Average AUC: 0.8710577025966719\n",
      "Recalls: 0.2830925352220366 0.5239479254714712 0.6549802216353463 0.8232400243134316\n",
      "NDCG: 0.7763827784111258\n",
      "AUCs: [0.88447258 0.8951847  0.79882799 0.94236143 0.85741558 0.85146385\n",
      " 0.83324679 0.97219869 0.85676626 0.92701868 0.93907624 0.91563426\n",
      " 0.88719993 0.86293671 0.80798237 0.8973269  0.80439728 0.96996899\n",
      " 0.90618389 0.87477696 0.83374923 0.63339908 0.96168076 0.8758008\n",
      " 0.89386887 0.94021524 0.89361837 0.89662009 0.65954735 0.91837845\n",
      " 0.81181744 0.89356371 0.85537304 0.91077048 0.84358555 0.97846155\n",
      " 0.8090877  0.85831482 0.93025976 0.83878159 0.87279332 0.87951696\n",
      " 0.90421894 0.90976345 0.59678851 0.74282023 0.89770958 0.86216134\n",
      " 0.98268502 0.98309381]\n",
      "Epoch 28/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.0971 - val_loss: 0.1968\n",
      "Average AUC: 0.8683682782843738\n",
      "Recalls: 0.2594209659479743 0.48473272649172927 0.6253757342226871 0.8090195270770063\n",
      "NDCG: 0.7504370462568403\n",
      "AUCs: [0.87897351 0.89084717 0.79497642 0.94200092 0.85588745 0.8578009\n",
      " 0.84279397 0.97563751 0.85052453 0.9296603  0.92066528 0.91631872\n",
      " 0.88246875 0.85058356 0.82160586 0.88933995 0.83587517 0.96183468\n",
      " 0.8981407  0.85217753 0.82998774 0.63593275 0.96569978 0.89161516\n",
      " 0.89524126 0.92249608 0.8897495  0.88990335 0.64435512 0.9111485\n",
      " 0.81851776 0.90434803 0.84307927 0.89761999 0.83890444 0.98104155\n",
      " 0.78184813 0.85690016 0.9318394  0.83916514 0.87408018 0.89046691\n",
      " 0.8998851  0.93472866 0.59653087 0.72359725 0.8645623  0.85173144\n",
      " 0.98255121 0.982774  ]\n",
      "Epoch 29/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.0948 - val_loss: 0.1739\n",
      "Average AUC: 0.8701259660357998\n",
      "Recalls: 0.2591420339689038 0.508720665940195 0.6443653370073038 0.8156850863048923\n",
      "NDCG: 0.7597585310983022\n",
      "AUCs: [0.86937692 0.88792884 0.77813485 0.93975455 0.86155074 0.85944839\n",
      " 0.84459671 0.97522624 0.85278271 0.90970301 0.9352041  0.91181466\n",
      " 0.90635797 0.8630954  0.82091984 0.90145091 0.81160953 0.97166737\n",
      " 0.90877153 0.87217895 0.83155547 0.63278589 0.96460531 0.89256001\n",
      " 0.88001268 0.93973858 0.90030078 0.89825408 0.65044158 0.91911242\n",
      " 0.79503908 0.87446345 0.8333371  0.90937266 0.82834934 0.97508061\n",
      " 0.79041648 0.85455048 0.9280905  0.85694093 0.88205147 0.88167501\n",
      " 0.89330903 0.93031076 0.61999853 0.73525569 0.89778657 0.86515328\n",
      " 0.98283337 0.98134395]\n",
      "Epoch 30/30\n",
      "15244/15244 [==============================] - 1009s 66ms/step - loss: 0.0935 - val_loss: 0.1792\n",
      "Average AUC: 0.8702661694110926\n",
      "Recalls: 0.2658761572888997 0.5110339536066683 0.6494579712377497 0.8191209638058667\n",
      "NDCG: 0.7651300044842179\n",
      "AUCs: [0.87668945 0.8903642  0.8066462  0.94229112 0.86121044 0.85978611\n",
      " 0.83247208 0.97680354 0.85012175 0.9160799  0.92669948 0.90846668\n",
      " 0.89443077 0.86113603 0.81851044 0.89748368 0.82046242 0.96712076\n",
      " 0.8949832  0.87026782 0.83881797 0.62803913 0.9641149  0.89190123\n",
      " 0.88897665 0.93404684 0.89765027 0.88789483 0.6362495  0.91892615\n",
      " 0.81821875 0.88826311 0.85561418 0.89553385 0.83950304 0.97536428\n",
      " 0.81178023 0.85620898 0.9267048  0.83666134 0.87634678 0.86446267\n",
      " 0.89793394 0.93762755 0.63126309 0.73695285 0.87972214 0.86192797\n",
      " 0.98233014 0.98224523]\n"
     ]
    }
   ],
   "source": [
    "#  Timbre CNN  (MTAT)\n",
    "import numpy as np \n",
    "from keras.layers import Input,Conv2D,BatchNormalization,Activation,MaxPooling2D,Concatenate,Flatten,Dropout,Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "epochs = 30\n",
    "pool_size = (4,4)\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1_10_96_1 = Conv2D(10,(96,1),padding='same')(input_melS)\n",
    "bn1_10_96_1 = BatchNormalization()(conv1_10_96_1)\n",
    "act1_10_96_1 = Activation('relu')(bn1_10_96_1)\n",
    "max1_10_96_1 = MaxPooling2D(pool_size,padding='same')(act1_10_96_1)\n",
    "conv1_6_96_3 = Conv2D(6,(96,3),padding='same')(input_melS)\n",
    "bn1_6_96_3 = BatchNormalization()(conv1_6_96_3)\n",
    "act1_6_96_3 = Activation('relu')(bn1_6_96_3)\n",
    "max1_6_96_3 = MaxPooling2D(pool_size,padding='same')(act1_6_96_3)\n",
    "conv1_3_96_5 = Conv2D(3,(96,5),padding='same')(input_melS)\n",
    "bn1_3_96_5 = BatchNormalization()(conv1_3_96_5)\n",
    "act1_3_96_5 = Activation('relu')(bn1_3_96_5)\n",
    "max1_3_96_5 = MaxPooling2D(pool_size,padding='same')(act1_3_96_5)\n",
    "conv1_3_96_7 = Conv2D(3,(96,7),padding='same')(input_melS)\n",
    "bn1_3_96_7 = BatchNormalization()(conv1_3_96_7)\n",
    "act1_3_96_7 = Activation('relu')(bn1_3_96_7)\n",
    "max1_3_96_7 = MaxPooling2D(pool_size,padding='same')(act1_3_96_7)\n",
    "conv1_15_75_1 = Conv2D(15,(75,1),padding='same')(input_melS)\n",
    "bn1_15_75_1 = BatchNormalization()(conv1_15_75_1)\n",
    "act1_15_75_1 = Activation('relu')(bn1_15_75_1)\n",
    "max1_15_75_1 = MaxPooling2D(pool_size,padding='same')(act1_15_75_1)\n",
    "conv1_10_75_3 = Conv2D(6,(75,3),padding='same')(input_melS)\n",
    "bn1_10_75_3 = BatchNormalization()(conv1_10_75_3)\n",
    "act1_10_75_3 = Activation('relu')(bn1_10_75_3)\n",
    "max1_10_75_3 = MaxPooling2D(pool_size,padding='same')(act1_10_75_3)\n",
    "conv1_5_75_5 = Conv2D(3,(75,5),padding='same')(input_melS)\n",
    "bn1_5_75_5 = BatchNormalization()(conv1_5_75_5)\n",
    "act1_5_75_5 = Activation('relu')(bn1_5_75_5)\n",
    "max1_5_75_5 = MaxPooling2D(pool_size,padding='same')(act1_5_75_5)\n",
    "conv1_5_75_7 = Conv2D(3,(75,7),padding='same')(input_melS)\n",
    "bn1_5_75_7 = BatchNormalization()(conv1_5_75_7)\n",
    "act1_5_75_7 = Activation('relu')(bn1_5_75_7)\n",
    "max1_5_75_7 = MaxPooling2D(pool_size,padding='same')(act1_5_75_7)\n",
    "conv1_15_25_1 = Conv2D(15,(25,1),padding='same')(input_melS)\n",
    "bn1_15_25_1 = BatchNormalization()(conv1_15_25_1)\n",
    "act1_15_25_1 = Activation('relu')(bn1_15_25_1)\n",
    "max1_15_25_1 = MaxPooling2D(pool_size,padding='same')(act1_15_25_1)\n",
    "conv1_10_25_3 = Conv2D(10,(25,3),padding='same')(input_melS)\n",
    "bn1_10_25_3 = BatchNormalization()(conv1_10_25_3)\n",
    "act1_10_25_3 = Activation('relu')(bn1_10_25_3)\n",
    "max1_10_25_3 = MaxPooling2D(pool_size,padding='same')(act1_10_25_3)\n",
    "conv1_5_25_5 = Conv2D(5,(25,5),padding='same')(input_melS)\n",
    "bn1_5_25_5 = BatchNormalization()(conv1_5_25_5)\n",
    "act1_5_25_5 = Activation('relu')(bn1_5_25_5)\n",
    "max1_5_25_5 = MaxPooling2D(pool_size,padding='same')(act1_5_25_5)\n",
    "conv1_5_25_7 = Conv2D(5,(25,7),padding='same')(input_melS)\n",
    "bn1_5_25_7 = BatchNormalization()(conv1_5_25_7)\n",
    "act1_5_25_7 = Activation('relu')(bn1_5_25_7)\n",
    "max1_5_25_7= MaxPooling2D(pool_size,padding='same')(act1_5_25_7)\n",
    "\n",
    "max1 = Concatenate()([max1_10_96_1,max1_6_96_3,max1_3_96_5,max1_3_96_7,max1_15_75_1,max1_10_75_3,\n",
    "                        max1_5_75_5,max1_5_75_7,max1_15_25_1,max1_10_25_3,max1_5_25_5,max1_5_25_7])\n",
    "\n",
    "conv2 = Conv2D(32,(8,8),padding='same')(max1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('relu')(bn2)\n",
    "max2 = MaxPooling2D(pool_size,padding='same')(act2)\n",
    "\n",
    "flat_max_2 = Flatten()(max2)\n",
    "drop = Dropout(0.5)(flat_max_2)\n",
    "fc1 = Dense(100, activation='relu')(drop)\n",
    "out = Dense(50, activation='sigmoid')(fc1)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [out])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "filepath='C:/DT/model_save/Timbrecnn/'+\"{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_val = np.load(path+'\\\\x_validation_MelSpec.npy')\n",
    "y_val = np.load(path+'\\\\y_validation.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "        self.aucs_all = []\n",
    "        self.recalls_1 = []\n",
    "        self.recalls_3 = []\n",
    "        self.recalls_5 = []\n",
    "        self.recalls_10 = []\n",
    "        self.ndcgs_50 = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        \n",
    "        recall_1 = recall(y_test,y_pred,1)\n",
    "        recall_3 = recall(y_test,y_pred,3)\n",
    "        recall_5 = recall(y_test,y_pred,5)\n",
    "        recall_10 = recall(y_test,y_pred,10)\n",
    "        self.recalls_1.append(recall_1)\n",
    "        self.recalls_3.append(recall_3)\n",
    "        self.recalls_5.append(recall_5)\n",
    "        self.recalls_10.append(recall_10)\n",
    "        \n",
    "        ndcg_50 = ndcg_score(y_test,y_pred,k=50,gains=\"exponential\")\n",
    "        self.ndcgs_50.append(ndcg_50)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        auc_all = roc_auc_score(y_test, y_pred,average = None )\n",
    "        self.aucs_all.append(auc_all)\n",
    "        \n",
    "        print(\"Average AUC:\",auc)\n",
    "        print(\"Recalls:\",recall_1,recall_3,recall_5,recall_10)\n",
    "        print(\"NDCG:\",ndcg_50)\n",
    "        print(\"AUCs:\",auc_all)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, validation_data=(x_val,y_val), callbacks=[histories,checkpoint])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "pickle.dump(histories.aucs,open(os.path.join(path,'project1/timbrecnn_aucs.pkl'),'wb'))\n",
    "pickle.dump(histories.aucs_all,open(os.path.join(path,'project1/timbrecnn_aucs_all.pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(path,'project1/timbrecnn_losses.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_1,open(os.path.join(path,'project1/timbrecnn_recalls_1.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_3,open(os.path.join(path,'project1/timbrecnn_recalls_3.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_5,open(os.path.join(path,'project1/timbrecnn_recalls_5.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_10,open(os.path.join(path,'project1/timbrecnn_recalls_10.pkl'),'wb'))\n",
    "pickle.dump(histories.ndcgs_50,open(os.path.join(path,'project1/timbrecnn_ndcgs_10.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 1360, 32)      2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1360, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 1360, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 340, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 340, 32)       65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 340, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 340, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 85, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16320)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16320)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               1632100   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "=================================================================\n",
      "Total params: 1,705,054\n",
      "Trainable params: 1,704,926\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 15244 samples, validate on 1529 samples\n",
      "Epoch 1/30\n",
      "15244/15244 [==============================] - 147s 10ms/step - loss: 0.2372 - val_loss: 0.2021\n",
      "Average AUC: 0.7313412632197906\n",
      "Recalls: 0.1592537816395157 0.3217374365400681 0.4394618814805795 0.6205900081246342\n",
      "NDCG: 0.6095848797746628\n",
      "AUCs: [0.70523113 0.84704901 0.74175216 0.90307452 0.74715063 0.71537681\n",
      " 0.7737384  0.96833215 0.77408171 0.8147494  0.79222503 0.88876003\n",
      " 0.75734775 0.58356    0.64513425 0.64644885 0.65253797 0.93365509\n",
      " 0.67552926 0.52158718 0.50363453 0.487451   0.93046472 0.90019375\n",
      " 0.85104539 0.8588803  0.47466298 0.67667984 0.55303065 0.78026808\n",
      " 0.79569318 0.59539239 0.75605683 0.60373635 0.80136945 0.95381043\n",
      " 0.48993748 0.68870795 0.88903747 0.65716288 0.62162332 0.71768295\n",
      " 0.84482283 0.76019249 0.42555454 0.5892472  0.66973456 0.66983546\n",
      " 0.97409225 0.95974059]\n",
      "Epoch 2/30\n",
      "15244/15244 [==============================] - 142s 9ms/step - loss: 0.1922 - val_loss: 0.1945\n",
      "Average AUC: 0.8045301727911796\n",
      "Recalls: 0.1705668837420915 0.39818087357907306 0.52593856461585 0.6941057909721345\n",
      "NDCG: 0.6553108339295577\n",
      "AUCs: [0.80389024 0.85833011 0.79318505 0.92077188 0.82000384 0.82239865\n",
      " 0.80675908 0.97470346 0.81857143 0.88257436 0.84944806 0.91227607\n",
      " 0.81872651 0.78502768 0.7254971  0.81276875 0.68644712 0.94147993\n",
      " 0.78016336 0.74996956 0.68508187 0.60194145 0.94839003 0.90905752\n",
      " 0.88917905 0.88912574 0.71723691 0.78014651 0.55142663 0.85222709\n",
      " 0.82313776 0.77323274 0.805675   0.76131628 0.82043194 0.97648484\n",
      " 0.61458368 0.72204763 0.93521138 0.7342549  0.62898415 0.90073112\n",
      " 0.85881093 0.81793831 0.53859476 0.62152414 0.82578083 0.72701143\n",
      " 0.97713783 0.97681395]\n",
      "Epoch 3/30\n",
      "15244/15244 [==============================] - 142s 9ms/step - loss: 0.1791 - val_loss: 0.1849\n",
      "Average AUC: 0.816915100906041\n",
      "Recalls: 0.18430298669218334 0.3940573386037375 0.5188225414679708 0.6951221453472146\n",
      "NDCG: 0.6650080401469782\n",
      "AUCs: [0.80011505 0.86696263 0.78481827 0.92676893 0.8172982  0.82603237\n",
      " 0.81030622 0.97939818 0.84652098 0.86964827 0.86170745 0.91242915\n",
      " 0.84839301 0.75440348 0.72183681 0.75665286 0.75515693 0.94702199\n",
      " 0.81250978 0.78744411 0.75263725 0.57306142 0.96377647 0.90554071\n",
      " 0.85722114 0.88321047 0.75185365 0.82044549 0.56214649 0.88624891\n",
      " 0.82019875 0.81820331 0.80841649 0.80689734 0.83940399 0.97222465\n",
      " 0.68253555 0.8078297  0.94336294 0.76663487 0.67811601 0.90198998\n",
      " 0.82865512 0.88705937 0.54103007 0.65944859 0.83555843 0.64889388\n",
      " 0.97612555 0.9816038 ]\n",
      "Epoch 4/30\n",
      "15244/15244 [==============================] - 143s 9ms/step - loss: 0.1704 - val_loss: 0.1682\n",
      "Average AUC: 0.8511631006322251\n",
      "Recalls: 0.2442444847396371 0.48723129748060495 0.6146349995034206 0.7840222770970694\n",
      "NDCG: 0.7382930089579897\n",
      "AUCs: [0.83864953 0.8778724  0.80740342 0.94675073 0.83563444 0.83746222\n",
      " 0.84271671 0.98181871 0.85896758 0.89817807 0.91050514 0.91841003\n",
      " 0.8590461  0.8225449  0.79541744 0.88073454 0.73510419 0.96562554\n",
      " 0.85520768 0.84174353 0.80865336 0.6354384  0.96573426 0.90648737\n",
      " 0.8977323  0.91099861 0.81712454 0.86208926 0.61849084 0.89656402\n",
      " 0.83266104 0.83529875 0.82303578 0.85467397 0.8520068  0.97708684\n",
      " 0.77092507 0.83813175 0.94132661 0.79918422 0.81188579 0.90115298\n",
      " 0.9090926  0.84481679 0.59930356 0.70111079 0.85953702 0.81282425\n",
      " 0.9833526  0.98164196]\n",
      "Epoch 5/30\n",
      "15244/15244 [==============================] - 143s 9ms/step - loss: 0.1618 - val_loss: 0.1649\n",
      "Average AUC: 0.857207488420139\n",
      "Recalls: 0.2597730056698201 0.4893540311130339 0.6284161539701706 0.7962917231788422\n",
      "NDCG: 0.7489086750283838\n",
      "AUCs: [0.85929336 0.88970678 0.79980021 0.93639663 0.83443952 0.84917493\n",
      " 0.824848   0.98302333 0.85577958 0.91405326 0.92949626 0.91422596\n",
      " 0.86387757 0.83407514 0.79408856 0.8843663  0.78124706 0.96994597\n",
      " 0.85536598 0.8467842  0.81208125 0.6518608  0.97015301 0.90848176\n",
      " 0.89906026 0.91619593 0.86171267 0.84936867 0.62327018 0.88706924\n",
      " 0.82351842 0.86614982 0.81356037 0.8577979  0.87080014 0.97774275\n",
      " 0.77679922 0.87040237 0.93960309 0.80238698 0.84241371 0.88984504\n",
      " 0.9088303  0.8708256  0.58304161 0.70028038 0.87642911 0.82754659\n",
      " 0.9835155  0.97964316]\n",
      "Epoch 6/30\n",
      "15244/15244 [==============================] - 143s 9ms/step - loss: 0.1560 - val_loss: 0.1780\n",
      "Average AUC: 0.8520932100191462\n",
      "Recalls: 0.21388218711625914 0.43524877195237305 0.5673056655051114 0.735311219123546\n",
      "NDCG: 0.6992549932591892\n",
      "AUCs: [0.82469623 0.86571907 0.80158454 0.94568666 0.83248795 0.84502828\n",
      " 0.83482353 0.98109782 0.86157799 0.90499431 0.89859373 0.92115226\n",
      " 0.85852463 0.8342232  0.7822778  0.87570973 0.74721351 0.97553882\n",
      " 0.87345431 0.84472443 0.80952018 0.64800687 0.96022615 0.90685918\n",
      " 0.90414106 0.91429819 0.83512458 0.87063376 0.59206169 0.89194554\n",
      " 0.82350366 0.78706717 0.81667111 0.87728095 0.8516063  0.97460055\n",
      " 0.76358953 0.83538964 0.94165349 0.82223434 0.84144745 0.90633131\n",
      " 0.90913829 0.86500464 0.58398629 0.70947121 0.87761194 0.81741588\n",
      " 0.98411182 0.97461891]\n",
      "Epoch 7/30\n",
      "15244/15244 [==============================] - 142s 9ms/step - loss: 0.1515 - val_loss: 0.1862\n",
      "Average AUC: 0.8330935489877201\n",
      "Recalls: 0.19603973409375075 0.4099636999914008 0.5312208720795978 0.698078883899521\n",
      "NDCG: 0.6720927605721443\n",
      "AUCs: [0.82158271 0.87043974 0.79187204 0.93607239 0.8319021  0.84758229\n",
      " 0.81892628 0.98043058 0.85056349 0.8417883  0.8577375  0.91631799\n",
      " 0.86883993 0.80718855 0.77119319 0.83850861 0.67806555 0.95181983\n",
      " 0.85731299 0.78476298 0.75796953 0.63431887 0.95083439 0.90554432\n",
      " 0.88224602 0.93602599 0.84064331 0.83808759 0.593438   0.85506799\n",
      " 0.80283318 0.75632967 0.75774182 0.84594287 0.83201413 0.96318184\n",
      " 0.72117046 0.81352062 0.94130628 0.78275573 0.82386745 0.89513429\n",
      " 0.86369475 0.89030612 0.59832412 0.67377269 0.85423877 0.76301244\n",
      " 0.98392274 0.97452442]\n",
      "Epoch 8/30\n",
      "15244/15244 [==============================] - 142s 9ms/step - loss: 0.1471 - val_loss: 0.1611\n",
      "Average AUC: 0.8720239254490367\n",
      "Recalls: 0.2613673690370366 0.49090214315283565 0.623418568068845 0.8020703359172888\n",
      "NDCG: 0.7525336252358432\n",
      "AUCs: [0.8734989  0.88682271 0.8074555  0.95664937 0.83825565 0.86171445\n",
      " 0.86257842 0.982757   0.86656452 0.922664   0.9136705  0.92781469\n",
      " 0.87604016 0.85028861 0.80666182 0.90233178 0.81424397 0.97186375\n",
      " 0.88856392 0.86384755 0.82966465 0.66252478 0.96942123 0.90270254\n",
      " 0.89625525 0.93351985 0.89482697 0.87840898 0.61945577 0.91339853\n",
      " 0.82238825 0.90104065 0.80465768 0.90018091 0.86806554 0.98017642\n",
      " 0.79642845 0.84107572 0.94779844 0.84274366 0.86823616 0.91266261\n",
      " 0.91528791 0.91222171 0.62724514 0.73536108 0.91348533 0.87272488\n",
      " 0.98485067 0.98009925]\n",
      "Epoch 9/30\n",
      "15244/15244 [==============================] - 142s 9ms/step - loss: 0.1428 - val_loss: 0.1785\n",
      "Average AUC: 0.8529862661758009\n",
      "Recalls: 0.21616771386508227 0.4561061360922857 0.5936160446201998 0.7674060345112977\n",
      "NDCG: 0.7138056214339208\n",
      "AUCs: [0.83941684 0.88917674 0.8144074  0.9391316  0.84717886 0.84954059\n",
      " 0.84065801 0.98274665 0.85633768 0.91887166 0.91559473 0.92067846\n",
      " 0.88631429 0.8202136  0.80105629 0.86733483 0.76270781 0.95839527\n",
      " 0.86620072 0.80739347 0.79060503 0.64101407 0.96687981 0.91721377\n",
      " 0.90986462 0.92107203 0.86442468 0.84563795 0.59462309 0.88679292\n",
      " 0.81279514 0.84601585 0.84040108 0.84648647 0.85768055 0.97463649\n",
      " 0.74646879 0.85360414 0.94143453 0.80314629 0.83802733 0.89974453\n",
      " 0.90418848 0.90558905 0.55035824 0.70686187 0.83106857 0.80257786\n",
      " 0.98365803 0.98308654]\n",
      "Epoch 10/30\n",
      "15244/15244 [==============================] - 143s 9ms/step - loss: 0.1402 - val_loss: 0.1648\n",
      "Average AUC: 0.8688909861853807\n",
      "Recalls: 0.2242400694616761 0.4616457308978084 0.6072501937633517 0.7901752115741035\n",
      "NDCG: 0.7244558888590951\n",
      "AUCs: [0.85952973 0.8980479  0.81687507 0.95153681 0.85888828 0.86367173\n",
      " 0.85632453 0.98177872 0.86525353 0.90561205 0.9174644  0.92486034\n",
      " 0.88719624 0.85088382 0.81780625 0.90204613 0.79043998 0.97312534\n",
      " 0.89006213 0.86022428 0.83355398 0.64356571 0.95762598 0.90593508\n",
      " 0.90179319 0.92049324 0.90925785 0.87869674 0.62209264 0.90039672\n",
      " 0.82065121 0.86420062 0.84094516 0.88554788 0.85816933 0.97583792\n",
      " 0.79497126 0.85922724 0.94944064 0.83188349 0.87893247 0.9036892\n",
      " 0.9040311  0.91069109 0.5972588  0.72843071 0.86991654 0.85879241\n",
      " 0.98498302 0.98191089]\n",
      "Epoch 11/30\n",
      "15244/15244 [==============================] - 143s 9ms/step - loss: 0.1363 - val_loss: 0.1857\n",
      "Average AUC: 0.8386723659102635\n",
      "Recalls: 0.20119625744625746 0.4260442139424134 0.5569484737074764 0.7368748479898064\n",
      "NDCG: 0.6912135523011991\n",
      "AUCs: [0.82822761 0.86655034 0.75893117 0.94821293 0.84164576 0.86631614\n",
      " 0.85613427 0.98282099 0.83244222 0.83580865 0.86852206 0.92293669\n",
      " 0.88386002 0.82899725 0.80953084 0.83129558 0.70253714 0.94555047\n",
      " 0.88658152 0.82143394 0.81165047 0.6238017  0.9619017  0.91372674\n",
      " 0.85798829 0.89960772 0.84315421 0.86327933 0.60986312 0.88567284\n",
      " 0.73115091 0.74706114 0.76247123 0.87260918 0.80616683 0.97316166\n",
      " 0.73638946 0.83076133 0.94467826 0.82021339 0.79180249 0.89954452\n",
      " 0.85019063 0.89741419 0.59361914 0.6996026  0.83618484 0.78566941\n",
      " 0.98418163 0.9817637 ]\n",
      "Epoch 12/30\n",
      "15244/15244 [==============================] - 143s 9ms/step - loss: 0.1339 - val_loss: 0.1626\n",
      "Average AUC: 0.86987519097183\n",
      "Recalls: 0.2572707705498564 0.48620821122552427 0.6164901330586926 0.7886510720478864\n",
      "NDCG: 0.7452000311609107\n",
      "AUCs: [0.84965759 0.89850666 0.81379092 0.95121616 0.84488699 0.86499571\n",
      " 0.85054734 0.98264595 0.86965932 0.93262768 0.93557525 0.91536164\n",
      " 0.865101   0.85192559 0.80219587 0.89316635 0.80103996 0.97136196\n",
      " 0.90416145 0.85403828 0.83129498 0.6606882  0.97722812 0.90794932\n",
      " 0.9064524  0.92283655 0.89217157 0.89236157 0.62191526 0.9076205\n",
      " 0.81686039 0.87034951 0.83949227 0.906487   0.86255114 0.97232733\n",
      " 0.8034018  0.8646307  0.93622016 0.84843269 0.86282059 0.88679283\n",
      " 0.9085257  0.91350881 0.58228097 0.722656   0.89939634 0.86359946\n",
      " 0.9848274  0.97561831]\n",
      "Epoch 13/30\n",
      "15244/15244 [==============================] - 143s 9ms/step - loss: 0.1310 - val_loss: 0.1548\n",
      "Average AUC: 0.8773143994693462\n",
      "Recalls: 0.2769321398822784 0.5289325344553877 0.6594020149594942 0.8250536282738499\n",
      "NDCG: 0.77683826924103\n",
      "AUCs: [0.87153882 0.89275545 0.82670175 0.95242936 0.86809571 0.85260145\n",
      " 0.86670528 0.98151497 0.87647941 0.93986554 0.94314452 0.92351837\n",
      " 0.88794624 0.8563885  0.83376759 0.90632226 0.81228127 0.97747827\n",
      " 0.89794143 0.8649509  0.82554855 0.65823642 0.97490253 0.90796557\n",
      " 0.90919126 0.94119815 0.90773685 0.89746167 0.61400086 0.91409241\n",
      " 0.83152792 0.88578779 0.84963987 0.91147292 0.86418544 0.975234\n",
      " 0.7863945  0.87154088 0.95181009 0.85073401 0.88738615 0.90789102\n",
      " 0.91663832 0.92904685 0.58145897 0.73588986 0.89210338 0.88986072\n",
      " 0.9845656  0.97979034]\n",
      "Epoch 14/30\n",
      "15244/15244 [==============================] - 142s 9ms/step - loss: 0.1287 - val_loss: 0.1491\n",
      "Average AUC: 0.8801560845064296\n",
      "Recalls: 0.28004242922871725 0.5345235129341778 0.6668747105208325 0.8360463937160613\n",
      "NDCG: 0.7803198956352537\n",
      "AUCs: [0.87145915 0.89499923 0.8167491  0.95280017 0.867176   0.8642126\n",
      " 0.8646019  0.98295934 0.88460892 0.9291794  0.94751394 0.92455564\n",
      " 0.89485512 0.86095169 0.83055745 0.90082646 0.82338851 0.97521309\n",
      " 0.91300356 0.87483825 0.83517118 0.65697907 0.97304435 0.90181093\n",
      " 0.89916393 0.93299879 0.90358195 0.90607702 0.64998365 0.92243072\n",
      " 0.82542858 0.89711213 0.84396849 0.92045641 0.85767409 0.98111471\n",
      " 0.8016051  0.87507106 0.94606709 0.87104474 0.88408138 0.90762042\n",
      " 0.9145924  0.91567718 0.60568524 0.75717341 0.89620129 0.88779029\n",
      " 0.98260503 0.98114408]\n",
      "Epoch 15/30\n",
      "15244/15244 [==============================] - 143s 9ms/step - loss: 0.1260 - val_loss: 0.1542\n",
      "Average AUC: 0.8739812622133367\n",
      "Recalls: 0.28036213299371193 0.5225817708504689 0.661402066821042 0.8286891810610647\n",
      "NDCG: 0.776658743435128\n",
      "AUCs: [0.8710393  0.89828929 0.81392358 0.95218753 0.85359719 0.86052047\n",
      " 0.85754335 0.98139521 0.87470009 0.91989717 0.94367989 0.92495145\n",
      " 0.89354407 0.84938429 0.83115261 0.89910458 0.82003395 0.97459482\n",
      " 0.89894707 0.86758501 0.82506611 0.65412183 0.9758629  0.90307885\n",
      " 0.88821147 0.92962519 0.89639482 0.9025285  0.62932015 0.91363538\n",
      " 0.81574891 0.89973926 0.82040431 0.91215065 0.85792386 0.9767621\n",
      " 0.7944183  0.87800534 0.94740744 0.86060901 0.86903913 0.90321691\n",
      " 0.91304738 0.89725186 0.58132709 0.73898799 0.90540848 0.86007496\n",
      " 0.98528554 0.97833849]\n",
      "Epoch 16/30\n",
      "15244/15244 [==============================] - 143s 9ms/step - loss: 0.1234 - val_loss: 0.1655\n",
      "Average AUC: 0.8767767097961284\n",
      "Recalls: 0.26230179741260073 0.5191173406720498 0.6520782496717399 0.8266984765772855\n",
      "NDCG: 0.7677274118730502\n",
      "AUCs: [0.8610293  0.89290981 0.82687945 0.95421222 0.86803448 0.85195901\n",
      " 0.8629119  0.98247467 0.88009519 0.94024283 0.94301634 0.92181705\n",
      " 0.89878511 0.85631977 0.82947504 0.9089104  0.81174913 0.97481694\n",
      " 0.90599487 0.86846248 0.8395806  0.64785207 0.97419118 0.90917935\n",
      " 0.90468903 0.93521479 0.90767437 0.89875296 0.62725569 0.91781101\n",
      " 0.83336137 0.89201548 0.84249752 0.91007686 0.86130442 0.97935236\n",
      " 0.7975495  0.87000349 0.95028363 0.85935906 0.88821608 0.90059666\n",
      " 0.91482254 0.90504406 0.57804423 0.74326178 0.86765236 0.87905981\n",
      " 0.98457578 0.97946145]\n",
      "Epoch 17/30\n",
      "15244/15244 [==============================] - 143s 9ms/step - loss: 0.1217 - val_loss: 0.1920\n",
      "Average AUC: 0.8556735338593164\n",
      "Recalls: 0.22499900261326852 0.4682273674309685 0.6040782547707755 0.7661428503014376\n",
      "NDCG: 0.7209362369246002\n",
      "AUCs: [0.82583875 0.89004405 0.81475558 0.946538   0.83160885 0.84081611\n",
      " 0.85858347 0.98121499 0.86787816 0.92911014 0.92291073 0.9151969\n",
      " 0.87995959 0.81730302 0.82290824 0.85476882 0.81105804 0.94716149\n",
      " 0.87354183 0.81742274 0.79772524 0.65362748 0.96247511 0.91325657\n",
      " 0.89309481 0.92770672 0.86701369 0.86186224 0.61006693 0.90930185\n",
      " 0.81185482 0.89444444 0.84856678 0.85083878 0.81988071 0.9690786\n",
      " 0.73927191 0.84720105 0.9477437  0.81370858 0.85339016 0.89636626\n",
      " 0.88083042 0.87227505 0.57075877 0.71704302 0.84409722 0.79990506\n",
      " 0.98359259 0.97807865]\n",
      "Epoch 18/30\n",
      "15244/15244 [==============================] - 143s 9ms/step - loss: 0.1198 - val_loss: 0.1708\n",
      "Average AUC: 0.8626240691870914\n",
      "Recalls: 0.2422862065348215 0.46960100853798914 0.5983321503058345 0.7739072491323183\n",
      "NDCG: 0.7302318317322508\n",
      "AUCs: [0.8509145  0.88032292 0.80816663 0.95106837 0.84858711 0.85427027\n",
      " 0.86730181 0.97834178 0.8643632  0.92086506 0.9143917  0.92055527\n",
      " 0.88662252 0.83790714 0.82883331 0.87717386 0.81193296 0.95940698\n",
      " 0.88995877 0.83798256 0.81349444 0.63980366 0.96331161 0.91000328\n",
      " 0.89257646 0.93610741 0.88328382 0.86963312 0.62020808 0.90622163\n",
      " 0.80924432 0.85450563 0.80121988 0.87948005 0.82595065 0.98293739\n",
      " 0.77760093 0.84710738 0.94841622 0.81945018 0.87247423 0.89596121\n",
      " 0.89142049 0.91746289 0.59625892 0.72284316 0.85792375 0.84088665\n",
      " 0.98329006 0.98315923]\n",
      "Epoch 19/30\n",
      "15244/15244 [==============================] - 142s 9ms/step - loss: 0.1180 - val_loss: 0.1729\n",
      "Average AUC: 0.8654832760473784\n",
      "Recalls: 0.23914887756646758 0.4654684599282937 0.6037087015272612 0.7842820748811054\n",
      "NDCG: 0.72907042035107\n",
      "AUCs: [0.85729658 0.88088327 0.81483352 0.94034256 0.83335611 0.83934992\n",
      " 0.8507376  0.97958264 0.86134738 0.91129142 0.92384608 0.90777565\n",
      " 0.88707326 0.85247302 0.80914467 0.89507424 0.82098351 0.96334547\n",
      " 0.89622534 0.85254699 0.82870239 0.64124376 0.95464652 0.90245798\n",
      " 0.89328043 0.92874589 0.90197602 0.88449381 0.62417975 0.91723986\n",
      " 0.80685318 0.89987484 0.83872212 0.88774874 0.80987468 0.97447733\n",
      " 0.7903543  0.85520451 0.94582154 0.84192204 0.88863105 0.88260614\n",
      " 0.89652599 0.90393089 0.56806582 0.73233926 0.87961366 0.85823392\n",
      " 0.98349514 0.97539299]\n",
      "Epoch 20/30\n",
      "15244/15244 [==============================] - 141s 9ms/step - loss: 0.1159 - val_loss: 0.1630\n",
      "Average AUC: 0.8655487470823907\n",
      "Recalls: 0.26665405231887224 0.4981031600491434 0.6248792098688221 0.787962939901998\n",
      "NDCG: 0.7547124852468651\n",
      "AUCs: [0.86026365 0.89217619 0.80841716 0.94955691 0.8303933  0.86531566\n",
      " 0.86375151 0.9800706  0.86394832 0.9222241  0.93874267 0.92209769\n",
      " 0.86776639 0.82580942 0.82620735 0.87598741 0.78367833 0.96365562\n",
      " 0.90941588 0.82932703 0.79675685 0.64180403 0.96678275 0.89962612\n",
      " 0.88363618 0.91676585 0.86295153 0.89453059 0.64929675 0.91997345\n",
      " 0.81729514 0.86856951 0.82845094 0.91683125 0.85950433 0.96946752\n",
      " 0.74108373 0.8535347  0.94612652 0.85427553 0.85591443 0.91302229\n",
      " 0.90606518 0.8637987  0.6071227  0.74971245 0.90647933 0.8582399\n",
      " 0.9827112  0.96830271]\n",
      "Epoch 21/30\n",
      "15244/15244 [==============================] - 140s 9ms/step - loss: 0.1143 - val_loss: 0.1684\n",
      "Average AUC: 0.8703721754285819\n",
      "Recalls: 0.2638047490367435 0.509921465115371 0.649084626387258 0.8122395590712765\n",
      "NDCG: 0.7627308985413457\n",
      "AUCs: [0.85967255 0.89312285 0.81905279 0.9480114  0.86513613 0.86472299\n",
      " 0.86004696 0.98013272 0.85946144 0.92414049 0.9318632  0.92366635\n",
      " 0.89229213 0.84653683 0.82535323 0.88712516 0.81025775 0.97108905\n",
      " 0.89752242 0.849598   0.81340951 0.63697038 0.95895161 0.90911618\n",
      " 0.90306882 0.94904077 0.89673358 0.88433041 0.622187   0.92183368\n",
      " 0.83202366 0.87470217 0.83593089 0.90180111 0.83829292 0.97692126\n",
      " 0.78249017 0.8652153  0.94808309 0.83153109 0.88330837 0.90474302\n",
      " 0.89626538 0.91899351 0.58925767 0.73241377 0.89720565 0.84049172\n",
      " 0.98278974 0.98170192]\n",
      "Epoch 22/30\n",
      "15244/15244 [==============================] - 140s 9ms/step - loss: 0.1128 - val_loss: 0.1576\n",
      "Average AUC: 0.8683330348118029\n",
      "Recalls: 0.27703618455003504 0.514601185082487 0.6468444599157895 0.8135633987434541\n",
      "NDCG: 0.7680357185186927\n",
      "AUCs: [0.86611711 0.88612335 0.80315142 0.93476246 0.86710671 0.8697843\n",
      " 0.83768059 0.98004378 0.82348899 0.92112601 0.9340546  0.91658041\n",
      " 0.8840722  0.8317869  0.8113943  0.88639974 0.82406025 0.97077348\n",
      " 0.89607822 0.83897423 0.81383854 0.64723189 0.96983501 0.90640254\n",
      " 0.90299082 0.92983391 0.89068182 0.89436864 0.6344379  0.91192195\n",
      " 0.81899678 0.89347332 0.83920441 0.905601   0.83374747 0.98142149\n",
      " 0.78102121 0.86991628 0.93963124 0.83261361 0.88107922 0.89280312\n",
      " 0.89986987 0.90845315 0.58960937 0.74978876 0.90168151 0.84402819\n",
      " 0.98573205 0.98287758]\n",
      "Epoch 23/30\n",
      "15244/15244 [==============================] - 139s 9ms/step - loss: 0.1111 - val_loss: 0.1629\n",
      "Average AUC: 0.8729722117219592\n",
      "Recalls: 0.26722529868305495 0.5156684548651308 0.6496916896328254 0.8201887197905203\n",
      "NDCG: 0.7657880796199382\n",
      "AUCs: [0.86494946 0.89139965 0.81982796 0.95261522 0.84948426 0.85663181\n",
      " 0.85615739 0.97803263 0.86782024 0.93255898 0.93523396 0.92108375\n",
      " 0.89379847 0.84764467 0.82256372 0.88792033 0.81752943 0.97318561\n",
      " 0.90737947 0.86651104 0.82542947 0.64492293 0.9723113  0.89951512\n",
      " 0.90124325 0.93420375 0.89580321 0.90565623 0.63201741 0.92096401\n",
      " 0.82758858 0.88515505 0.85678373 0.91554108 0.83127988 0.98082719\n",
      " 0.80894652 0.85486215 0.94868366 0.84969238 0.88042456 0.89310061\n",
      " 0.89041868 0.90802412 0.58701253 0.73505763 0.88535284 0.8709357\n",
      " 0.98326679 0.98126219]\n",
      "Epoch 24/30\n",
      "15244/15244 [==============================] - 140s 9ms/step - loss: 0.1100 - val_loss: 0.1679\n",
      "Average AUC: 0.8696075428068086\n",
      "Recalls: 0.26339096870606565 0.5002200201819315 0.6346612240483431 0.8055994456963986\n",
      "NDCG: 0.7563333294641049\n",
      "AUCs: [0.84828398 0.88368504 0.81109665 0.94572831 0.85063858 0.85853577\n",
      " 0.85970874 0.97610571 0.85420638 0.92338867 0.93422345 0.91859007\n",
      " 0.88914962 0.84708485 0.82744385 0.89667854 0.80049676 0.96482444\n",
      " 0.90260179 0.85508454 0.82055424 0.6482096  0.96563209 0.90157719\n",
      " 0.89294868 0.93856174 0.90102418 0.89853172 0.64899607 0.91285699\n",
      " 0.82443121 0.85996616 0.83295429 0.90448204 0.82981784 0.98271533\n",
      " 0.79878147 0.85413222 0.94752943 0.84067015 0.89380992 0.90135299\n",
      " 0.89564772 0.89930427 0.6168905  0.74524786 0.85062729 0.8593529\n",
      " 0.98410454 0.98211077]\n",
      "Epoch 25/30\n",
      "15244/15244 [==============================] - 140s 9ms/step - loss: 0.1084 - val_loss: 0.1606\n",
      "Average AUC: 0.875845078261489\n",
      "Recalls: 0.29050032569769413 0.5327941788641235 0.6650345223925557 0.8321343393192424\n",
      "NDCG: 0.7842056125155211\n",
      "AUCs: [0.86993611 0.89723631 0.8154317  0.94856001 0.85953504 0.84929123\n",
      " 0.85420538 0.9805628  0.86702258 0.93869764 0.93861089 0.91664893\n",
      " 0.89609756 0.85666723 0.81900413 0.89945799 0.83509424 0.97455216\n",
      " 0.91244022 0.86965988 0.83842045 0.64556608 0.9685809  0.90544234\n",
      " 0.9030629  0.9440344  0.89958373 0.91185674 0.6318677  0.91993768\n",
      " 0.82398957 0.91214018 0.84613727 0.91768724 0.84306231 0.97752583\n",
      " 0.8017093  0.87089007 0.94747782 0.85886453 0.87876768 0.89195267\n",
      " 0.90949028 0.89045686 0.57385862 0.74639626 0.89937184 0.87068039\n",
      " 0.98380057 0.98092966]\n",
      "Epoch 26/30\n",
      "15244/15244 [==============================] - 140s 9ms/step - loss: 0.1074 - val_loss: 0.1598\n",
      "Average AUC: 0.8719501028368577\n",
      "Recalls: 0.27130448421999664 0.5168034361247658 0.6447085463013441 0.8146981602833404\n",
      "NDCG: 0.765437965836825\n",
      "AUCs: [0.86230638 0.89034746 0.81448165 0.94320875 0.85077102 0.86338987\n",
      " 0.85139247 0.97547517 0.85672361 0.9283478  0.93306263 0.90800527\n",
      " 0.89298672 0.84423326 0.81761392 0.8919447  0.83733752 0.97329531\n",
      " 0.904127   0.85599812 0.8212836  0.63917848 0.97184516 0.90005658\n",
      " 0.90282989 0.94168961 0.89741988 0.90423624 0.62493458 0.91536422\n",
      " 0.82410465 0.89899643 0.83344109 0.91494277 0.83125619 0.98284883\n",
      " 0.80219167 0.86262822 0.94486907 0.85200148 0.88701762 0.88669367\n",
      " 0.90730221 0.90819805 0.58931697 0.75225455 0.88118493 0.8582399\n",
      " 0.98283628 0.98329369]\n",
      "Epoch 27/30\n",
      "15244/15244 [==============================] - 140s 9ms/step - loss: 0.1057 - val_loss: 0.1576\n",
      "Average AUC: 0.8757493643783537\n",
      "Recalls: 0.28070599504117505 0.5291960604287475 0.6602341442542273 0.8297308192218164\n",
      "NDCG: 0.7787130480514355\n",
      "AUCs: [0.86996487 0.89450542 0.80802799 0.94845566 0.85146419 0.87170147\n",
      " 0.85227939 0.97999343 0.8606824  0.9320598  0.93544656 0.9217252\n",
      " 0.88752506 0.85694625 0.82338603 0.90055343 0.8367888  0.97458264\n",
      " 0.91205007 0.87065828 0.83116715 0.64250511 0.97203289 0.90222605\n",
      " 0.88771682 0.9400598  0.90138051 0.91044832 0.64134083 0.92265647\n",
      " 0.82002662 0.90732165 0.83699494 0.92259021 0.8439516  0.979826\n",
      " 0.80019665 0.86248288 0.94721819 0.86828589 0.88270763 0.89997311\n",
      " 0.91437748 0.88028757 0.59713816 0.75917402 0.87949817 0.88239283\n",
      " 0.98393729 0.97875642]\n",
      "Epoch 28/30\n",
      "15244/15244 [==============================] - 140s 9ms/step - loss: 0.1049 - val_loss: 0.1606\n",
      "Average AUC: 0.8724596536919437\n",
      "Recalls: 0.2828399158039047 0.5200670892152887 0.6503414073358672 0.8138437297543946\n",
      "NDCG: 0.774301766707906\n",
      "AUCs: [0.86176718 0.89144336 0.81274376 0.94946644 0.84963315 0.86409782\n",
      " 0.85614373 0.97852765 0.85957622 0.92360918 0.94185707 0.91437466\n",
      " 0.88530936 0.84982436 0.81703769 0.88958176 0.81964832 0.96615849\n",
      " 0.90875942 0.86302129 0.83980299 0.63715015 0.97476971 0.89913339\n",
      " 0.8955187  0.93507268 0.88838471 0.90685498 0.61013612 0.9099285\n",
      " 0.82444399 0.89613637 0.83192039 0.90963916 0.84744197 0.98165766\n",
      " 0.80769774 0.86850647 0.94957514 0.84894864 0.87942084 0.89556792\n",
      " 0.90386695 0.89310065 0.59703388 0.77181369 0.89035362 0.86281159\n",
      " 0.98201308 0.9817001 ]\n",
      "Epoch 29/30\n",
      "15244/15244 [==============================] - 140s 9ms/step - loss: 0.1035 - val_loss: 0.1653\n",
      "Average AUC: 0.8729445535964373\n",
      "Recalls: 0.2788552424286497 0.5273233396848355 0.6632138797131871 0.8262559712525087\n",
      "NDCG: 0.7771491830573367\n",
      "AUCs: [0.86471739 0.89841372 0.80695901 0.95258745 0.85335067 0.86888387\n",
      " 0.86066425 0.97957087 0.85717851 0.90899219 0.93956477 0.9163333\n",
      " 0.89290227 0.8511186  0.82333568 0.90042389 0.85226996 0.97731574\n",
      " 0.90864676 0.87076995 0.8298494  0.61763281 0.97167658 0.90505069\n",
      " 0.88929062 0.93266276 0.90177589 0.9071543  0.60911207 0.91543022\n",
      " 0.82588006 0.91060817 0.81189045 0.91760429 0.84397097 0.97715102\n",
      " 0.79784362 0.86161406 0.94508334 0.85441377 0.88025228 0.90276816\n",
      " 0.90598395 0.88675788 0.5806513  0.75646475 0.88791097 0.87401939\n",
      " 0.98410309 0.97862196]\n",
      "Epoch 30/30\n",
      "15244/15244 [==============================] - 140s 9ms/step - loss: 0.1025 - val_loss: 0.1647\n",
      "Average AUC: 0.8693902574928599\n",
      "Recalls: 0.27524892133617895 0.5145878193315866 0.640702832357957 0.8116939340796682\n",
      "NDCG: 0.7672504748821096\n",
      "AUCs: [0.86814695 0.89564503 0.80405115 0.94273807 0.84941079 0.87088128\n",
      " 0.84136018 0.97785617 0.8359061  0.92087808 0.93117031 0.91264418\n",
      " 0.87164465 0.84283224 0.81463208 0.89364067 0.83178667 0.9733935\n",
      " 0.90836276 0.85343202 0.81799054 0.62663398 0.97472629 0.89694136\n",
      " 0.88590902 0.92882435 0.89629524 0.9040179  0.65637203 0.91949483\n",
      " 0.81859842 0.90015065 0.81397031 0.91756193 0.84660006 0.97999928\n",
      " 0.79429225 0.85832289 0.94183961 0.84645652 0.87901336 0.8914098\n",
      " 0.90941751 0.8799513  0.58224416 0.7530468  0.88021907 0.86734338\n",
      " 0.98424708 0.97721008]\n"
     ]
    }
   ],
   "source": [
    "#  2 CNNs + FC + output  (MTAT)\n",
    "import numpy as np \n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Flatten,Dense,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 30\n",
    "input_shape = (96,1360,1)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(8,8),padding='same',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((4,4),padding='same'))\n",
    "\n",
    "model.add(Conv2D(32,(8,8),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((4,4),padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "filepath='C:/DT/model_save/cnn/'+\"{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_val = np.load(path+'\\\\x_validation_MelSpec.npy')\n",
    "y_val = np.load(path+'\\\\y_validation.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "        self.aucs_all = []\n",
    "        self.recalls_1 = []\n",
    "        self.recalls_3 = []\n",
    "        self.recalls_5 = []\n",
    "        self.recalls_10 = []\n",
    "        self.ndcgs_50 = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        \n",
    "        recall_1 = recall(y_test,y_pred,1)\n",
    "        recall_3 = recall(y_test,y_pred,3)\n",
    "        recall_5 = recall(y_test,y_pred,5)\n",
    "        recall_10 = recall(y_test,y_pred,10)\n",
    "        self.recalls_1.append(recall_1)\n",
    "        self.recalls_3.append(recall_3)\n",
    "        self.recalls_5.append(recall_5)\n",
    "        self.recalls_10.append(recall_10)\n",
    "        \n",
    "        ndcg_50 = ndcg_score(y_test,y_pred,k=50,gains=\"exponential\")\n",
    "        self.ndcgs_50.append(ndcg_50)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        auc_all = roc_auc_score(y_test, y_pred,average = None )\n",
    "        self.aucs_all.append(auc_all)\n",
    "        \n",
    "        print(\"Average AUC:\",auc)\n",
    "        print(\"Recalls:\",recall_1,recall_3,recall_5,recall_10)\n",
    "        print(\"NDCG:\",ndcg_50)\n",
    "        print(\"AUCs:\",auc_all)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, validation_data=(x_val,y_val), callbacks=[histories,checkpoint])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "pickle.dump(histories.aucs,open(os.path.join(path,'project1/cnn_aucs.pkl'),'wb'))\n",
    "pickle.dump(histories.aucs_all,open(os.path.join(path,'project1/cnn_aucs_all.pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(path,'project1/cnn_losses.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_1,open(os.path.join(path,'project1/cnn_recalls_1.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_3,open(os.path.join(path,'project1/cnn_recalls_3.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_5,open(os.path.join(path,'project1/cnn_recalls_5.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_10,open(os.path.join(path,'project1/cnn_recalls_10.pkl'),'wb'))\n",
    "pickle.dump(histories.ndcgs_50,open(os.path.join(path,'project1/cnn_ndcgs_10.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 1360, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1360, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 1360, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 680, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 680, 128)      73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 680, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 680, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 227, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 227, 128)      147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 227, 128)      512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 227, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 57, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 57, 128)        147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 57, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 57, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 15, 128)        0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 15, 32)            15456     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                1650      \n",
      "=================================================================\n",
      "Total params: 394,802\n",
      "Trainable params: 393,906\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 15244 samples, validate on 1529 samples\n",
      "Epoch 1/50\n",
      "15244/15244 [==============================] - 356s 23ms/step - loss: 0.2611 - val_loss: 0.2115\n",
      "Average AUC: 0.6353997826981107\n",
      "Recalls: 0.13151265926542935 0.2867986276573534 0.36101888070378374 0.5329674724065306\n",
      "NDCG: 0.5637388376730341\n",
      "AUCs: [0.69802719 0.83748539 0.63528763 0.89769908 0.69117321 0.8227831\n",
      " 0.778466   0.96878341 0.69379092 0.78290678 0.52787976 0.89765299\n",
      " 0.71511541 0.54408254 0.60518907 0.45215305 0.60501291 0.77133853\n",
      " 0.65550043 0.51858361 0.6225313  0.48049016 0.58955694 0.90360859\n",
      " 0.72397002 0.47138807 0.49442075 0.68096727 0.45944985 0.78297453\n",
      " 0.65397323 0.5324526  0.58386046 0.50400992 0.53101934 0.31581292\n",
      " 0.47176964 0.53038441 0.86710083 0.66592812 0.53309714 0.7713024\n",
      " 0.42771153 0.65233071 0.49735715 0.52278447 0.74620567 0.48696013\n",
      " 0.96761859 0.20004143]\n",
      "Epoch 2/50\n",
      "15244/15244 [==============================] - 348s 23ms/step - loss: 0.2113 - val_loss: 0.2023\n",
      "Average AUC: 0.716451052385585\n",
      "Recalls: 0.14883520859975152 0.3140683185697036 0.41052541961475475 0.5540081865912891\n",
      "NDCG: 0.5868401900061565\n",
      "AUCs: [0.7265206  0.82873926 0.65647216 0.93391693 0.70834096 0.81442783\n",
      " 0.82447274 0.97539564 0.76158931 0.70130862 0.76655469 0.92133668\n",
      " 0.75416301 0.63818086 0.66895113 0.57740225 0.63245205 0.86202713\n",
      " 0.71764846 0.65766574 0.67243324 0.45995416 0.68058956 0.86571604\n",
      " 0.78713054 0.71574444 0.55423833 0.79987449 0.52827848 0.82213417\n",
      " 0.70099748 0.54692208 0.6094638  0.74642734 0.79214289 0.76684183\n",
      " 0.58430283 0.54479097 0.92906643 0.71480667 0.58786254 0.91047514\n",
      " 0.36757253 0.76633813 0.50757582 0.58174898 0.75394306 0.61047737\n",
      " 0.97498237 0.81215487]\n",
      "Epoch 3/50\n",
      "15244/15244 [==============================] - 347s 23ms/step - loss: 0.1968 - val_loss: 0.1823\n",
      "Average AUC: 0.8054421780755588\n",
      "Recalls: 0.19241400719932578 0.40858732744120557 0.534830793885503 0.7072996793910921\n",
      "NDCG: 0.6731168605237144\n",
      "AUCs: [0.79550229 0.89617152 0.68324615 0.94564411 0.77299378 0.81999395\n",
      " 0.85233011 0.97930313 0.78746285 0.87433482 0.89569143 0.92391346\n",
      " 0.81041157 0.74314872 0.77579619 0.77643887 0.76506306 0.92385422\n",
      " 0.78592805 0.76345415 0.76608441 0.48923266 0.9327073  0.87491912\n",
      " 0.76989372 0.81704414 0.77880197 0.83582674 0.53057317 0.81604404\n",
      " 0.73296074 0.76266398 0.84619454 0.81742514 0.84810086 0.94257912\n",
      " 0.73978285 0.78683272 0.94031784 0.77900393 0.71342507 0.90062355\n",
      " 0.7705282  0.83819573 0.50076678 0.6874372  0.82283075 0.75170291\n",
      " 0.98281737 0.92610992]\n",
      "Epoch 4/50\n",
      "15244/15244 [==============================] - 348s 23ms/step - loss: 0.1848 - val_loss: 0.1764\n",
      "Average AUC: 0.825896891436786\n",
      "Recalls: 0.22550491085809646 0.42293824724572643 0.5596633988254487 0.7399187396936705\n",
      "NDCG: 0.7003563845147778\n",
      "AUCs: [0.84217844 0.8897816  0.73805946 0.93137812 0.79341339 0.81676804\n",
      " 0.83640816 0.98275041 0.80381559 0.89017953 0.92200112 0.92008584\n",
      " 0.78294282 0.81005607 0.77564627 0.82326678 0.68318793 0.95561002\n",
      " 0.78988167 0.83045389 0.81035899 0.57911297 0.96954894 0.88010048\n",
      " 0.8108867  0.86228647 0.8057376  0.83951408 0.58897129 0.86831282\n",
      " 0.75195025 0.77956473 0.87105637 0.82277288 0.83990354 0.93325521\n",
      " 0.78028673 0.82592227 0.93331894 0.8021806  0.78072717 0.88099096\n",
      " 0.86867672 0.81539889 0.49000932 0.68107375 0.86586761 0.80506914\n",
      " 0.98053247 0.95359157]\n",
      "Epoch 5/50\n",
      "15244/15244 [==============================] - 347s 23ms/step - loss: 0.1763 - val_loss: 0.1715\n",
      "Average AUC: 0.8389757494939587\n",
      "Recalls: 0.20107196012666928 0.399788949892828 0.5528336775566692 0.7520976900651417\n",
      "NDCG: 0.6887104806114468\n",
      "AUCs: [0.76719435 0.88059679 0.78439321 0.93461825 0.83173324 0.81344563\n",
      " 0.84099438 0.97864812 0.83777467 0.88141089 0.93678987 0.91479088\n",
      " 0.86027165 0.84409758 0.79910045 0.85756156 0.69903192 0.93706233\n",
      " 0.83450564 0.85672949 0.83522459 0.64991536 0.97041864 0.87817873\n",
      " 0.81613831 0.85302869 0.8603674  0.85071491 0.6719335  0.86972773\n",
      " 0.76098467 0.72028693 0.85145598 0.82859891 0.84711253 0.95359736\n",
      " 0.79040136 0.85536277 0.94315024 0.79267552 0.86212248 0.8763471\n",
      " 0.85387973 0.8916628  0.58076785 0.70069286 0.73486028 0.81152176\n",
      " 0.98330025 0.96360736]\n",
      "Epoch 6/50\n",
      "15244/15244 [==============================] - 346s 23ms/step - loss: 0.1702 - val_loss: 0.1736\n",
      "Average AUC: 0.8152000938996192\n",
      "Recalls: 0.202829443947865 0.41914017230845485 0.5656341644915052 0.7269251556128288\n",
      "NDCG: 0.6864513482388523\n",
      "AUCs: [0.82205182 0.86312403 0.77743076 0.94317247 0.81498506 0.81805952\n",
      " 0.84236089 0.97334591 0.83708284 0.8803527  0.92142843 0.91743107\n",
      " 0.86586103 0.7312846  0.79056229 0.7070631  0.71937216 0.94780481\n",
      " 0.79699558 0.74417738 0.74315209 0.63234896 0.96913389 0.87466914\n",
      " 0.83473567 0.85142109 0.70442757 0.78957019 0.64250075 0.77033908\n",
      " 0.78180368 0.8109002  0.85844611 0.78286607 0.82934843 0.95026005\n",
      " 0.66990151 0.81599788 0.9474872  0.73680153 0.69932736 0.88683485\n",
      " 0.8839543  0.92896568 0.58690211 0.7156802  0.77999335 0.61567537\n",
      " 0.98387329 0.96874063]\n",
      "Epoch 7/50\n",
      "15244/15244 [==============================] - 348s 23ms/step - loss: 0.1667 - val_loss: 0.1571\n",
      "Average AUC: 0.8563203391301751\n",
      "Recalls: 0.23439669107951655 0.49120605528154004 0.6253631640750754 0.7909198437245529\n",
      "NDCG: 0.7377889359827743\n",
      "AUCs: [0.83490524 0.89574033 0.80681281 0.95575906 0.84902473 0.82418834\n",
      " 0.86748892 0.98108418 0.83271179 0.90235712 0.94273373 0.91653157\n",
      " 0.89410882 0.84442557 0.81786607 0.87219356 0.74443118 0.97532686\n",
      " 0.84040348 0.84670359 0.8361203  0.66569961 0.973499   0.88308349\n",
      " 0.85345645 0.87885247 0.87634759 0.8425724  0.67093649 0.85503099\n",
      " 0.81250301 0.80286933 0.87322364 0.82375771 0.85917704 0.97359166\n",
      " 0.81022723 0.84409397 0.94721976 0.79519781 0.85382161 0.90011093\n",
      " 0.86072316 0.93814935 0.63406645 0.73002884 0.78180259 0.83206242\n",
      " 0.98410745 0.97888725]\n",
      "Epoch 8/50\n",
      "15244/15244 [==============================] - 349s 23ms/step - loss: 0.1626 - val_loss: 0.1484\n",
      "Average AUC: 0.8702485175297389\n",
      "Recalls: 0.25085044674726115 0.5007712861417847 0.6396959432277991 0.8106470309725158\n",
      "NDCG: 0.7531552613443326\n",
      "AUCs: [0.8776518  0.90112531 0.80802887 0.93970215 0.8608985  0.82549861\n",
      " 0.85163792 0.98398279 0.83430447 0.90800712 0.94444176 0.91283225\n",
      " 0.91663843 0.8784134  0.82122348 0.90231584 0.77286964 0.96685937\n",
      " 0.88920827 0.88782323 0.85886612 0.67375501 0.97815018 0.89608494\n",
      " 0.84122836 0.86061077 0.90623148 0.89467664 0.70161282 0.90932899\n",
      " 0.80636728 0.79105363 0.87432989 0.88747695 0.85722406 0.97842176\n",
      " 0.81332482 0.86653468 0.93728837 0.84740275 0.89480016 0.89142492\n",
      " 0.89147802 0.91825139 0.67014207 0.72798007 0.82332768 0.8642916\n",
      " 0.98628764 0.98100961]\n",
      "Epoch 9/50\n",
      "15244/15244 [==============================] - 347s 23ms/step - loss: 0.1601 - val_loss: 0.1543\n",
      "Average AUC: 0.8673694634513709\n",
      "Recalls: 0.24583114510399826 0.4770474197240125 0.6081915583646885 0.7765901400077301\n",
      "NDCG: 0.7362483225689528\n",
      "AUCs: [0.8872317  0.89505199 0.81096224 0.93534062 0.84862707 0.8325619\n",
      " 0.84467029 0.98289299 0.82877643 0.91923954 0.91540735 0.91662123\n",
      " 0.85590886 0.87742708 0.79598686 0.90312828 0.80039862 0.97261136\n",
      " 0.88786277 0.88507492 0.85413536 0.65706546 0.97934426 0.8855273\n",
      " 0.83700456 0.88396838 0.89760341 0.89177015 0.69243471 0.90330794\n",
      " 0.81392531 0.87165902 0.85600755 0.89083208 0.85965721 0.98069498\n",
      " 0.81756025 0.81492882 0.93397426 0.86223083 0.88904302 0.8927964\n",
      " 0.89694905 0.86387987 0.66689602 0.70740336 0.82433553 0.88046602\n",
      " 0.9848303  0.98245965]\n",
      "Epoch 10/50\n",
      "15244/15244 [==============================] - 346s 23ms/step - loss: 0.1581 - val_loss: 0.1472\n",
      "Average AUC: 0.8810755046451958\n",
      "Recalls: 0.25697286003726444 0.5149917462244331 0.6587575282519881 0.8294535264930002\n",
      "NDCG: 0.761940104920267\n",
      "AUCs: [0.87052886 0.90048463 0.80978418 0.96023435 0.8309044  0.8225632\n",
      " 0.88482521 0.98153685 0.8541669  0.91697799 0.9507663  0.91915427\n",
      " 0.89040156 0.87713862 0.85308558 0.90693475 0.85412831 0.97441131\n",
      " 0.88808345 0.88437378 0.85773269 0.68323155 0.97783601 0.89160704\n",
      " 0.86709247 0.88696746 0.90996367 0.89945717 0.70853211 0.92053349\n",
      " 0.81831416 0.90070227 0.87586868 0.89342476 0.87526592 0.97874908\n",
      " 0.82027127 0.87746434 0.94595292 0.84119777 0.89139801 0.90954654\n",
      " 0.86673909 0.93690863 0.67912366 0.74974697 0.91276793 0.87926925\n",
      " 0.98501356 0.98261228]\n",
      "Epoch 11/50\n",
      "15244/15244 [==============================] - 347s 23ms/step - loss: 0.1559 - val_loss: 0.1471\n",
      "Average AUC: 0.8782167128727228\n",
      "Recalls: 0.2509075239165267 0.5083406314881385 0.6484878649871724 0.8254735850996238\n",
      "NDCG: 0.7581614204748197\n",
      "AUCs: [0.887156   0.89635699 0.82678796 0.94882692 0.86147597 0.85433832\n",
      " 0.85616002 0.98268877 0.86515665 0.9332482  0.93513718 0.9260587\n",
      " 0.89947336 0.87910093 0.82222449 0.9117038  0.82168704 0.97053444\n",
      " 0.88658897 0.88411012 0.86039751 0.67868054 0.97688841 0.88563018\n",
      " 0.84030125 0.88242739 0.91860053 0.8918815  0.70350808 0.90653866\n",
      " 0.81969809 0.88179437 0.86640533 0.88507311 0.86280953 0.98164226\n",
      " 0.82055867 0.84519211 0.94897144 0.84404618 0.90957724 0.89508555\n",
      " 0.90270607 0.95739796 0.66271552 0.70675103 0.86855523 0.88811941\n",
      " 0.98645054 0.98361713]\n",
      "Epoch 12/50\n",
      "15244/15244 [==============================] - 349s 23ms/step - loss: 0.1539 - val_loss: 0.1427\n",
      "Average AUC: 0.8833912307203342\n",
      "Recalls: 0.2810374906462164 0.5260606833148384 0.6610938358860796 0.8331328041508097\n",
      "NDCG: 0.7802164077918817\n",
      "AUCs: [0.90058564 0.91056903 0.81635008 0.96309829 0.83827886 0.85038821\n",
      " 0.87971131 0.9850039  0.85506722 0.92832508 0.94215615 0.92291263\n",
      " 0.84280046 0.88202891 0.83775991 0.91261125 0.84652906 0.97685661\n",
      " 0.90615595 0.88860078 0.85925138 0.6808367  0.97857162 0.89781492\n",
      " 0.85567004 0.84473162 0.91372808 0.91228331 0.70511021 0.92637691\n",
      " 0.82794071 0.93636722 0.87147385 0.9036737  0.87477714 0.97631156\n",
      " 0.81822414 0.86349543 0.9492858  0.87402944 0.90602229 0.91089953\n",
      " 0.90406833 0.9145872  0.65443221 0.75436783 0.90818708 0.89504375\n",
      " 0.98546589 0.98074432]\n",
      "Epoch 13/50\n",
      "15244/15244 [==============================] - 348s 23ms/step - loss: 0.1516 - val_loss: 0.1593\n",
      "Average AUC: 0.860970684541567\n",
      "Recalls: 0.23580746482408532 0.46172553080447815 0.5952343138804357 0.7605344454201796\n",
      "NDCG: 0.7213399100703198\n",
      "AUCs: [0.8515975  0.90612125 0.79510151 0.95427581 0.81469052 0.83156447\n",
      " 0.86913714 0.97841613 0.84622403 0.90496051 0.92952097 0.92140229\n",
      " 0.86313232 0.82168777 0.8280693  0.85641895 0.84633693 0.95732261\n",
      " 0.85098775 0.83419807 0.82172664 0.66713721 0.97284896 0.89591754\n",
      " 0.87937486 0.87809456 0.87100459 0.84299753 0.66273903 0.85690108\n",
      " 0.80761449 0.87162889 0.87514374 0.84016979 0.87242152 0.97318733\n",
      " 0.78957948 0.84708639 0.94717597 0.78468712 0.85516689 0.90633971\n",
      " 0.88008414 0.90992579 0.64188764 0.75558891 0.89712166 0.81914921\n",
      " 0.98450306 0.98016466]\n",
      "Epoch 14/50\n",
      "15244/15244 [==============================] - 349s 23ms/step - loss: 0.1497 - val_loss: 0.1397\n",
      "Average AUC: 0.891716116628879\n",
      "Recalls: 0.28481383574873875 0.541550897420011 0.6823809801822267 0.8437397276213066\n",
      "NDCG: 0.7891011201983132\n",
      "AUCs: [0.89174958 0.91392761 0.81334546 0.95714155 0.86671002 0.85606148\n",
      " 0.88313021 0.98304404 0.84947415 0.92574053 0.95142212 0.92214215\n",
      " 0.91824188 0.88463805 0.86205155 0.91381829 0.89410802 0.97721891\n",
      " 0.9193977  0.88961933 0.85923124 0.68591452 0.97484889 0.89709568\n",
      " 0.87067944 0.91051899 0.91136264 0.92187328 0.71488904 0.92975195\n",
      " 0.82072989 0.94010105 0.87976615 0.93043179 0.87835365 0.97916881\n",
      " 0.82918081 0.86937045 0.94908248 0.89555897 0.90066665 0.90483882\n",
      " 0.90272299 0.93605056 0.68297087 0.77113955 0.89704817 0.90291355\n",
      " 0.98470231 0.98186001]\n",
      "Epoch 15/50\n",
      "15244/15244 [==============================] - 349s 23ms/step - loss: 0.1477 - val_loss: 0.1484\n",
      "Average AUC: 0.8723953364232563\n",
      "Recalls: 0.2765622541765201 0.5178291096919906 0.6477857335544316 0.8093258727780889\n",
      "NDCG: 0.768101052100359\n",
      "AUCs: [0.88391619 0.90591136 0.82899876 0.96211931 0.87580853 0.85900655\n",
      " 0.88038353 0.97780159 0.86280106 0.94534545 0.93859596 0.92313131\n",
      " 0.88854582 0.84634806 0.8516257  0.8794604  0.88718742 0.96852998\n",
      " 0.86165676 0.85818383 0.83355223 0.65346969 0.97972484 0.89242375\n",
      " 0.84228085 0.90097404 0.89112406 0.85302564 0.66328628 0.87051721\n",
      " 0.81856104 0.94164697 0.87171499 0.85307142 0.85339779 0.98210178\n",
      " 0.79083667 0.8506198  0.94484092 0.81321405 0.87011925 0.91125752\n",
      " 0.91576174 0.89101345 0.62788311 0.75390083 0.8617242  0.83074796\n",
      " 0.98553425 0.98608292]\n",
      "Epoch 16/50\n",
      "15244/15244 [==============================] - 349s 23ms/step - loss: 0.1470 - val_loss: 0.1518\n",
      "Average AUC: 0.8747818589310544\n",
      "Recalls: 0.2419865638875334 0.46322288886347057 0.6069207845350504 0.792229539338265\n",
      "NDCG: 0.7299536190876484\n",
      "AUCs: [0.88038778 0.90421179 0.81671831 0.95437703 0.84782788 0.87048058\n",
      " 0.87904487 0.98216551 0.86160537 0.93876302 0.9354795  0.91718761\n",
      " 0.87864432 0.85604046 0.85947859 0.88842255 0.86264257 0.96514881\n",
      " 0.87102589 0.86622891 0.85023816 0.66087195 0.97123471 0.90289476\n",
      " 0.85606892 0.889068   0.9049155  0.86955214 0.66593951 0.88780321\n",
      " 0.82585448 0.91546146 0.87616257 0.85251723 0.86384738 0.97782105\n",
      " 0.81204242 0.86916697 0.94833645 0.81187648 0.87751977 0.90228243\n",
      " 0.9019141  0.88762755 0.62007009 0.76516678 0.922773   0.84639382\n",
      " 0.9847314  0.98305929]\n",
      "Epoch 17/50\n",
      "15244/15244 [==============================] - 349s 23ms/step - loss: 0.1446 - val_loss: 0.1500\n",
      "Average AUC: 0.8827927033443079\n",
      "Recalls: 0.2745288279741188 0.5259188840040642 0.6555445234461854 0.8198853495944909\n",
      "NDCG: 0.7733076661942594\n",
      "AUCs: [0.88650209 0.91354918 0.80553077 0.95975023 0.87236235 0.83839058\n",
      " 0.89373066 0.9794283  0.83778099 0.933036   0.93924972 0.91808784\n",
      " 0.92632248 0.87911214 0.86060909 0.91338716 0.85581181 0.97137415\n",
      " 0.89947409 0.88005693 0.85756414 0.68734714 0.97619495 0.88949352\n",
      " 0.83811432 0.88636646 0.91266593 0.90347564 0.71499346 0.89645053\n",
      " 0.82655678 0.91627266 0.8854722  0.90235    0.87323759 0.98089779\n",
      " 0.81338196 0.85332961 0.94601548 0.86306413 0.89487506 0.90850785\n",
      " 0.88588685 0.93548237 0.657849   0.75518188 0.86366293 0.88340411\n",
      " 0.98562006 0.98237424]\n",
      "Epoch 18/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1429 - val_loss: 0.1439\n",
      "Average AUC: 0.889166671652959\n",
      "Recalls: 0.2866371406883872 0.5395165494195965 0.6748122094382482 0.8347512028086821\n",
      "NDCG: 0.7863869243214542\n",
      "AUCs: [0.89399727 0.914384   0.83256848 0.96747012 0.84781789 0.865402\n",
      " 0.90315801 0.98363835 0.86530934 0.94920206 0.94927705 0.92614471\n",
      " 0.8979058  0.87028749 0.87532597 0.91134508 0.87310848 0.97415804\n",
      " 0.9008587  0.87458887 0.85165485 0.68568233 0.97978614 0.90357068\n",
      " 0.88018941 0.92691773 0.9192595  0.90591217 0.71390902 0.91243758\n",
      " 0.83398792 0.92201131 0.86383113 0.90418553 0.87046423 0.98532998\n",
      " 0.82834381 0.87616112 0.95475667 0.85435731 0.896096   0.91622239\n",
      " 0.89557156 0.89377319 0.68530802 0.78400817 0.89586884 0.87343896\n",
      " 0.98445215 0.98489818]\n",
      "Epoch 19/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1414 - val_loss: 0.1451\n",
      "Average AUC: 0.8894287529815083\n",
      "Recalls: 0.2857042529133942 0.5268425505960131 0.6621926729267449 0.8259003756579935\n",
      "NDCG: 0.7806580074560499\n",
      "AUCs: [0.89392586 0.90533013 0.81772906 0.96616556 0.86721403 0.85198288\n",
      " 0.90142937 0.98430042 0.86105517 0.94442687 0.95212788 0.92159691\n",
      " 0.90958387 0.88472713 0.87520861 0.91051337 0.86063979 0.97293979\n",
      " 0.91430436 0.89102245 0.86044042 0.68695965 0.97320527 0.89131239\n",
      " 0.87150485 0.88400539 0.89832681 0.92172145 0.6928203  0.93336754\n",
      " 0.83051678 0.91519492 0.8765062  0.92408863 0.86106972 0.97991842\n",
      " 0.81188107 0.87196721 0.95174128 0.88722402 0.89261296 0.90915157\n",
      " 0.90394648 0.90771104 0.67337892 0.78873078 0.92921209 0.88901499\n",
      " 0.985207   0.982476  ]\n",
      "Epoch 20/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1397 - val_loss: 0.1434\n",
      "Average AUC: 0.8886043383131232\n",
      "Recalls: 0.2914039753721194 0.5463557416985395 0.675608533382079 0.8311665250723423\n",
      "NDCG: 0.7898562781948885\n",
      "AUCs: [0.89880772 0.9135543  0.82824224 0.96149547 0.87732957 0.88026902\n",
      " 0.90194339 0.98332849 0.86930288 0.94812225 0.94691783 0.92841242\n",
      " 0.92984395 0.86845702 0.86451017 0.91527777 0.81594544 0.97793469\n",
      " 0.89456978 0.87138965 0.8406488  0.68847366 0.97315546 0.90234427\n",
      " 0.87794817 0.91343592 0.91765259 0.89496585 0.70228965 0.91022949\n",
      " 0.82960989 0.90570389 0.87735171 0.89739938 0.86652168 0.98468819\n",
      " 0.82519244 0.8788572  0.95460809 0.83915346 0.88840334 0.91802077\n",
      " 0.87734186 0.93658395 0.67976264 0.79931714 0.92933107 0.87604793\n",
      " 0.98508774 0.98443664]\n",
      "Epoch 21/50\n",
      "15244/15244 [==============================] - 351s 23ms/step - loss: 0.1387 - val_loss: 0.1396\n",
      "Average AUC: 0.8909208256178861\n",
      "Recalls: 0.2658924376895291 0.532788211198876 0.6704119018869711 0.8477094920827607\n",
      "NDCG: 0.7759419923197949\n",
      "AUCs: [0.86005207 0.91230483 0.81499327 0.95962439 0.8501784  0.87056996\n",
      " 0.88634151 0.98251231 0.86533987 0.92330113 0.95425133 0.9286639\n",
      " 0.91121794 0.88202832 0.86101949 0.92366064 0.87985907 0.97314227\n",
      " 0.91433509 0.88512698 0.85796515 0.66751871 0.97556278 0.89737814\n",
      " 0.88018842 0.91287711 0.92584428 0.92093193 0.70805153 0.93494775\n",
      " 0.82517088 0.93145367 0.87198779 0.92644305 0.87337539 0.98214542\n",
      " 0.82630509 0.86419306 0.94847878 0.88014485 0.90962069 0.91567111\n",
      " 0.89575263 0.92893089 0.66048264 0.77825709 0.94005704 0.90160308\n",
      " 0.98381802 0.98236152]\n",
      "Epoch 22/50\n",
      "15244/15244 [==============================] - 351s 23ms/step - loss: 0.1364 - val_loss: 0.1399\n",
      "Average AUC: 0.88897356203136\n",
      "Recalls: 0.288050179532174 0.5459337061830136 0.6748693256830376 0.8379831220897703\n",
      "NDCG: 0.7889013327705461\n",
      "AUCs: [0.89595008 0.91404771 0.82534441 0.95392291 0.87495972 0.8792142\n",
      " 0.86961174 0.98301674 0.85877198 0.94268389 0.93955705 0.92522699\n",
      " 0.8875525  0.87646849 0.85155755 0.91572485 0.87284448 0.96411475\n",
      " 0.91095598 0.88605778 0.8558839  0.67511323 0.97537761 0.89637553\n",
      " 0.87792052 0.91640465 0.92394255 0.91141281 0.71665912 0.92894767\n",
      " 0.82331481 0.92802346 0.86850478 0.91229008 0.86505534 0.98669314\n",
      " 0.81827288 0.84816515 0.95425775 0.86615981 0.90510247 0.90156644\n",
      " 0.92954507 0.92617115 0.68295758 0.75672459 0.92638799 0.87288445\n",
      " 0.98559097 0.98538879]\n",
      "Epoch 23/50\n",
      "15244/15244 [==============================] - 351s 23ms/step - loss: 0.1354 - val_loss: 0.1461\n",
      "Average AUC: 0.8837986226013507\n",
      "Recalls: 0.29480787820469256 0.5477037697605565 0.6778263512162404 0.8244840134729331\n",
      "NDCG: 0.78911153546179\n",
      "AUCs: [0.89934956 0.91291007 0.82767889 0.96171133 0.87084969 0.88039903\n",
      " 0.89084732 0.98273018 0.86527827 0.95278442 0.94239217 0.92948176\n",
      " 0.91804448 0.84609617 0.86206556 0.89489753 0.88753849 0.96617812\n",
      " 0.87674775 0.85695873 0.83857368 0.66707879 0.98046428 0.89601275\n",
      " 0.87955357 0.93707404 0.90708765 0.87480985 0.67860054 0.90497942\n",
      " 0.82849448 0.93006536 0.8737421  0.87817753 0.85982516 0.98171543\n",
      " 0.80199334 0.87279404 0.94960173 0.81833651 0.87802163 0.9158291\n",
      " 0.92709132 0.92772495 0.6452758  0.77565865 0.91222201 0.85453189\n",
      " 0.98515028 0.98450569]\n",
      "Epoch 24/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1338 - val_loss: 0.1499\n",
      "Average AUC: 0.885519174683759\n",
      "Recalls: 0.27302425247369844 0.5273309401945137 0.66503035092024 0.831403659052551\n",
      "NDCG: 0.7765579202467399\n",
      "AUCs: [0.87949552 0.89707643 0.82968016 0.95679492 0.87959566 0.87217834\n",
      " 0.87635915 0.97714846 0.86946425 0.95252956 0.9316421  0.92954007\n",
      " 0.92835661 0.8809252  0.85901822 0.91778287 0.78962725 0.96759344\n",
      " 0.9221455  0.882466   0.85358112 0.68925962 0.9751158  0.88882752\n",
      " 0.88536993 0.93192853 0.92162201 0.92410015 0.70432644 0.90643257\n",
      " 0.8319371  0.8116465  0.867602   0.92867569 0.8613927  0.98382178\n",
      " 0.8067851  0.83285586 0.94890731 0.89095246 0.91011206 0.9038371\n",
      " 0.90301406 0.94673006 0.69043013 0.74182447 0.87844832 0.89084407\n",
      " 0.98394601 0.98221252]\n",
      "Epoch 25/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1314 - val_loss: 0.1427\n",
      "Average AUC: 0.8922456194981515\n",
      "Recalls: 0.29336793298012137 0.5585206319278341 0.691862008413255 0.8536921379892294\n",
      "NDCG: 0.7981733968661332\n",
      "AUCs: [0.89633225 0.91031898 0.82718522 0.96043856 0.85705659 0.879169\n",
      " 0.89277305 0.98294993 0.86787552 0.94541526 0.94355943 0.92892121\n",
      " 0.90572989 0.88112695 0.86630624 0.91735439 0.89048255 0.97216916\n",
      " 0.91775051 0.88428309 0.85122844 0.67820067 0.97765594 0.89979849\n",
      " 0.86836514 0.93749593 0.91636004 0.92092036 0.70145808 0.93545598\n",
      " 0.82634432 0.93394753 0.87816255 0.93077595 0.87036734 0.98230459\n",
      " 0.82062254 0.85859904 0.94573709 0.87724388 0.89919853 0.91871996\n",
      " 0.90116443 0.91559601 0.67326032 0.78221834 0.92392084 0.89300425\n",
      " 0.98472413 0.98223251]\n",
      "Epoch 26/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1301 - val_loss: 0.1444\n",
      "Average AUC: 0.8867550483225728\n",
      "Recalls: 0.29070429288573335 0.5456439451591806 0.6799627837023959 0.8447492482637912\n",
      "NDCG: 0.7910279340955783\n",
      "AUCs: [0.9004739  0.8982438  0.83765934 0.95795035 0.87983349 0.86539997\n",
      " 0.87929663 0.97987438 0.87322008 0.95682275 0.93308219 0.92506735\n",
      " 0.9217433  0.86649854 0.85247831 0.90999853 0.87251967 0.96821103\n",
      " 0.89830365 0.87881839 0.85223536 0.67220605 0.97736604 0.89031565\n",
      " 0.8919732  0.9373405  0.91954163 0.89703943 0.70216762 0.91526245\n",
      " 0.84311874 0.90355537 0.86715739 0.89239051 0.85000646 0.98026113\n",
      " 0.79900333 0.84213348 0.94537268 0.83959542 0.90005843 0.90409257\n",
      " 0.92186228 0.93719852 0.66901336 0.76709653 0.92042134 0.87763964\n",
      " 0.98478085 0.9820508 ]\n",
      "Epoch 27/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1284 - val_loss: 0.1390\n",
      "Average AUC: 0.8930623311401099\n",
      "Recalls: 0.29323172723449725 0.5524834289030964 0.6851958431944581 0.8511420411178029\n",
      "NDCG: 0.7962926653680245\n",
      "AUCs: [0.9005311  0.90709586 0.82527316 0.96471948 0.87333298 0.86919874\n",
      " 0.89598908 0.98236691 0.86199709 0.95607702 0.93673659 0.92547993\n",
      " 0.92838934 0.8792021  0.86880499 0.91987344 0.87175394 0.97145405\n",
      " 0.91449432 0.89014665 0.85986341 0.67673709 0.98255999 0.90190929\n",
      " 0.88317115 0.92929804 0.92281792 0.91937891 0.71016002 0.9259908\n",
      " 0.82816694 0.89627544 0.86442946 0.92394391 0.87023599 0.97958854\n",
      " 0.81701906 0.86235207 0.95085136 0.87810054 0.90770314 0.91136341\n",
      " 0.9290154  0.93678108 0.67740504 0.78186037 0.92753233 0.88967123\n",
      " 0.98390529 0.98211258]\n",
      "Epoch 28/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1265 - val_loss: 0.1637\n",
      "Average AUC: 0.8799644614506638\n",
      "Recalls: 0.2756561062308985 0.5282277612610021 0.6561402611956629 0.8199229005323188\n",
      "NDCG: 0.7739800341454635\n",
      "AUCs: [0.88087309 0.9004866  0.83184469 0.94972037 0.86676351 0.86382612\n",
      " 0.87243254 0.97754419 0.85791035 0.93808655 0.94321865 0.92203281\n",
      " 0.9286564  0.87435959 0.85149395 0.9226137  0.70366638 0.96788666\n",
      " 0.90002346 0.87360307 0.84268365 0.68685379 0.97760614 0.89844483\n",
      " 0.89458568 0.92944163 0.9252683  0.89716234 0.70446986 0.90537787\n",
      " 0.83955513 0.72913132 0.86876401 0.8946355  0.86421558 0.97941012\n",
      " 0.80356819 0.8698097  0.95008813 0.85515362 0.89469379 0.89716461\n",
      " 0.91791427 0.92934833 0.67487159 0.76315708 0.9241868  0.88698646\n",
      " 0.98327843 0.98335365]\n",
      "Epoch 29/50\n",
      "15244/15244 [==============================] - 349s 23ms/step - loss: 0.1247 - val_loss: 0.1531\n",
      "Average AUC: 0.8789075467835171\n",
      "Recalls: 0.2776876504023318 0.5275290973005655 0.6549537290707651 0.8052088217773813\n",
      "NDCG: 0.7705512735958042\n",
      "AUCs: [0.90451804 0.90597318 0.820917   0.94714125 0.86753531 0.8520098\n",
      " 0.86941833 0.97972474 0.86616754 0.94956772 0.91906844 0.91171917\n",
      " 0.89583366 0.8473798  0.85062317 0.89989112 0.87704633 0.96854352\n",
      " 0.87664067 0.86226809 0.838867   0.65751037 0.97673388 0.91255086\n",
      " 0.89571518 0.91971312 0.91270888 0.8694943  0.68735029 0.92095784\n",
      " 0.82544284 0.90657535 0.86151088 0.87798516 0.86260928 0.98241626\n",
      " 0.79127198 0.83768604 0.9458059  0.82857755 0.88743109 0.89453931\n",
      " 0.92502509 0.89284555 0.65209301 0.75433694 0.91616595 0.87079608\n",
      " 0.98397801 0.98469648]\n",
      "Epoch 30/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1228 - val_loss: 0.1436\n",
      "Average AUC: 0.8894733272360614\n",
      "Recalls: 0.30403111239330083 0.5604994459218836 0.6887345034159438 0.8449077116840275\n",
      "NDCG: 0.8013923167407503\n",
      "AUCs: [0.90514947 0.91149068 0.82003944 0.96031541 0.8575593  0.8755495\n",
      " 0.89588817 0.98144133 0.87806973 0.94617262 0.94618376 0.92459428\n",
      " 0.91253532 0.87671802 0.86637363 0.91711325 0.85941379 0.97173237\n",
      " 0.90931438 0.87785778 0.84414062 0.68108338 0.97804163 0.89120274\n",
      " 0.86675184 0.9239068  0.92555434 0.90951564 0.69502315 0.92777084\n",
      " 0.81750662 0.90380105 0.87419424 0.91693008 0.86238319 0.98279748\n",
      " 0.80750109 0.85994264 0.94663952 0.87451423 0.89663531 0.91723923\n",
      " 0.91407288 0.91240724 0.68333892 0.79097489 0.92678343 0.88131972\n",
      " 0.9827272  0.98545421]\n",
      "Epoch 31/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1211 - val_loss: 0.1642\n",
      "Average AUC: 0.8768078504139634\n",
      "Recalls: 0.24928966014492332 0.5055777267515494 0.637559396717984 0.8031596532635313\n",
      "NDCG: 0.7500840523387363\n",
      "AUCs: [0.88474664 0.89924185 0.82464366 0.951063   0.83518006 0.86682045\n",
      " 0.8716284  0.97809145 0.87289523 0.9436202  0.93804412 0.90787187\n",
      " 0.86845305 0.86388941 0.85579104 0.90621797 0.74185202 0.96882252\n",
      " 0.90427878 0.87525054 0.83993258 0.69068675 0.97036118 0.89545955\n",
      " 0.87555389 0.92219262 0.9148205  0.90670748 0.69413119 0.92583044\n",
      " 0.82721088 0.82983591 0.85039645 0.90341073 0.85119504 0.98519392\n",
      " 0.81250966 0.85849084 0.94246364 0.87150033 0.88555099 0.89305187\n",
      " 0.90744605 0.85222635 0.66953887 0.77057262 0.89516544 0.87437643\n",
      " 0.98031139 0.98586669]\n",
      "Epoch 32/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1189 - val_loss: 0.1595\n",
      "Average AUC: 0.8798633254236354\n",
      "Recalls: 0.26997989250413074 0.512580222691026 0.6515609717306393 0.8150358054790187\n",
      "NDCG: 0.764826808207888\n",
      "AUCs: [0.87814207 0.89788723 0.81208928 0.95503804 0.85609562 0.86294905\n",
      " 0.88297464 0.97965887 0.86457223 0.93395957 0.93657031 0.91560874\n",
      " 0.90042868 0.87271612 0.86382945 0.9125674  0.84985045 0.9686749\n",
      " 0.90371264 0.87760839 0.84883986 0.6606882  0.96829994 0.89504263\n",
      " 0.84491209 0.89643396 0.91801576 0.90921343 0.65664125 0.91071675\n",
      " 0.82619579 0.90002086 0.87677297 0.91651091 0.86067353 0.97978877\n",
      " 0.81695855 0.84954185 0.94485812 0.85997625 0.89496494 0.88442973\n",
      " 0.90110351 0.91274351 0.61947507 0.76946965 0.90197897 0.87706918\n",
      " 0.98448415 0.9824124 ]\n",
      "Epoch 33/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1179 - val_loss: 0.1548\n",
      "Average AUC: 0.8812630601016932\n",
      "Recalls: 0.2819920358701522 0.5327981126803842 0.6643698746364952 0.8250219085572272\n",
      "NDCG: 0.7791922454006752\n",
      "AUCs: [0.89330964 0.90457525 0.81698556 0.95346388 0.84478774 0.87261205\n",
      " 0.88403947 0.98102159 0.86734954 0.92813006 0.9360262  0.91660811\n",
      " 0.90367464 0.86544085 0.85436486 0.91254482 0.85017526 0.97075452\n",
      " 0.89440496 0.87010324 0.84535943 0.67047333 0.96789638 0.89820478\n",
      " 0.87411535 0.89298635 0.92116806 0.89110788 0.68214825 0.91044783\n",
      " 0.82087842 0.8889955  0.86301124 0.90214704 0.86945222 0.97992098\n",
      " 0.80367407 0.84731086 0.95234967 0.85315408 0.89474173 0.89714444\n",
      " 0.88344155 0.95149583 0.63470032 0.79025532 0.90840055 0.88098263\n",
      " 0.9831868  0.98362985]\n",
      "Epoch 34/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1161 - val_loss: 0.1602\n",
      "Average AUC: 0.8828073598497136\n",
      "Recalls: 0.2675316949901438 0.5232190356324705 0.6553072094623341 0.8152837966896139\n",
      "NDCG: 0.7679863500851629\n",
      "AUCs: [0.90405851 0.8903707  0.81889463 0.94288317 0.85756639 0.84054948\n",
      " 0.8647375  0.97438724 0.86334389 0.95254951 0.91399893 0.90801256\n",
      " 0.92370988 0.88224777 0.83414959 0.92085661 0.82953509 0.97178926\n",
      " 0.91901873 0.88215952 0.84763068 0.66106071 0.9732257  0.88914518\n",
      " 0.87889798 0.91589987 0.92430767 0.91991827 0.7014996  0.92682223\n",
      " 0.82305514 0.87056738 0.8577061  0.92268375 0.85409328 0.98155626\n",
      " 0.82475041 0.81052982 0.94438892 0.8784802  0.90908587 0.89050388\n",
      " 0.91312353 0.95453386 0.67154477 0.72804003 0.91413974 0.89470566\n",
      " 0.98286101 0.98079156]\n",
      "Epoch 35/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1146 - val_loss: 0.1618\n",
      "Average AUC: 0.8785600697041861\n",
      "Recalls: 0.2789819380885863 0.5265355348457842 0.6624513099755481 0.8233601572071101\n",
      "NDCG: 0.7760129887375371\n",
      "AUCs: [0.89341113 0.87845638 0.82372493 0.95065098 0.86595659 0.85502139\n",
      " 0.87531325 0.97080444 0.86596483 0.95200434 0.91685387 0.91137366\n",
      " 0.92737174 0.86512407 0.84263701 0.92196534 0.83839075 0.96177576\n",
      " 0.89208363 0.87477612 0.84831538 0.67287417 0.97112999 0.88592979\n",
      " 0.87324453 0.92574533 0.92289016 0.88576919 0.68159093 0.90086547\n",
      " 0.82325481 0.88255226 0.86403459 0.88695894 0.83349554 0.98087597\n",
      " 0.79414266 0.82343613 0.94581529 0.84343289 0.89789519 0.89431578\n",
      " 0.90539674 0.91653525 0.66171359 0.76267919 0.90699025 0.88448919\n",
      " 0.98374094 0.98423313]\n",
      "Epoch 36/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1131 - val_loss: 0.1657\n",
      "Average AUC: 0.8799503384527254\n",
      "Recalls: 0.271340575911213 0.522412088270814 0.650767490050731 0.8064410050040244\n",
      "NDCG: 0.7676565684417472\n",
      "AUCs: [0.89815992 0.89101493 0.8120277  0.94920087 0.86376591 0.85309102\n",
      " 0.87700194 0.9782185  0.87739264 0.94694217 0.90037846 0.91580191\n",
      " 0.92926337 0.8725067  0.84874457 0.91283047 0.86660253 0.96022231\n",
      " 0.90241836 0.87773267 0.84650118 0.67690986 0.97688713 0.89060804\n",
      " 0.85578655 0.93031797 0.92180164 0.90317342 0.69495018 0.90570723\n",
      " 0.79958433 0.89115329 0.84005745 0.89955259 0.8522049  0.98394243\n",
      " 0.81326431 0.82851015 0.93989556 0.85828239 0.89677463 0.89926384\n",
      " 0.90898599 0.90294527 0.67761361 0.74730662 0.88026106 0.87638502\n",
      " 0.98233596 0.98323736]\n",
      "Epoch 37/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1113 - val_loss: 0.1639\n",
      "Average AUC: 0.88450234320079\n",
      "Recalls: 0.26616080774668033 0.5159445977486143 0.6522135983181689 0.8197621957144118\n",
      "NDCG: 0.7664719467118163\n",
      "AUCs: [0.87068953 0.88489829 0.82261548 0.95415445 0.86459926 0.8732776\n",
      " 0.87737195 0.9677496  0.87254984 0.9498536  0.92037185 0.92169459\n",
      " 0.91768558 0.8880058  0.84850681 0.91853287 0.85104327 0.97028727\n",
      " 0.91186105 0.88432676 0.86936083 0.67572442 0.96852344 0.87142848\n",
      " 0.85976746 0.92425763 0.91782051 0.9172229  0.68472977 0.91082161\n",
      " 0.8295253  0.8611876  0.86254704 0.92843566 0.83950088 0.98046009\n",
      " 0.82504118 0.83666542 0.94427475 0.87867684 0.90456466 0.90478672\n",
      " 0.89511466 0.93812616 0.68144139 0.76084211 0.92659446 0.89909185\n",
      " 0.97776905 0.98073886]\n",
      "Epoch 38/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1104 - val_loss: 0.1646\n",
      "Average AUC: 0.8764748125086871\n",
      "Recalls: 0.2736868939258136 0.5214490662205343 0.6479246720243951 0.8048561196933773\n",
      "NDCG: 0.7668272456196311\n",
      "AUCs: [0.90024679 0.89464955 0.80686084 0.94362256 0.85347312 0.86019443\n",
      " 0.87462474 0.97583326 0.87300895 0.94945968 0.92164387 0.91244664\n",
      " 0.90609407 0.86425809 0.85356791 0.90595225 0.79684917 0.96920581\n",
      " 0.88957793 0.8696221  0.8381893  0.67086381 0.97411967 0.89305004\n",
      " 0.87041385 0.91685614 0.91444269 0.88771553 0.6813909  0.91466726\n",
      " 0.80412072 0.82729801 0.84200167 0.89227579 0.84469876 0.98492951\n",
      " 0.80241185 0.83588703 0.94200852 0.83941435 0.88348514 0.89940502\n",
      " 0.92044926 0.94993043 0.66934666 0.74601285 0.92642998 0.86503958\n",
      " 0.97996233 0.98573222]\n",
      "Epoch 39/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1088 - val_loss: 0.1760\n",
      "Average AUC: 0.8698101802017646\n",
      "Recalls: 0.2727242600684429 0.5228817081656417 0.6496137025742289 0.8077408497422348\n",
      "NDCG: 0.7685583844045695\n",
      "AUCs: [0.88064499 0.88578469 0.82554339 0.95355658 0.86227516 0.84973612\n",
      " 0.86874716 0.97758984 0.86784288 0.94434875 0.92440204 0.91785823\n",
      " 0.92073204 0.86164011 0.8143928  0.91492569 0.76220884 0.96796589\n",
      " 0.88263349 0.86999072 0.83601874 0.63328423 0.97156931 0.88522228\n",
      " 0.86891409 0.92810344 0.9176604  0.88615672 0.63943866 0.88768109\n",
      " 0.81622203 0.77404626 0.86602553 0.89163512 0.84198786 0.98417861\n",
      " 0.80468083 0.81467528 0.94431854 0.83700985 0.88860858 0.90485731\n",
      " 0.89295705 0.94160482 0.61055585 0.74838779 0.87766793 0.87781616\n",
      " 0.98039139 0.98601387]\n",
      "Epoch 40/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1074 - val_loss: 0.1545\n",
      "Average AUC: 0.885569581814217\n",
      "Recalls: 0.28966104814442767 0.5499639781322607 0.6776548039013413 0.8367744290181963\n",
      "NDCG: 0.7901666780475514\n",
      "AUCs: [0.90090004 0.89006079 0.82209718 0.95661176 0.85517978 0.87136323\n",
      " 0.88064632 0.97606524 0.87898742 0.94999709 0.93069929 0.92201823\n",
      " 0.89205885 0.87564322 0.85520649 0.9162151  0.86234402 0.97042067\n",
      " 0.91294955 0.87994441 0.84991332 0.66628883 0.97288982 0.88085176\n",
      " 0.87313493 0.92996862 0.91902227 0.91221824 0.68286534 0.91750138\n",
      " 0.82159842 0.89221017 0.86507753 0.91922978 0.84619525 0.98586523\n",
      " 0.81750815 0.84808117 0.94670833 0.86945991 0.89391479 0.9029564\n",
      " 0.91127391 0.93002087 0.66619978 0.77298753 0.9277143  0.89397364\n",
      " 0.98011068 0.98333003]\n",
      "Epoch 41/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1064 - val_loss: 0.1499\n",
      "Average AUC: 0.8848832430241594\n",
      "Recalls: 0.29407667586337943 0.5542102256264306 0.6838121756923695 0.8439211879481963\n",
      "NDCG: 0.7961918596121299\n",
      "AUCs: [0.89205934 0.89624004 0.81571601 0.95793513 0.83899941 0.86855173\n",
      " 0.88326161 0.97687036 0.8797935  0.94063952 0.91987715 0.92130388\n",
      " 0.88632168 0.87473712 0.85329305 0.92082339 0.87775815 0.97124887\n",
      " 0.91930272 0.88356768 0.8543779  0.63562615 0.97339683 0.89204653\n",
      " 0.86990142 0.92193356 0.92369947 0.92402495 0.67333182 0.92366182\n",
      " 0.81418695 0.8977356  0.8546888  0.92957756 0.85295422 0.98047421\n",
      " 0.83260446 0.82109775 0.94568391 0.8828414  0.90533018 0.90274295\n",
      " 0.90556596 0.91618738 0.65665486 0.77606749 0.93090935 0.904603\n",
      " 0.98219342 0.98176189]\n",
      "Epoch 42/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1050 - val_loss: 0.1662\n",
      "Average AUC: 0.8790756619035155\n",
      "Recalls: 0.276825030668521 0.5165317324770233 0.6369853106522081 0.8035526761634795\n",
      "NDCG: 0.767608027402074\n",
      "AUCs: [0.89217538 0.89608213 0.80951253 0.95769643 0.84062809 0.86090086\n",
      " 0.88287426 0.9801793  0.87135204 0.94346895 0.930602   0.91247726\n",
      " 0.90312731 0.86591336 0.86146851 0.9061801  0.8490861  0.96654922\n",
      " 0.8977566  0.86777142 0.83508537 0.63502694 0.96454145 0.88538201\n",
      " 0.86619894 0.91222577 0.90245731 0.91037458 0.67992276 0.9343618\n",
      " 0.81501613 0.84374681 0.86308811 0.9189474  0.85475216 0.97922913\n",
      " 0.80703049 0.82436147 0.94751223 0.87405085 0.89526906 0.89570238\n",
      " 0.90953766 0.90166976 0.66197123 0.76718012 0.93310703 0.87936898\n",
      " 0.97939219 0.98147115]\n",
      "Epoch 43/50\n",
      "15244/15244 [==============================] - 351s 23ms/step - loss: 0.1040 - val_loss: 0.1603\n",
      "Average AUC: 0.8841912177600243\n",
      "Recalls: 0.29294628309517506 0.5510013961364376 0.6808711384542409 0.8361258015863279\n",
      "NDCG: 0.7932267503261089\n",
      "AUCs: [0.89113881 0.89005134 0.81787544 0.9517061  0.85144421 0.86772494\n",
      " 0.88055224 0.96898716 0.87384504 0.95080764 0.92556234 0.92161659\n",
      " 0.91015231 0.88444456 0.85171278 0.92451095 0.86439933 0.97061028\n",
      " 0.9115277  0.88779636 0.85659487 0.65054154 0.97423077 0.87190948\n",
      " 0.85011137 0.91162625 0.92426276 0.91428604 0.6954144  0.91097704\n",
      " 0.81662432 0.86544755 0.8704505  0.92231488 0.84733646 0.98228919\n",
      " 0.83207167 0.8238447  0.94096377 0.86812819 0.91222435 0.90624895\n",
      " 0.9090063  0.94677644 0.67706561 0.75429696 0.9115991  0.90472068\n",
      " 0.97829701 0.98343361]\n",
      "Epoch 44/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1027 - val_loss: 0.1662\n",
      "Average AUC: 0.8810793895118074\n",
      "Recalls: 0.28621969622662147 0.5383565880103276 0.6645104517161304 0.8268431251983883\n",
      "NDCG: 0.782446779778237\n",
      "AUCs: [0.88246258 0.89315711 0.8141822  0.95578459 0.84961961 0.8705207\n",
      " 0.87890664 0.97632452 0.87418885 0.94163179 0.9307482  0.91535362\n",
      " 0.89013872 0.87430119 0.83929323 0.91259065 0.86314845 0.96820358\n",
      " 0.90490543 0.88016105 0.85633395 0.67699875 0.96962557 0.88311327\n",
      " 0.85582407 0.93121355 0.91653284 0.90468885 0.68406175 0.92188549\n",
      " 0.80894531 0.87163352 0.86455305 0.90937619 0.84564188 0.98264987\n",
      " 0.81091465 0.8433818  0.94184117 0.86286944 0.8934354  0.90590272\n",
      " 0.89592694 0.90526438 0.66245992 0.77596574 0.91460167 0.88009103\n",
      " 0.97679458 0.98581944]\n",
      "Epoch 45/50\n",
      "15244/15244 [==============================] - 351s 23ms/step - loss: 0.1023 - val_loss: 0.1535\n",
      "Average AUC: 0.8865497993843351\n",
      "Recalls: 0.2915839758118151 0.5562959822828244 0.6894277089741079 0.8524941637822524\n",
      "NDCG: 0.7964322983749649\n",
      "AUCs: [0.89410174 0.88702551 0.81405659 0.95809187 0.85212223 0.87400409\n",
      " 0.8914428  0.97592737 0.87874418 0.94969625 0.92752621 0.92498644\n",
      " 0.92117328 0.87466339 0.86074917 0.92062809 0.88073814 0.97373142\n",
      " 0.90345192 0.88217631 0.85480869 0.67895917 0.96883122 0.88454274\n",
      " 0.86336925 0.9120585  0.92287259 0.91028058 0.68013788 0.92061244\n",
      " 0.80667515 0.88196125 0.85749661 0.92446103 0.83649283 0.98365106\n",
      " 0.82396719 0.84879173 0.94875404 0.86491375 0.90362686 0.90813473\n",
      " 0.91390873 0.93520408 0.68355362 0.78440429 0.91953597 0.89724682\n",
      " 0.97811666 0.98508352]\n",
      "Epoch 46/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.1013 - val_loss: 0.1624\n",
      "Average AUC: 0.8845163986682419\n",
      "Recalls: 0.282926075412225 0.543217679903968 0.6774332014809855 0.8398231519942047\n",
      "NDCG: 0.7865752925502922\n",
      "AUCs: [0.88585909 0.88750041 0.81912845 0.95865526 0.84207694 0.85275838\n",
      " 0.8878657  0.9804254  0.86354396 0.95060874 0.90988072 0.91378496\n",
      " 0.91689705 0.88002973 0.8523405  0.92327867 0.88824064 0.97622683\n",
      " 0.91659497 0.8903339  0.86022065 0.66461104 0.96256706 0.8837531\n",
      " 0.85878112 0.93031649 0.9224899  0.92015108 0.68434984 0.93757155\n",
      " 0.81771908 0.88300422 0.8516293  0.92515818 0.84549976 0.98394757\n",
      " 0.81248109 0.8339007  0.9480565  0.88286282 0.9079668  0.89211738\n",
      " 0.90163995 0.87814239 0.67480616 0.76332789 0.93388742 0.90495006\n",
      " 0.98029976 0.98358079]\n",
      "Epoch 47/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.0997 - val_loss: 0.1694\n",
      "Average AUC: 0.877061963780003\n",
      "Recalls: 0.27027577108948303 0.5204330827426397 0.6463311734433618 0.807827431494329\n",
      "NDCG: 0.7664277281128741\n",
      "AUCs: [0.88232241 0.89240695 0.81687331 0.95567532 0.81634562 0.88069359\n",
      " 0.88263249 0.97826838 0.86699205 0.94654714 0.92852694 0.92107864\n",
      " 0.87268442 0.87283764 0.85258129 0.91127599 0.84747585 0.97037869\n",
      " 0.90285227 0.87284399 0.8395053  0.63571404 0.96297318 0.86743789\n",
      " 0.85791721 0.92008615 0.90355657 0.91003765 0.65570904 0.91578795\n",
      " 0.80674892 0.8332244  0.87163662 0.91896328 0.84410878 0.9807168\n",
      " 0.78374399 0.82006259 0.94312678 0.86074919 0.89295751 0.91303573\n",
      " 0.91833564 0.89751855 0.66726203 0.78249635 0.92321394 0.89234004\n",
      " 0.98049029 0.9823488 ]\n",
      "Epoch 48/50\n",
      "15244/15244 [==============================] - 351s 23ms/step - loss: 0.0998 - val_loss: 0.1613\n",
      "Average AUC: 0.8851770505589138\n",
      "Recalls: 0.2922114582606272 0.5501704743394493 0.6728567850278376 0.83169579599635\n",
      "NDCG: 0.7905232006870971\n",
      "AUCs: [0.89243126 0.89016514 0.8141903  0.95682806 0.8437069  0.87687044\n",
      " 0.88283116 0.97944971 0.87424729 0.94227945 0.92905664 0.92088621\n",
      " 0.91403533 0.87782055 0.85146215 0.91813428 0.87507671 0.96773158\n",
      " 0.91035074 0.87903335 0.8529796  0.63875803 0.97500469 0.87411956\n",
      " 0.86350451 0.92843059 0.91475802 0.91697274 0.67264619 0.9317269\n",
      " 0.80669383 0.88519446 0.87239019 0.92280377 0.85108953 0.97977722\n",
      " 0.81519715 0.82075054 0.94682407 0.87686422 0.90677583 0.91049447\n",
      " 0.91916146 0.93317486 0.67447695 0.79269567 0.92270301 0.8976258\n",
      " 0.98052374 0.9781477 ]\n",
      "Epoch 49/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.0978 - val_loss: 0.1681\n",
      "Average AUC: 0.8791638240686614\n",
      "Recalls: 0.2938864075290668 0.5392798606441266 0.6677270181598436 0.8260006062983902\n",
      "NDCG: 0.7859854426711483\n",
      "AUCs: [0.89114658 0.89240459 0.81393167 0.95641336 0.84616505 0.85641902\n",
      " 0.88145676 0.97773759 0.8634434  0.94265453 0.93101176 0.91517868\n",
      " 0.88886989 0.8646669  0.85433192 0.90273368 0.85480973 0.97077822\n",
      " 0.90090525 0.87531688 0.84597759 0.66771196 0.97346452 0.88020561\n",
      " 0.84127674 0.9168295  0.90960344 0.90327609 0.66408389 0.92202735\n",
      " 0.7981522  0.8740648  0.86245209 0.90592398 0.8543775  0.98247145\n",
      " 0.81639719 0.85316489 0.94488784 0.84857093 0.87708683 0.90283875\n",
      " 0.91576174 0.89656772 0.67332166 0.78984284 0.9270109  0.87072028\n",
      " 0.97730218 0.98244329]\n",
      "Epoch 50/50\n",
      "15244/15244 [==============================] - 350s 23ms/step - loss: 0.0977 - val_loss: 0.1674\n",
      "Average AUC: 0.8801441125405347\n",
      "Recalls: 0.28547302125903234 0.5386643583665744 0.6653906342964514 0.8276883460747726\n",
      "NDCG: 0.784013916629987\n",
      "AUCs: [0.87960759 0.88693297 0.79595497 0.95353329 0.85064502 0.85729507\n",
      " 0.87487807 0.96978993 0.86581689 0.94814885 0.89137245 0.91795663\n",
      " 0.92824894 0.88023443 0.83551406 0.91780479 0.87201102 0.97051819\n",
      " 0.90650048 0.88826239 0.85596358 0.66150312 0.97310565 0.87842059\n",
      " 0.87045038 0.93156882 0.91881433 0.90683039 0.67526167 0.91909022\n",
      " 0.80280662 0.85305243 0.86292986 0.91254776 0.8403288  0.9847113\n",
      " 0.80947259 0.79346352 0.94841622 0.86729099 0.90837128 0.89812095\n",
      " 0.91300338 0.92235622 0.67003574 0.75726063 0.92121573 0.89951072\n",
      " 0.97606301 0.98421314]\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + 2RNN + output  (MTAT)\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Flatten,Dense,Dropout,Reshape,GRU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 50\n",
    "input_shape = (96,1360,1)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((3,3),padding='same'))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((4,4),padding='same'))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((4,4),padding='same'))\n",
    "model.add(Reshape((15, 128)))\n",
    "\n",
    "model.add(GRU(32,return_sequences=True))\n",
    "model.add(GRU(32))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "filepath='C:/DT/model_save/crnn/'+\"{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath,monitor = 'loss')\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_val = np.load(path+'\\\\x_validation_MelSpec.npy')\n",
    "y_val = np.load(path+'\\\\y_validation.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "        self.aucs_all = []\n",
    "        self.recalls_1 = []\n",
    "        self.recalls_3 = []\n",
    "        self.recalls_5 = []\n",
    "        self.recalls_10 = []\n",
    "        self.ndcgs_50 = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        \n",
    "        recall_1 = recall(y_test,y_pred,1)\n",
    "        recall_3 = recall(y_test,y_pred,3)\n",
    "        recall_5 = recall(y_test,y_pred,5)\n",
    "        recall_10 = recall(y_test,y_pred,10)\n",
    "        self.recalls_1.append(recall_1)\n",
    "        self.recalls_3.append(recall_3)\n",
    "        self.recalls_5.append(recall_5)\n",
    "        self.recalls_10.append(recall_10)\n",
    "        \n",
    "        ndcg_50 = ndcg_score(y_test,y_pred,k=50,gains=\"exponential\")\n",
    "        self.ndcgs_50.append(ndcg_50)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        auc_all = roc_auc_score(y_test, y_pred,average = None )\n",
    "        self.aucs_all.append(auc_all)\n",
    "        \n",
    "        print(\"Average AUC:\",auc)\n",
    "        print(\"Recalls:\",recall_1,recall_3,recall_5,recall_10)\n",
    "        print(\"NDCG:\",ndcg_50)\n",
    "        print(\"AUCs:\",auc_all)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, validation_data=(x_val,y_val), callbacks=[histories,checkpoint])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "pickle.dump(histories.aucs,open(os.path.join(path,'project1/crnn_aucs.pkl'),'wb'))\n",
    "pickle.dump(histories.aucs_all,open(os.path.join(path,'project1/crnn_aucs_all.pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(path,'project1/crnn_losses.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_1,open(os.path.join(path,'project1/crnn_recalls_1.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_3,open(os.path.join(path,'project1/crnn_recalls_3.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_5,open(os.path.join(path,'project1/crnn_recalls_5.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_10,open(os.path.join(path,'project1/crnn_recalls_10.pkl'),'wb'))\n",
    "pickle.dump(histories.ndcgs_50,open(os.path.join(path,'project1/crnn_ndcgs_10.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 1360, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 1360, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 1360, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 48, 340, 64)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 48, 340, 128) 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 48, 340, 128) 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 48, 340, 128) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 85, 128)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 24, 85, 128)  147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 85, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 85, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 22, 128)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 12, 22, 128)  147584      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12, 22, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 12, 22, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 128)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 6, 6, 128)    0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 6, 6, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 6, 6, 128)    0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 6, 128)    0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 6, 128)    0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 6, 768)       0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 6, 768)       0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 6, 768)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 6, 768)       0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 6, 768)       0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 6, 768)       0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 6, 768)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 6, 768)       0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 32)           76896       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 32)           76896       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, 32)           76896       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     (None, 32)           76896       reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_5 (GRU)                     (None, 32)           76896       reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_6 (GRU)                     (None, 32)           76896       reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_7 (GRU)                     (None, 32)           76896       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_8 (GRU)                     (None, 32)           76896       reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           gru_1[0][0]                      \n",
      "                                                                 gru_2[0][0]                      \n",
      "                                                                 gru_3[0][0]                      \n",
      "                                                                 gru_4[0][0]                      \n",
      "                                                                 gru_5[0][0]                      \n",
      "                                                                 gru_6[0][0]                      \n",
      "                                                                 gru_7[0][0]                      \n",
      "                                                                 gru_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50)           3250        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,006,322\n",
      "Trainable params: 1,005,426\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Train on 15244 samples, validate on 1529 samples\n",
      "Epoch 1/50\n",
      "15244/15244 [==============================] - 332s 22ms/step - loss: 0.2091 - val_loss: 0.1858\n",
      "Average AUC: 0.7975221354911204\n",
      "Recalls: 0.1516085586722706 0.32382644991717013 0.4482143894886277 0.6415563827267429\n",
      "NDCG: 0.613997141501963\n",
      "AUCs: [0.76669515 0.88104039 0.79731178 0.91397992 0.77408203 0.83404383\n",
      " 0.82256172 0.97851401 0.80996675 0.82987    0.92018705 0.91875408\n",
      " 0.77428586 0.73684974 0.76947132 0.76584552 0.57626898 0.94538727\n",
      " 0.7961529  0.77874743 0.75988355 0.5785532  0.90525997 0.89461848\n",
      " 0.87061724 0.81838677 0.58851875 0.8402877  0.5649293  0.89512321\n",
      " 0.7991122  0.5673643  0.81924983 0.78941043 0.83330821 0.97020558\n",
      " 0.62004941 0.82970518 0.91858139 0.72942058 0.66029632 0.90130088\n",
      " 0.88159362 0.77546382 0.5604123  0.64426863 0.87686305 0.66134035\n",
      " 0.97945183 0.95251494]\n",
      "Epoch 2/50\n",
      "15244/15244 [==============================] - 315s 21ms/step - loss: 0.1738 - val_loss: 0.1747\n",
      "Average AUC: 0.85376881629369\n",
      "Recalls: 0.22878277590881468 0.4392353049382135 0.5755937711616382 0.7627003908167342\n",
      "NDCG: 0.7124324544409161\n",
      "AUCs: [0.76066383 0.89236206 0.80395157 0.93215333 0.8149451  0.84105683\n",
      " 0.8434788  0.98018165 0.82472154 0.92314047 0.94131089 0.92781688\n",
      " 0.83787398 0.8547819  0.80419184 0.8621559  0.73290928 0.95979162\n",
      " 0.84975306 0.85090036 0.84057701 0.66792668 0.96210092 0.9035039\n",
      " 0.8950517  0.87507179 0.87423206 0.86489597 0.65437299 0.90754401\n",
      " 0.82710465 0.78076299 0.86490421 0.83558803 0.85947849 0.97765675\n",
      " 0.79867727 0.84894676 0.93991276 0.77680776 0.84850941 0.91426098\n",
      " 0.84152803 0.92847866 0.61343691 0.69317193 0.87100138 0.82903259\n",
      " 0.98253812 0.9732252 ]\n",
      "Epoch 3/50\n",
      "15244/15244 [==============================] - 314s 21ms/step - loss: 0.1625 - val_loss: 0.1630\n",
      "Average AUC: 0.862686213548613\n",
      "Recalls: 0.21906569179768626 0.43147387072248566 0.5759729811842 0.7691482205852012\n",
      "NDCG: 0.7066479698845121\n",
      "AUCs: [0.84641779 0.88695344 0.82082552 0.94300409 0.82420023 0.83927933\n",
      " 0.84475859 0.97898409 0.85403843 0.89295966 0.93812133 0.93041989\n",
      " 0.84869386 0.83865455 0.80320673 0.89353172 0.77525253 0.97252874\n",
      " 0.86821012 0.85790086 0.83105507 0.65422869 0.96875076 0.90878137\n",
      " 0.87391295 0.88597122 0.88728448 0.87620236 0.65936871 0.90536923\n",
      " 0.82313383 0.82706624 0.85959756 0.8628703  0.85753413 0.96761018\n",
      " 0.81430804 0.84818453 0.94085585 0.8078745  0.87505393 0.90814313\n",
      " 0.87558107 0.90061456 0.63273224 0.71721927 0.90075764 0.84663716\n",
      " 0.98199126 0.97767889]\n",
      "Epoch 4/50\n",
      "15244/15244 [==============================] - 313s 21ms/step - loss: 0.1566 - val_loss: 0.1685\n",
      "Average AUC: 0.8657731010904907\n",
      "Recalls: 0.24266616860107168 0.4457152291639826 0.5728094760989498 0.7487741284313306\n",
      "NDCG: 0.7172562295145067\n",
      "AUCs: [0.81762222 0.90490957 0.79717455 0.95135857 0.82218808 0.84101976\n",
      " 0.85278526 0.97874176 0.845558   0.93295124 0.93779806 0.91853686\n",
      " 0.79974792 0.86476718 0.80832084 0.88522259 0.81229647 0.95955393\n",
      " 0.88598466 0.8610539  0.8462709  0.66124396 0.97962012 0.91248408\n",
      " 0.88401778 0.87565059 0.89129588 0.88071103 0.65998515 0.90299214\n",
      " 0.80280269 0.88471933 0.86701572 0.8682904  0.86198269 0.97673257\n",
      " 0.8100474  0.87552646 0.94828953 0.81497216 0.87338507 0.91579045\n",
      " 0.86574575 0.86948052 0.66657602 0.71831498 0.88296268 0.85386968\n",
      " 0.98051938 0.97976854]\n",
      "Epoch 5/50\n",
      "15244/15244 [==============================] - 314s 21ms/step - loss: 0.1526 - val_loss: 0.1590\n",
      "Average AUC: 0.873523878621568\n",
      "Recalls: 0.2519098553032071 0.4879423804112169 0.6262583670305277 0.7911363964341803\n",
      "NDCG: 0.7447704936676325\n",
      "AUCs: [0.84296144 0.89882404 0.81719808 0.94686045 0.87126153 0.83135878\n",
      " 0.85287724 0.98037882 0.86029779 0.93960791 0.93947211 0.9268044\n",
      " 0.90828232 0.87087798 0.82211394 0.90990121 0.70198012 0.97552527\n",
      " 0.89763137 0.8774732  0.84722354 0.66385203 0.98262895 0.89757668\n",
      " 0.90897503 0.9250037  0.90705543 0.88323867 0.65263813 0.92359521\n",
      " 0.83144924 0.7746929  0.86893582 0.88592028 0.86065846 0.98174751\n",
      " 0.82778581 0.85633333 0.9335598  0.85126747 0.89789969 0.8963461\n",
      " 0.92687471 0.90561224 0.67096304 0.71861661 0.87757345 0.87894811\n",
      " 0.98442016 0.9831138 ]\n",
      "Epoch 6/50\n",
      "15244/15244 [==============================] - 313s 21ms/step - loss: 0.1492 - val_loss: 0.1471\n",
      "Average AUC: 0.8791950819793709\n",
      "Recalls: 0.27515290444653323 0.5122164577496988 0.6442446762737623 0.8149140820193451\n",
      "NDCG: 0.7671590316354051\n",
      "AUCs: [0.88649713 0.90534589 0.82387482 0.9445375  0.85833013 0.86643904\n",
      " 0.84450684 0.98071056 0.86139213 0.94877601 0.93673298 0.9285757\n",
      " 0.90988155 0.85617407 0.8328563  0.89479257 0.79315459 0.97792792\n",
      " 0.89086198 0.8636435  0.83225637 0.67697578 0.98046811 0.89899261\n",
      " 0.91085985 0.92409776 0.91016771 0.89398111 0.68159345 0.9023914\n",
      " 0.82392662 0.83988551 0.87489959 0.88727751 0.86616855 0.98087853\n",
      " 0.81277186 0.86322251 0.93835189 0.84583739 0.88856963 0.90147232\n",
      " 0.91658417 0.93823052 0.68061735 0.73931143 0.90545047 0.87823404\n",
      " 0.97863298 0.9826359 ]\n",
      "Epoch 7/50\n",
      "15244/15244 [==============================] - 313s 21ms/step - loss: 0.1468 - val_loss: 0.1550\n",
      "Average AUC: 0.8832732129036447\n",
      "Recalls: 0.26456221653590073 0.5080705991197682 0.6399217593989063 0.8136002956466946\n",
      "NDCG: 0.7622857044600063\n",
      "AUCs: [0.88496252 0.89547137 0.83403121 0.95290183 0.87174298 0.85653328\n",
      " 0.86520685 0.98161402 0.86277    0.93927106 0.95014187 0.93073698\n",
      " 0.89208207 0.87270904 0.83343707 0.9121562  0.76328004 0.97226125\n",
      " 0.91044758 0.86912752 0.84924175 0.67785163 0.97916292 0.90622927\n",
      " 0.9149622  0.91401841 0.90687385 0.90868563 0.68127768 0.91162836\n",
      " 0.83920694 0.8663306  0.88086184 0.910241   0.85082038 0.98375503\n",
      " 0.83240949 0.87433143 0.94935149 0.8679296  0.90384558 0.91381223\n",
      " 0.91588696 0.91756725 0.65087434 0.74011459 0.90291333 0.89598222\n",
      " 0.98392856 0.98268133]\n",
      "Epoch 8/50\n",
      "15244/15244 [==============================] - 316s 21ms/step - loss: 0.1447 - val_loss: 0.1543\n",
      "Average AUC: 0.8863326986861482\n",
      "Recalls: 0.24534667202603494 0.5050067551971983 0.6451140022642793 0.8216011641738787\n",
      "NDCG: 0.7515835845342448\n",
      "AUCs: [0.8901905  0.9133771  0.8338324  0.9576409  0.86256584 0.86885086\n",
      " 0.87489699 0.98197964 0.87494755 0.93790261 0.94479438 0.9280064\n",
      " 0.87295043 0.87773029 0.84829858 0.91343831 0.76431944 0.97730829\n",
      " 0.90175539 0.8815499  0.85015936 0.68679287 0.98457908 0.91044186\n",
      " 0.91418814 0.92473281 0.91694579 0.90657445 0.69603588 0.92580083\n",
      " 0.83116497 0.89429379 0.86077163 0.90262004 0.86236596 0.98264474\n",
      " 0.81509126 0.86766834 0.94956106 0.86378451 0.90938099 0.91236848\n",
      " 0.91955068 0.94357607 0.6554321  0.75446958 0.91280992 0.89445434\n",
      " 0.9805921  0.98144753]\n",
      "Epoch 9/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.1434 - val_loss: 0.1388\n",
      "Average AUC: 0.8917947129560847\n",
      "Recalls: 0.2906605231743736 0.5485732014471627 0.6851614919655086 0.8439669678069956\n",
      "NDCG: 0.7931034949060062\n",
      "AUCs: [0.8821624  0.90724943 0.83857843 0.9537487  0.87968525 0.86756141\n",
      " 0.87343272 0.9839922  0.87126359 0.9473998  0.9529577  0.9295306\n",
      " 0.91844878 0.87575058 0.84734602 0.91295669 0.83790422 0.9773022\n",
      " 0.90958069 0.87964464 0.85342177 0.69556933 0.98166858 0.9055362\n",
      " 0.91417432 0.93907541 0.91816317 0.9077703  0.70498188 0.92591926\n",
      " 0.84313005 0.89998378 0.88149937 0.89655574 0.8591189  0.98414909\n",
      " 0.83266496 0.89174171 0.95186327 0.85784627 0.9090604  0.91033984\n",
      " 0.93238297 0.93798701 0.66569882 0.75706075 0.91869609 0.8967701\n",
      " 0.98418745 0.98622284]\n",
      "Epoch 10/50\n",
      "15244/15244 [==============================] - 316s 21ms/step - loss: 0.1417 - val_loss: 0.1420\n",
      "Average AUC: 0.8949369327873359\n",
      "Recalls: 0.2837407033563543 0.5425259669026982 0.6824435868584069 0.8486614493539701\n",
      "NDCG: 0.7869528635017196\n",
      "AUCs: [0.89703475 0.9112042  0.83361741 0.94884976 0.88341115 0.86320095\n",
      " 0.87360721 0.98365858 0.87489753 0.95023754 0.95133821 0.92822946\n",
      " 0.91265883 0.88567038 0.84543789 0.92420272 0.86697572 0.98000754\n",
      " 0.92195834 0.89356251 0.86263199 0.67770082 0.98441688 0.90545498\n",
      " 0.91283155 0.93117802 0.92505645 0.91932251 0.6950156  0.93507974\n",
      " 0.83335546 0.938773   0.86916189 0.91218242 0.85804444 0.98658661\n",
      " 0.82618239 0.88395626 0.95384642 0.87681749 0.9198436  0.91311641\n",
      " 0.91519822 0.95474258 0.67305176 0.76098566 0.92359889 0.89939902\n",
      " 0.98366822 0.98588668]\n",
      "Epoch 11/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.1403 - val_loss: 0.1465\n",
      "Average AUC: 0.8898612380612285\n",
      "Recalls: 0.2597226988154966 0.49963443950632325 0.6403637836463322 0.823551003987292\n",
      "NDCG: 0.7575810166585465\n",
      "AUCs: [0.88677995 0.90336712 0.83845316 0.95140246 0.86391801 0.87881503\n",
      " 0.86508807 0.98469568 0.87893688 0.94624963 0.93684932 0.93131502\n",
      " 0.9156715  0.87507868 0.83621636 0.92487234 0.8469216  0.97468015\n",
      " 0.91087218 0.88502958 0.85041415 0.67917289 0.98154725 0.90480071\n",
      " 0.90714847 0.93056518 0.9283464  0.9142658  0.69841737 0.92324241\n",
      " 0.82425268 0.91007973 0.87765917 0.8960245  0.86826149 0.98827708\n",
      " 0.81688292 0.85667892 0.94766081 0.85948366 0.92373412 0.90510437\n",
      " 0.93451266 0.94298469 0.67498814 0.74511703 0.90349075 0.89379412\n",
      " 0.98439543 0.98654628]\n",
      "Epoch 12/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1388 - val_loss: 0.1431\n",
      "Average AUC: 0.8963664567841697\n",
      "Recalls: 0.28095147516892666 0.5224977290074243 0.6731043297525291 0.8461943623474094\n",
      "NDCG: 0.7782542029249421\n",
      "AUCs: [0.8969045  0.91901096 0.83686447 0.95270613 0.88072419 0.870379\n",
      " 0.8789818  0.98232409 0.87413252 0.9548925  0.95265347 0.92670599\n",
      " 0.91370598 0.8860314  0.84351385 0.92648394 0.86003577 0.98366433\n",
      " 0.92055511 0.89028436 0.85795202 0.69322341 0.98423426 0.90512739\n",
      " 0.91823323 0.94197235 0.92631386 0.92211043 0.7079446  0.92741557\n",
      " 0.84220202 0.91608724 0.88044889 0.90561159 0.87121786 0.98214799\n",
      " 0.82840768 0.8767554  0.95087169 0.87791753 0.91875449 0.91261555\n",
      " 0.92529923 0.95785019 0.65980379 0.77711777 0.9319382  0.90224336\n",
      " 0.98230832 0.98364257]\n",
      "Epoch 13/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1376 - val_loss: 0.1356\n",
      "Average AUC: 0.9000016235465662\n",
      "Recalls: 0.3052401091009124 0.5590760642353441 0.6988035016947759 0.860165808209437\n",
      "NDCG: 0.8063226552166269\n",
      "AUCs: [0.90635712 0.91029732 0.83906859 0.95684687 0.89178459 0.88320672\n",
      " 0.87530379 0.98347695 0.8851328  0.95426811 0.95169495 0.93087402\n",
      " 0.90976227 0.88881633 0.83822937 0.93244941 0.88096482 0.98101655\n",
      " 0.92822305 0.8960522  0.86634358 0.70350589 0.98522145 0.90932464\n",
      " 0.91344863 0.9491059  0.93173984 0.9262012  0.70337032 0.93400407\n",
      " 0.84383874 0.94256246 0.87860264 0.93175372 0.86473451 0.98847347\n",
      " 0.82766816 0.87237255 0.95770167 0.89220046 0.92558275 0.91484083\n",
      " 0.94122495 0.96192022 0.67118285 0.75664282 0.90142605 0.91086812\n",
      " 0.98355041 0.98684246]\n",
      "Epoch 14/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1366 - val_loss: 0.1449\n",
      "Average AUC: 0.8951414557477813\n",
      "Recalls: 0.2859732084628206 0.5344460774169915 0.6732766720301346 0.8403703400067666\n",
      "NDCG: 0.7868481620792739\n",
      "AUCs: [0.89109104 0.91299158 0.83449357 0.95973187 0.87697832 0.87357901\n",
      " 0.88541728 0.98389527 0.87617536 0.93824721 0.95206508 0.93042645\n",
      " 0.89698849 0.87150977 0.8563809  0.92645405 0.85900466 0.98045313\n",
      " 0.93071385 0.88039365 0.8508283  0.69245742 0.98190228 0.91395687\n",
      " 0.91774253 0.91401841 0.92100893 0.9283977  0.69275111 0.92985311\n",
      " 0.84556989 0.86872943 0.88782334 0.93161959 0.87312777 0.98590503\n",
      " 0.83407678 0.87271007 0.95501003 0.89155212 0.9216428  0.91507614\n",
      " 0.93540363 0.92757421 0.66214503 0.78175498 0.92892513 0.91170786\n",
      " 0.98363622 0.98317558]\n",
      "Epoch 15/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1352 - val_loss: 0.1474\n",
      "Average AUC: 0.8956035296889178\n",
      "Recalls: 0.2820402051011469 0.535229327074895 0.6701186874836459 0.837822930378332\n",
      "NDCG: 0.7825536328634265\n",
      "AUCs: [0.89478706 0.91440094 0.83104876 0.96061277 0.88266739 0.87137136\n",
      " 0.87838737 0.98328543 0.87801444 0.9483145  0.95433678 0.93001789\n",
      " 0.90073902 0.86910326 0.83935154 0.92281432 0.8539818  0.98023034\n",
      " 0.93294766 0.88232661 0.84927765 0.6837229  0.98129694 0.90086336\n",
      " 0.91306653 0.92607988 0.92361551 0.9277817  0.69116093 0.92018439\n",
      " 0.83595809 0.91022575 0.88643526 0.93976297 0.87589682 0.98497315\n",
      " 0.84263673 0.87598832 0.95688839 0.88300495 0.91722495 0.91999059\n",
      " 0.93267234 0.94648655 0.66359681 0.77927829 0.92433728 0.9126194\n",
      " 0.98203053 0.98438031]\n",
      "Epoch 16/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1342 - val_loss: 0.1408\n",
      "Average AUC: 0.8983091463916506\n",
      "Recalls: 0.29434883752750785 0.5452517249089271 0.6751245042276899 0.8385377997912624\n",
      "NDCG: 0.7891275548101991\n",
      "AUCs: [0.90629332 0.91787607 0.83882298 0.95707885 0.88505496 0.87582425\n",
      " 0.88520258 0.9842703  0.87538823 0.9594001  0.94690599 0.92902982\n",
      " 0.89285793 0.87614168 0.86088547 0.92324612 0.90001686 0.98203909\n",
      " 0.91649161 0.8780677  0.85055337 0.706464   0.9842598  0.9095692\n",
      " 0.91698623 0.93726352 0.93214693 0.9140677  0.70434783 0.93129762\n",
      " 0.83287153 0.95331201 0.88057699 0.91110935 0.87309978 0.98226608\n",
      " 0.82043262 0.88238738 0.95421083 0.86913866 0.93079009 0.90935662\n",
      " 0.939883   0.93218924 0.67181672 0.7913165  0.926325   0.90933026\n",
      " 0.98373366 0.98346086]\n",
      "Epoch 17/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1331 - val_loss: 0.1395\n",
      "Average AUC: 0.9040066621693414\n",
      "Recalls: 0.28957494939143136 0.5522038057356617 0.6885315765336542 0.8601467047623558\n",
      "NDCG: 0.7965834643863802\n",
      "AUCs: [0.9012584  0.90892616 0.83941025 0.96558538 0.89372262 0.88105417\n",
      " 0.9002815  0.98404632 0.88225755 0.95695017 0.95385856 0.92788248\n",
      " 0.92450157 0.88997785 0.86231127 0.93675145 0.89281982 0.98312258\n",
      " 0.93803913 0.89751829 0.86428246 0.69974783 0.9852802  0.91102935\n",
      " 0.91273972 0.93278414 0.93469689 0.93240171 0.71442608 0.94125745\n",
      " 0.83612432 0.92962268 0.89178863 0.93706969 0.87072693 0.98754544\n",
      " 0.84838902 0.875759   0.95611422 0.8998384  0.9342207  0.91333826\n",
      " 0.94644552 0.9296962  0.67689999 0.79217235 0.93569316 0.91943504\n",
      " 0.98445652 0.98607565]\n",
      "Epoch 18/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1320 - val_loss: 0.1574\n",
      "Average AUC: 0.8925745977815518\n",
      "Recalls: 0.25794286379466436 0.4931747154046323 0.629403832035411 0.8010590280500253\n",
      "NDCG: 0.7508609820148212\n",
      "AUCs: [0.88754411 0.90459376 0.8266919  0.96069428 0.88563019 0.87603705\n",
      " 0.88093276 0.98410561 0.85338082 0.94899984 0.95115753 0.92579264\n",
      " 0.90036112 0.86982913 0.84855148 0.92036635 0.86191416 0.97224636\n",
      " 0.91633053 0.87591726 0.85032221 0.68834682 0.98166858 0.90083629\n",
      " 0.91430267 0.92787992 0.92628164 0.91490639 0.69579937 0.92614623\n",
      " 0.82787383 0.9024336  0.88508335 0.91560992 0.86335214 0.98475751\n",
      " 0.81795691 0.88891562 0.95290802 0.87083836 0.9220308  0.91540808\n",
      " 0.93526486 0.94705473 0.66843163 0.77147208 0.91811517 0.89458798\n",
      " 0.98307626 0.98599207]\n",
      "Epoch 19/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1308 - val_loss: 0.1489\n",
      "Average AUC: 0.900349513704163\n",
      "Recalls: 0.2769923315629687 0.5362658931045357 0.6786452620940155 0.8477743933249474\n",
      "NDCG: 0.7833316473506841\n",
      "AUCs: [0.88496153 0.90495604 0.83945177 0.96265583 0.88768939 0.88081065\n",
      " 0.89599066 0.98431077 0.88671863 0.94955387 0.95395019 0.93027046\n",
      " 0.91838967 0.88895909 0.86012524 0.93918813 0.85237155 0.97902157\n",
      " 0.93201651 0.89105772 0.86875755 0.68642535 0.98075034 0.91154555\n",
      " 0.92098492 0.94324392 0.9382641  0.92718739 0.69212586 0.93428902\n",
      " 0.84986234 0.89942289 0.884375   0.93063299 0.86855433 0.98733622\n",
      " 0.82122929 0.88984904 0.95424524 0.88760562 0.93630004 0.91841743\n",
      " 0.93459981 0.96012291 0.67974629 0.80382533 0.89461602 0.919078\n",
      " 0.98511101 0.98652266]\n",
      "Epoch 20/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1295 - val_loss: 0.1385\n",
      "Average AUC: 0.9049754820669976\n",
      "Recalls: 0.3032669911651906 0.5592856467683338 0.6978421445180448 0.8612316808819579\n",
      "NDCG: 0.8054605600885609\n",
      "AUCs: [0.91460738 0.91407291 0.8409708  0.96238981 0.89230567 0.89397661\n",
      " 0.88888795 0.98517    0.88940223 0.95410689 0.95249749 0.93289389\n",
      " 0.92057792 0.89108864 0.86101192 0.93834047 0.87434968 0.9844011\n",
      " 0.93361156 0.89063283 0.86740916 0.70469932 0.98328666 0.90456066\n",
      " 0.91629708 0.94632442 0.93641313 0.92984516 0.71962623 0.93784848\n",
      " 0.84978366 0.91558198 0.89088435 0.9351265  0.87288876 0.98537491\n",
      " 0.83241117 0.88431315 0.9577267  0.89119193 0.93694271 0.91725436\n",
      " 0.935627   0.95538033 0.68817477 0.80804643 0.93765988 0.92080535\n",
      " 0.98496993 0.98702417]\n",
      "Epoch 21/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1284 - val_loss: 0.1618\n",
      "Average AUC: 0.8895102184299634\n",
      "Recalls: 0.27394724709475404 0.5179712613230618 0.6541145123728226 0.8194662581954825\n",
      "NDCG: 0.7714316918100563\n",
      "AUCs: [0.88730311 0.90550497 0.8298904  0.95933239 0.88548195 0.85572173\n",
      " 0.88138213 0.98081267 0.86152297 0.94395539 0.94314709 0.92618408\n",
      " 0.89375097 0.87815207 0.83443278 0.92296179 0.81922675 0.98040099\n",
      " 0.93184612 0.87679893 0.84309693 0.66354344 0.9788794  0.90604517\n",
      " 0.91164724 0.91924979 0.91974274 0.92593514 0.67156426 0.9172707\n",
      " 0.84133054 0.87765494 0.89465371 0.93063476 0.87150424 0.9867278\n",
      " 0.82993882 0.84754987 0.95443292 0.8889685  0.91165808 0.91357525\n",
      " 0.94018253 0.89581401 0.66659033 0.78352664 0.91103218 0.90988278\n",
      " 0.98173528 0.98333367]\n",
      "Epoch 22/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1272 - val_loss: 0.1388\n",
      "Average AUC: 0.9055242285240006\n",
      "Recalls: 0.29233685481954175 0.5544231282977821 0.6978178613220165 0.8571484231629661\n",
      "NDCG: 0.7981930809478898\n",
      "AUCs: [0.91623555 0.90980981 0.83759847 0.96373378 0.89197859 0.88333394\n",
      " 0.89125885 0.98424866 0.88541974 0.95329967 0.95347917 0.93055985\n",
      " 0.91542133 0.8879182  0.86592083 0.93987302 0.88404295 0.98040708\n",
      " 0.93653068 0.89187977 0.86638998 0.69207692 0.98284989 0.91012511\n",
      " 0.92480787 0.94468425 0.94017364 0.93264175 0.70887304 0.93356862\n",
      " 0.85008366 0.94723265 0.89444723 0.93505414 0.87659662 0.98870708\n",
      " 0.83326835 0.88911587 0.95544795 0.89270862 0.93901456 0.91412148\n",
      " 0.94084081 0.9611897  0.69556656 0.79709302 0.93529772 0.92006534\n",
      " 0.98452924 0.98668983]\n",
      "Epoch 23/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1260 - val_loss: 0.1538\n",
      "Average AUC: 0.894852234313938\n",
      "Recalls: 0.26747373509838884 0.5165666249980654 0.6549530987377248 0.8267048125773887\n",
      "NDCG: 0.770086404669617\n",
      "AUCs: [0.87206413 0.86642236 0.84302079 0.96361152 0.87836465 0.8769974\n",
      " 0.89097451 0.97977368 0.87544141 0.94981149 0.93976604 0.92708795\n",
      " 0.905846   0.88742033 0.85545561 0.93585198 0.82921442 0.97480543\n",
      " 0.93840786 0.89167237 0.86888889 0.69449224 0.9774465  0.91073335\n",
      " 0.91990676 0.94425349 0.94016387 0.93442903 0.70366974 0.91326901\n",
      " 0.84934202 0.85843299 0.89035685 0.93750386 0.85102924 0.98879436\n",
      " 0.82643954 0.85854575 0.95567317 0.89606129 0.93986397 0.9073868\n",
      " 0.93229836 0.93094852 0.65778561 0.775675   0.91095869 0.91695373\n",
      " 0.98247122 0.98682793]\n",
      "Epoch 24/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1248 - val_loss: 0.1408\n",
      "Average AUC: 0.9026919342921232\n",
      "Recalls: 0.3035402270859335 0.5610691542478246 0.6870720807355157 0.8486260264307356\n",
      "NDCG: 0.8035576632731546\n",
      "AUCs: [0.91245523 0.91680538 0.84069915 0.95636007 0.90216245 0.89485469\n",
      " 0.87880468 0.9830191  0.87838668 0.95898291 0.95176445 0.9311255\n",
      " 0.93003185 0.88685019 0.84822134 0.92759466 0.90185102 0.98279415\n",
      " 0.93598131 0.89266992 0.85811137 0.68939994 0.9848396  0.91403357\n",
      " 0.9191475  0.92980875 0.93347463 0.93381158 0.69639883 0.9341854\n",
      " 0.84348464 0.94581189 0.89166806 0.93753739 0.88326945 0.98849657\n",
      " 0.81629298 0.87292646 0.95261868 0.89482691 0.93014292 0.9079717\n",
      " 0.95289805 0.95349026 0.67064303 0.77823528 0.92156568 0.91977812\n",
      " 0.98365803 0.98465469]\n",
      "Epoch 25/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.1232 - val_loss: 0.1411\n",
      "Average AUC: 0.9051208389881009\n",
      "Recalls: 0.306071142359231 0.5574734008425144 0.6936682578476207 0.8541766296440811\n",
      "NDCG: 0.8050995184519836\n",
      "AUCs: [0.90959792 0.91620446 0.81450029 0.96106061 0.89507738 0.89373842\n",
      " 0.89243037 0.98452299 0.86744063 0.95736293 0.94852496 0.93177716\n",
      " 0.93052481 0.89271323 0.86250133 0.93559556 0.90895131 0.98418779\n",
      " 0.93532672 0.89478048 0.86837142 0.70998437 0.98497114 0.90859096\n",
      " 0.91734957 0.94006721 0.93436594 0.93028909 0.70108821 0.93811555\n",
      " 0.83482891 0.94254856 0.8898625  0.94258862 0.88095474 0.98615019\n",
      " 0.84387374 0.87458981 0.95408102 0.88901328 0.92891749 0.91876702\n",
      " 0.9471935  0.96948052 0.66586649 0.80349281 0.94085493 0.92176277\n",
      " 0.98503392 0.98616832]\n",
      "Epoch 26/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1221 - val_loss: 0.1426\n",
      "Average AUC: 0.9031391091514134\n",
      "Recalls: 0.30312874516475624 0.5547094135217404 0.6890413180233126 0.8424756574860454\n",
      "NDCG: 0.8009752029624962\n",
      "AUCs: [0.91655159 0.91081711 0.84144441 0.96235891 0.88679288 0.88719468\n",
      " 0.8903065  0.98450087 0.8869066  0.95625487 0.95107619 0.93003939\n",
      " 0.911409   0.88813204 0.85020747 0.92873328 0.89202921 0.98005698\n",
      " 0.93024362 0.88857643 0.86769285 0.69056341 0.98298398 0.90585115\n",
      " 0.92039154 0.95202653 0.93731909 0.92949378 0.70165874 0.93669695\n",
      " 0.84995972 0.93284661 0.89468385 0.93640431 0.87042332 0.98602953\n",
      " 0.83625332 0.88517712 0.95761878 0.88652895 0.93224473 0.91887458\n",
      " 0.92258318 0.96089981 0.65471643 0.80732323 0.9389547  0.91655081\n",
      " 0.98285955 0.98771285]\n",
      "Epoch 27/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1206 - val_loss: 0.1395\n",
      "Average AUC: 0.90603593216629\n",
      "Recalls: 0.3059331794961989 0.56941065692797 0.7029925720888325 0.8640881599676613\n",
      "NDCG: 0.810309727521802\n",
      "AUCs: [0.90292194 0.90991141 0.8415352  0.96266837 0.88800391 0.90194692\n",
      " 0.89485698 0.98359741 0.87870574 0.95693355 0.9505923  0.9302916\n",
      " 0.93381405 0.88800698 0.87124847 0.93877161 0.90876471 0.98321807\n",
      " 0.94513628 0.89290923 0.86579984 0.68337237 0.98345779 0.91322408\n",
      " 0.91311047 0.92923143 0.93572097 0.93993834 0.69864005 0.93943794\n",
      " 0.84006858 0.92447736 0.89162435 0.94710684 0.87721459 0.98885212\n",
      " 0.83770043 0.8821621  0.95424837 0.90222343 0.94081226 0.91847625\n",
      " 0.95138519 0.95827922 0.67878116 0.81692654 0.93271859 0.92272019\n",
      " 0.98336133 0.98688971]\n",
      "Epoch 28/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1197 - val_loss: 0.1341\n",
      "Average AUC: 0.9072147631708561\n",
      "Recalls: 0.316609716332708 0.5798440703392227 0.7141116110472066 0.8706276122307978\n",
      "NDCG: 0.8198468606035872\n",
      "AUCs: [0.91679094 0.91291047 0.8416858  0.95924641 0.89288992 0.89524625\n",
      " 0.88973782 0.98377763 0.89057213 0.96199573 0.95493186 0.93484305\n",
      " 0.92101071 0.89165258 0.85764315 0.94015934 0.91050765 0.98173097\n",
      " 0.93836596 0.89614624 0.86979862 0.66630281 0.98367234 0.90645037\n",
      " 0.92094543 0.95301537 0.94283391 0.93112199 0.69793051 0.93904566\n",
      " 0.83967513 0.95117508 0.90033263 0.93720912 0.87848069 0.98739526\n",
      " 0.82598575 0.89223587 0.95690873 0.88715393 0.9431238  0.91694679\n",
      " 0.95889029 0.96783395 0.68877388 0.80406519 0.94518731 0.92432986\n",
      " 0.98493648 0.98713683]\n",
      "Epoch 29/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1183 - val_loss: 0.1386\n",
      "Average AUC: 0.9072304519050483\n",
      "Recalls: 0.3109243672609323 0.5740848723708835 0.7061487271321066 0.8686034719102586\n",
      "NDCG: 0.8138471498277622\n",
      "AUCs: [0.9177523  0.90726243 0.83919807 0.95958856 0.89960698 0.90081897\n",
      " 0.886444   0.98371552 0.8856214  0.9589192  0.95168826 0.93395521\n",
      " 0.93234044 0.89032294 0.86090288 0.94080505 0.91403222 0.98302236\n",
      " 0.93862389 0.89062444 0.86476841 0.68753789 0.98325473 0.91226118\n",
      " 0.91521496 0.9504204  0.94151988 0.9333503  0.69865388 0.93492554\n",
      " 0.84515087 0.94783989 0.8982377  0.93927232 0.87751389 0.9873452\n",
      " 0.83457763 0.88130216 0.95591715 0.89838402 0.94024748 0.9107012\n",
      " 0.95974657 0.96748609 0.68337573 0.79784711 0.93995556 0.92811965\n",
      " 0.98420781 0.98714228]\n",
      "Epoch 30/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.1163 - val_loss: 0.1355\n",
      "Average AUC: 0.9068497781934289\n",
      "Recalls: 0.31163722396409377 0.5828627564084629 0.7139771374362787 0.8726047190728632\n",
      "NDCG: 0.8185967677531074\n",
      "AUCs: [0.91934939 0.9074987  0.83922376 0.96323175 0.89410288 0.89960824\n",
      " 0.89492636 0.98473615 0.88502434 0.95961949 0.95149625 0.93386847\n",
      " 0.926788   0.88845708 0.86661366 0.93833051 0.90520835 0.98295261\n",
      " 0.93654931 0.88902818 0.85827248 0.68398706 0.98259575 0.91118908\n",
      " 0.91814141 0.93517778 0.94156479 0.93544847 0.70066803 0.94333231\n",
      " 0.85779021 0.95569925 0.90134091 0.94430413 0.87572025 0.98863135\n",
      " 0.82225789 0.88184235 0.95572322 0.89407539 0.94286463 0.92158896\n",
      " 0.95341757 0.95916048 0.67597576 0.80321843 0.93273609 0.9273956\n",
      " 0.98451178 0.98724404]\n",
      "Epoch 31/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1148 - val_loss: 0.1578\n",
      "Average AUC: 0.8937791953419096\n",
      "Recalls: 0.2733484364717052 0.5077337988522199 0.6496868602824282 0.8261577033564568\n",
      "NDCG: 0.7686546796751001\n",
      "AUCs: [0.89590016 0.90487728 0.82047752 0.95893784 0.86398536 0.88594128\n",
      " 0.87174245 0.98265112 0.84448762 0.94747847 0.94699556 0.932185\n",
      " 0.898669   0.88460384 0.84946769 0.93972887 0.83619169 0.98074567\n",
      " 0.93334339 0.88287073 0.85372297 0.68207907 0.98078483 0.89383877\n",
      " 0.90678316 0.9309012  0.94215054 0.92863051 0.6685311  0.93309616\n",
      " 0.83132678 0.87047467 0.89449697 0.92715255 0.87444124 0.98778033\n",
      " 0.82215537 0.86622461 0.95768134 0.88449437 0.9400003  0.91152308\n",
      " 0.93533763 0.94750696 0.66819342 0.78126255 0.92024287 0.91787724\n",
      " 0.98220797 0.98678068]\n",
      "Epoch 32/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.1131 - val_loss: 0.1356\n",
      "Average AUC: 0.905597213999892\n",
      "Recalls: 0.3162563192168455 0.5807776992680039 0.7139750305609031 0.8683997346912858\n",
      "NDCG: 0.8200741789385657\n",
      "AUCs: [0.91167238 0.91074072 0.84115307 0.9618674  0.89117166 0.89781449\n",
      " 0.89274887 0.98432583 0.88704296 0.95660778 0.95090117 0.9325214\n",
      " 0.92308602 0.88670153 0.86696122 0.93837435 0.91093613 0.97762725\n",
      " 0.93784266 0.88978139 0.86407145 0.6854716  0.98180523 0.90871279\n",
      " 0.91583303 0.94614827 0.93903728 0.93111765 0.70304323 0.94061846\n",
      " 0.84513317 0.94589765 0.89955042 0.93610957 0.86791697 0.98326663\n",
      " 0.82487983 0.88837302 0.95485051 0.89571278 0.94092761 0.91646442\n",
      " 0.94721211 0.95977505 0.67629883 0.80975086 0.92819723 0.92335049\n",
      " 0.98533645 0.98511986]\n",
      "Epoch 33/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.1117 - val_loss: 0.1401\n",
      "Average AUC: 0.9031077871028867\n",
      "Recalls: 0.29950636018849314 0.5607792881684849 0.6973858436116054 0.8565616349896129\n",
      "NDCG: 0.8030542590012313\n",
      "AUCs: [0.91370123 0.90970664 0.83728495 0.95434792 0.88891331 0.89612129\n",
      " 0.87901386 0.9835353  0.88422984 0.96106773 0.94352237 0.93280787\n",
      " 0.91975666 0.88669327 0.84996365 0.93581146 0.91273988 0.981668\n",
      " 0.93072595 0.88569377 0.86719727 0.6797721  0.9826596  0.90610293\n",
      " 0.91533542 0.94077479 0.94169756 0.92366634 0.70011071 0.92600437\n",
      " 0.84442103 0.96043666 0.90436122 0.92572119 0.86751217 0.98645183\n",
      " 0.83111029 0.88287911 0.95383703 0.88031813 0.94098304 0.91749471\n",
      " 0.94885867 0.93737245 0.6720028  0.80465574 0.93856975 0.91556547\n",
      " 0.98542226 0.98678977]\n",
      "Epoch 34/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.1105 - val_loss: 0.1541\n",
      "Average AUC: 0.8980794187489894\n",
      "Recalls: 0.29880892614618376 0.5534019906942343 0.6845704067656976 0.8453500549414676\n",
      "NDCG: 0.7975555378088618\n",
      "AUCs: [0.91774106 0.90649731 0.84020337 0.95968305 0.8898472  0.89027331\n",
      " 0.88156188 0.98341013 0.88312997 0.95616013 0.94801276 0.93076103\n",
      " 0.89596456 0.87172154 0.85412748 0.91466528 0.90758847 0.97954909\n",
      " 0.91627745 0.87785946 0.84752123 0.66735143 0.98324707 0.90494149\n",
      " 0.91526433 0.93137194 0.92755857 0.91426435 0.67115917 0.93824014\n",
      " 0.84610595 0.953115   0.89271402 0.91164588 0.86986995 0.98765968\n",
      " 0.838845   0.88669675 0.95595    0.87149254 0.91924437 0.91256513\n",
      " 0.95105351 0.94783163 0.64961886 0.79954064 0.9410194  0.89268112\n",
      " 0.98250904 0.98785822]\n",
      "Epoch 35/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.1083 - val_loss: 0.1416\n",
      "Average AUC: 0.90644830060438\n",
      "Recalls: 0.31073712183476726 0.5723578757858536 0.7058937868840917 0.8636782026324963\n",
      "NDCG: 0.8129246689844735\n",
      "AUCs: [0.91348138 0.9059338  0.82941784 0.96298813 0.88624182 0.89101986\n",
      " 0.89020296 0.98444817 0.88600838 0.95845547 0.95322487 0.93400186\n",
      " 0.92681544 0.89055949 0.8599473  0.94023839 0.90989672 0.98318759\n",
      " 0.94175997 0.89289748 0.86919797 0.6855485  0.98178224 0.90129834\n",
      " 0.90859985 0.9472955  0.93762661 0.93510142 0.71285854 0.94483233\n",
      " 0.8375771  0.94468549 0.90057377 0.94353639 0.87273373 0.98793436\n",
      " 0.83013042 0.89031575 0.95517425 0.89455239 0.94725551 0.91573666\n",
      " 0.94904989 0.95978664 0.68600528 0.80644739 0.93536421 0.92733376\n",
      " 0.98523027 0.98812351]\n",
      "Epoch 36/50\n",
      "15244/15244 [==============================] - 315s 21ms/step - loss: 0.1065 - val_loss: 0.1593\n",
      "Average AUC: 0.893424657172045\n",
      "Recalls: 0.30578000216158113 0.5475868955093331 0.6743994008710075 0.832617987967711\n",
      "NDCG: 0.794694092901369\n",
      "AUCs: [0.91190909 0.90109814 0.82815322 0.96058456 0.86960322 0.89277044\n",
      " 0.88485044 0.98338613 0.86329124 0.95534071 0.94982374 0.93413525\n",
      " 0.90130482 0.86602072 0.85056108 0.91450917 0.88398628 0.97951794\n",
      " 0.90993173 0.87369628 0.83393748 0.66142123 0.98043362 0.90426917\n",
      " 0.91820065 0.94397519 0.92009516 0.90484502 0.67841813 0.92517171\n",
      " 0.83392104 0.92026839 0.89089339 0.90127163 0.87021015 0.98687798\n",
      " 0.8198847  0.8852288  0.95370253 0.86823722 0.91997993 0.90733134\n",
      " 0.95084198 0.95362941 0.62830433 0.79343159 0.9347063  0.89725081\n",
      " 0.98102406 0.98899571]\n",
      "Epoch 37/50\n",
      "15244/15244 [==============================] - 315s 21ms/step - loss: 0.1049 - val_loss: 0.1453\n",
      "Average AUC: 0.9032012637869136\n",
      "Recalls: 0.30526593289751186 0.5614311537441731 0.6963500020806115 0.8626202091229792\n",
      "NDCG: 0.8059766234012862\n",
      "AUCs: [0.91263275 0.90577117 0.82896357 0.95946764 0.88561021 0.89083805\n",
      " 0.88197972 0.98570973 0.88057958 0.95711694 0.95357131 0.93189452\n",
      " 0.93028625 0.88915022 0.86073781 0.94308561 0.91882979 0.98302913\n",
      " 0.93274187 0.89062695 0.86050215 0.67362518 0.98012329 0.90233976\n",
      " 0.90475123 0.92402226 0.94338646 0.92700808 0.68665585 0.93875577\n",
      " 0.83636333 0.94042785 0.89478634 0.93420168 0.87157099 0.98750436\n",
      " 0.83838112 0.87978334 0.95324741 0.89097582 0.9479686  0.90780699\n",
      " 0.95117366 0.94841141 0.66971267 0.81602345 0.9333275  0.92344025\n",
      " 0.98403764 0.98712593]\n",
      "Epoch 38/50\n",
      "15244/15244 [==============================] - 316s 21ms/step - loss: 0.1025 - val_loss: 0.1461\n",
      "Average AUC: 0.9024081842852888\n",
      "Recalls: 0.31108448146190526 0.5713507976839002 0.7030414523662447 0.8602996066465596\n",
      "NDCG: 0.8126756031848752\n",
      "AUCs: [0.90352659 0.90062875 0.83501997 0.95672819 0.88416973 0.9011247\n",
      " 0.88026475 0.98195706 0.88612947 0.95790089 0.94539821 0.93027921\n",
      " 0.92717223 0.88971623 0.8487476  0.94180815 0.90605839 0.98167274\n",
      " 0.93341183 0.89072016 0.86514053 0.67751407 0.97961628 0.90766325\n",
      " 0.91302408 0.9435089  0.94296961 0.9269112  0.6860004  0.93941697\n",
      " 0.84153022 0.93856904 0.90143887 0.93453172 0.8706085  0.98863006\n",
      " 0.83194897 0.87159417 0.95549644 0.89234064 0.94464735 0.90934317\n",
      " 0.9478907  0.95041744 0.66580105 0.78799032 0.92725237 0.92249081\n",
      " 0.98493502 0.98875222]\n",
      "Epoch 39/50\n",
      "15244/15244 [==============================] - 316s 21ms/step - loss: 0.1010 - val_loss: 0.1487\n",
      "Average AUC: 0.897921631838459\n",
      "Recalls: 0.29622927792941645 0.5563799658328744 0.6820192689479392 0.8455388236724803\n",
      "NDCG: 0.7970938503014169\n",
      "AUCs: [0.90659945 0.9030269  0.82738508 0.95610122 0.87169851 0.8977058\n",
      " 0.8849461  0.98075102 0.87361917 0.96078683 0.93740322 0.93257024\n",
      " 0.873436   0.88059073 0.84612164 0.93193059 0.91270118 0.97766652\n",
      " 0.9331283  0.88245761 0.85567814 0.66423553 0.98107345 0.90832023\n",
      " 0.90371157 0.94114634 0.93814988 0.92264545 0.68295843 0.93222156\n",
      " 0.83527251 0.95262597 0.8942935  0.93241028 0.875281   0.98492437\n",
      " 0.81883425 0.87211901 0.9528048  0.88381878 0.941407   0.91677199\n",
      " 0.94608508 0.91761364 0.65635019 0.80061817 0.93145877 0.91009221\n",
      " 0.98495684 0.98757657]\n",
      "Epoch 40/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.0996 - val_loss: 0.1563\n",
      "Average AUC: 0.8990522840805362\n",
      "Recalls: 0.2944645407941807 0.5478183321500496 0.6835893632119393 0.8458829310629864\n",
      "NDCG: 0.7952316864496408\n",
      "AUCs: [0.89996281 0.89331068 0.82610322 0.96230248 0.87940295 0.88694633\n",
      " 0.89264481 0.98334896 0.87005789 0.95394677 0.95022012 0.93472715\n",
      " 0.89815914 0.88394197 0.85463405 0.93701917 0.87809402 0.97838027\n",
      " 0.93313575 0.8826457  0.86228089 0.67039243 0.9771451  0.90668591\n",
      " 0.90352102 0.9403603  0.94253615 0.92505451 0.69952571 0.93609867\n",
      " 0.8436253  0.91911417 0.89666123 0.93544595 0.86347057 0.98758138\n",
      " 0.82950687 0.88276284 0.95323959 0.89204276 0.9413291  0.90513463\n",
      " 0.93900303 0.93596939 0.66459465 0.78748426 0.94093542 0.91985391\n",
      " 0.98485939 0.98741485]\n",
      "Epoch 41/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.0972 - val_loss: 0.1472\n",
      "Average AUC: 0.9022643094883273\n",
      "Recalls: 0.30979664764290804 0.5662896166878162 0.704648268013919 0.8649619027735371\n",
      "NDCG: 0.8122338889468034\n",
      "AUCs: [0.91393529 0.9075176  0.82947414 0.95803813 0.88040194 0.89331538\n",
      " 0.89020191 0.98355976 0.87859518 0.95693688 0.95175827 0.93483794\n",
      " 0.90341602 0.88831196 0.86055419 0.93646082 0.88723856 0.97970349\n",
      " 0.93250443 0.88999467 0.86832064 0.67065808 0.98087933 0.89882385\n",
      " 0.91060018 0.9359505  0.94133927 0.92422306 0.70356532 0.94388372\n",
      " 0.83086694 0.93676123 0.89795285 0.93606544 0.87115327 0.98570094\n",
      " 0.84109718 0.88285166 0.95563094 0.88279273 0.94286913 0.91012135\n",
      " 0.94751841 0.94060761 0.66914423 0.81826028 0.93641056 0.91953477\n",
      " 0.98441579 0.98845967]\n",
      "Epoch 42/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.0951 - val_loss: 0.1528\n",
      "Average AUC: 0.8999763902204754\n",
      "Recalls: 0.30562567562221304 0.5641307439610763 0.6988186687632671 0.8627612282044415\n",
      "NDCG: 0.8086343066209145\n",
      "AUCs: [0.90467309 0.90435119 0.82215699 0.96100374 0.88266223 0.89415943\n",
      " 0.88639933 0.98229538 0.87387032 0.9541429  0.943527   0.9355071\n",
      " 0.91500225 0.8863529  0.85644678 0.9365515  0.89044523 0.97994524\n",
      " 0.93151463 0.88687858 0.86243061 0.6667672  0.97716554 0.89930034\n",
      " 0.90134198 0.94266661 0.94003696 0.92856978 0.68194067 0.93747039\n",
      " 0.83215842 0.93310852 0.89451053 0.93719323 0.86702984 0.98426461\n",
      " 0.81943763 0.87493056 0.95484425 0.89192983 0.93997034 0.91565599\n",
      " 0.94087973 0.96000696 0.65841744 0.79612633 0.94622666 0.91670839\n",
      " 0.9826603  0.98718408]\n",
      "Epoch 43/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.0934 - val_loss: 0.1506\n",
      "Average AUC: 0.8966941233269687\n",
      "Recalls: 0.3020743997717682 0.5594558206746573 0.6887980254843136 0.8531354751230098\n",
      "NDCG: 0.8030060080749374\n",
      "AUCs: [0.90705368 0.8959132  0.82382627 0.95425611 0.86223005 0.89237635\n",
      " 0.87561966 0.98197494 0.88151307 0.95672524 0.94529783 0.93351129\n",
      " 0.9029695  0.8865688  0.84084397 0.9375453  0.89393387 0.97764756\n",
      " 0.92711406 0.88495317 0.86177568 0.64405307 0.97926125 0.90027227\n",
      " 0.90449255 0.9440196  0.94046846 0.92289995 0.66976022 0.93552752\n",
      " 0.82656661 0.94447689 0.89408703 0.92555    0.86384953 0.98653911\n",
      " 0.82235873 0.88097353 0.95121577 0.87791363 0.94189687 0.90855827\n",
      " 0.94259736 0.94885204 0.65598214 0.78567081 0.92119123 0.92036653\n",
      " 0.98398092 0.98767469]\n",
      "Epoch 44/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.0918 - val_loss: 0.1535\n",
      "Average AUC: 0.8990592865509677\n",
      "Recalls: 0.3115189724608007 0.5648294104838427 0.6898624305826521 0.8540779069345552\n",
      "NDCG: 0.8093685983535741\n",
      "AUCs: [0.90180817 0.90210269 0.82672427 0.96020121 0.87879196 0.89169937\n",
      " 0.88161917 0.98342566 0.87322377 0.95439166 0.94677935 0.93180413\n",
      " 0.92456596 0.88301051 0.85524586 0.93293502 0.89849784 0.97982335\n",
      " 0.92987955 0.88286821 0.85800018 0.66343558 0.97948219 0.90475739\n",
      " 0.90185934 0.92182106 0.92787488 0.92447611 0.66993508 0.94184093\n",
      " 0.83489973 0.93216057 0.89951877 0.93645196 0.88029801 0.98676502\n",
      " 0.830717   0.87191069 0.95110786 0.88716171 0.93289489 0.9170594\n",
      " 0.94794824 0.92315631 0.66140074 0.81625967 0.9389477  0.92114444\n",
      " 0.98329879 0.98698238]\n",
      "Epoch 45/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.0893 - val_loss: 0.1551\n",
      "Average AUC: 0.8978391542638345\n",
      "Recalls: 0.3059750505214494 0.5629322733027718 0.6917796231161882 0.8546535438502197\n",
      "NDCG: 0.8051437965594128\n",
      "AUCs: [0.9051617  0.90283355 0.82284314 0.95613436 0.8755894  0.88943738\n",
      " 0.8782996  0.98356212 0.8758921  0.95704048 0.94310437 0.93342528\n",
      " 0.91966272 0.88557364 0.84557645 0.93985775 0.89284332 0.98027435\n",
      " 0.92791112 0.88490446 0.85361002 0.66645961 0.97731879 0.89936622\n",
      " 0.89602422 0.93721615 0.93865264 0.92494028 0.67442381 0.93492307\n",
      " 0.83723677 0.94602744 0.88676985 0.92889454 0.87840317 0.9876661\n",
      " 0.82906148 0.87154734 0.95327243 0.89033527 0.94434174 0.90905745\n",
      " 0.94857775 0.93143553 0.63277212 0.7894558  0.9361551  0.91927946\n",
      " 0.98100079 0.98780552]\n",
      "Epoch 46/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.0884 - val_loss: 0.1517\n",
      "Average AUC: 0.8977889915648588\n",
      "Recalls: 0.31021674027214197 0.5667902369252784 0.6987945521186519 0.8599948591984604\n",
      "NDCG: 0.8110424691853184\n",
      "AUCs: [0.90929212 0.89655821 0.8261655  0.95847075 0.88046381 0.88565282\n",
      " 0.88145519 0.98221962 0.87415094 0.94913502 0.9456139  0.93097024\n",
      " 0.91948432 0.88495424 0.84737328 0.93894565 0.88647559 0.98060888\n",
      " 0.93085538 0.88671148 0.86297259 0.66442129 0.97679263 0.89098165\n",
      " 0.90186329 0.93012405 0.93763246 0.92549266 0.68304147 0.93625286\n",
      " 0.83142169 0.92557132 0.89042617 0.93119953 0.87191335 0.98603338\n",
      " 0.83670375 0.87762099 0.94841309 0.88846423 0.93980405 0.90090255\n",
      " 0.94588031 0.92974258 0.64777653 0.80369087 0.93522423 0.92120228\n",
      " 0.98379621 0.98853054]\n",
      "Epoch 47/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.0865 - val_loss: 0.1566\n",
      "Average AUC: 0.8985705575200447\n",
      "Recalls: 0.2998431271457588 0.5618283705368193 0.6986969004628284 0.8577346565919972\n",
      "NDCG: 0.80329515934614\n",
      "AUCs: [0.9092822  0.90204637 0.81346333 0.96139067 0.87817839 0.88606672\n",
      " 0.88663899 0.9821041  0.8733217  0.95402212 0.94680458 0.93274664\n",
      " 0.90705677 0.87997723 0.85568882 0.93901607 0.89544874 0.97806538\n",
      " 0.92277867 0.88596247 0.86140355 0.67562655 0.97649506 0.89798729\n",
      " 0.90504941 0.93373153 0.94004184 0.91944832 0.6886637  0.93679317\n",
      " 0.8278335  0.94154499 0.8905377  0.92215604 0.87457043 0.98583828\n",
      " 0.83913409 0.88485899 0.95243569 0.87678245 0.94034036 0.90959528\n",
      " 0.94596323 0.91990955 0.66710152 0.79360603 0.94305611 0.91800091\n",
      " 0.98231851 0.9876438 ]\n",
      "Epoch 48/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.0846 - val_loss: 0.1628\n",
      "Average AUC: 0.8958044811328445\n",
      "Recalls: 0.29712021973102304 0.5613361778008592 0.6880070670583136 0.8514954632163775\n",
      "NDCG: 0.8013107901351568\n",
      "AUCs: [0.89742287 0.89434673 0.81887721 0.95941345 0.87031475 0.89219403\n",
      " 0.8851269  0.98166625 0.87277361 0.94811283 0.94056549 0.93251338\n",
      " 0.92602269 0.88312436 0.84870444 0.93880349 0.88093718 0.9783112\n",
      " 0.92867838 0.88694491 0.85808073 0.66322686 0.97419501 0.90232802\n",
      " 0.90183367 0.93389585 0.94159896 0.92152624 0.67059745 0.93443088\n",
      " 0.82546104 0.9313007  0.87991988 0.92355033 0.8722471  0.98651729\n",
      " 0.8283623  0.86910076 0.95055264 0.88173163 0.94029542 0.91206763\n",
      " 0.93708572 0.92408395 0.66221864 0.77437215 0.93115431 0.92424808\n",
      " 0.9816611  0.98772557]\n",
      "Epoch 49/50\n",
      "15244/15244 [==============================] - 318s 21ms/step - loss: 0.0827 - val_loss: 0.1590\n",
      "Average AUC: 0.8982242354560203\n",
      "Recalls: 0.3027896464877074 0.5615914594792711 0.6943392018876783 0.8595016613887805\n",
      "NDCG: 0.8043345688132864\n",
      "AUCs: [0.9066011  0.89664032 0.8212277  0.95867541 0.87843039 0.88536994\n",
      " 0.88859468 0.98120511 0.87343753 0.95437449 0.94736517 0.93219265\n",
      " 0.91162118 0.88156584 0.85473854 0.93635553 0.88818812 0.97649771\n",
      " 0.92727515 0.88461225 0.86044129 0.66776489 0.98179884 0.89573029\n",
      " 0.89704907 0.92675045 0.93982512 0.91685995 0.67969882 0.93454807\n",
      " 0.83462923 0.93878227 0.88343454 0.92611124 0.87023599 0.98625031\n",
      " 0.83553565 0.88843923 0.95395121 0.88112028 0.94120925 0.91680056\n",
      " 0.94305934 0.94744898 0.66732031 0.7933371  0.93030043 0.91810662\n",
      " 0.98177455 0.98792908]\n",
      "Epoch 50/50\n",
      "15244/15244 [==============================] - 317s 21ms/step - loss: 0.0816 - val_loss: 0.1655\n",
      "Average AUC: 0.8958661893505648\n",
      "Recalls: 0.3039310149940344 0.5606325896838361 0.6873725644674398 0.8505174758810494\n",
      "NDCG: 0.8028770064871285\n",
      "AUCs: [0.90162436 0.89920129 0.8203804  0.9581371  0.87710786 0.88761924\n",
      " 0.8803604  0.98210057 0.86544939 0.94862974 0.94768124 0.93211903\n",
      " 0.91688333 0.88067037 0.85471204 0.93809933 0.89035262 0.98001567\n",
      " 0.92265017 0.88355004 0.85842133 0.65678633 0.97765211 0.89872278\n",
      " 0.89331103 0.93230453 0.93886546 0.91154151 0.65474914 0.93265207\n",
      " 0.82915055 0.91855328 0.89261756 0.92045994 0.8664657  0.983945\n",
      " 0.83751555 0.88000136 0.95338191 0.88266228 0.93665209 0.91061716\n",
      " 0.94148048 0.92641466 0.65732963 0.80910216 0.93494427 0.92096692\n",
      " 0.98117823 0.98752024]\n"
     ]
    }
   ],
   "source": [
    "# some useful functions for metrics calculation\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x,1)[:,np.newaxis])\n",
    "    return e_x/e_x.sum(1)[:,np.newaxis]\n",
    "\n",
    "def recall(label_true,label_pred,k):\n",
    "    '''the previous two inputs are 2 dimensional array\n",
    "    '''\n",
    "    idx = np.argpartition(label_pred, -k, 1)[:,-k:]\n",
    "    r = label_true[np.repeat(np.arange(label_true.shape[0]),k),idx.flatten()].reshape(-1,k)\n",
    "    recall = (np.sum(r,1)/np.sum(label_true,1)).mean()\n",
    "    return recall\n",
    "\n",
    "def dcg_score(y_true, y_score, k, gains=\"exponential\"):\n",
    "\n",
    "    order = np.argsort(y_score,axis = 1)[:,::-1][:,:k]\n",
    "    \n",
    "    y_t = y_true[np.repeat(np.arange(y_true.shape[0]),k),order.flatten()].reshape(-1,k)\n",
    "\n",
    "    if gains == \"exponential\":\n",
    "        gains = 2 ** y_t - 1\n",
    "    elif gains == \"linear\":\n",
    "        gains = y_t\n",
    "    else:\n",
    "        raise ValueError(\"Invalid gains option.\")\n",
    "    discounts = np.log2(np.arange(len(y_t[0,:])) + 2)[np.newaxis,:]\n",
    "    dcg = np.sum(gains / discounts,1)\n",
    "    return dcg\n",
    "\n",
    "def ndcg_score(y_true, y_score, k, gains=\"exponential\"):\n",
    "   \n",
    "    best = dcg_score(y_true, y_true, k, gains)\n",
    "    actual = dcg_score(y_true, y_score, k, gains)\n",
    "    return (actual / best).mean()\n",
    "\n",
    "\n",
    "\n",
    "#  4 CNNs + GridRNN + output  (MTAT)\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "\n",
    "epochs = 50\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "lam = 0.0000001\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(lam),padding='same')(input_melS)\n",
    "bn1 = BatchNormalization()(conv1)\n",
    "act1 = Activation('elu')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),kernel_regularizer=regularizers.l2(lam),padding='same')(pool1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('elu')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),kernel_regularizer=regularizers.l2(lam),padding='same')(pool2)\n",
    "bn3 = BatchNormalization()(conv3)\n",
    "act3 = Activation('elu')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),kernel_regularizer=regularizers.l2(lam),padding='same')(pool3)\n",
    "bn4 = BatchNormalization()(conv4)\n",
    "act4 = Activation('elu')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same')(act4)\n",
    "\n",
    "gru1_in = Reshape((6, 128*6))(pool4)\n",
    "gru1 = GRU(32,kernel_regularizer=regularizers.l2(lam))(gru1_in)\n",
    "\n",
    "gru2_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(pool4)\n",
    "gru2_in = Reshape((6, 128*6))(gru2_in_perm)\n",
    "gru2 = GRU(32,kernel_regularizer=regularizers.l2(lam))(gru2_in)\n",
    "\n",
    "gru3_in_perm = Lambda(K.reverse,arguments={'axes':2})(pool4)\n",
    "gru3_in = Reshape((6, 128*6))(gru3_in_perm)\n",
    "gru3 = GRU(32,kernel_regularizer=regularizers.l2(lam))(gru3_in)\n",
    "\n",
    "gru4_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(gru3_in_perm)\n",
    "gru4_in = Reshape((6, 128*6))(gru4_in_perm)\n",
    "gru4 = GRU(32,kernel_regularizer=regularizers.l2(lam))(gru4_in)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1})(pool4)\n",
    "gru5_in = Reshape((6, 128*6))(gru5_in_perm)\n",
    "gru5 = GRU(32,kernel_regularizer=regularizers.l2(lam))(gru5_in)\n",
    "\n",
    "gru6_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)})(gru5_in_perm)\n",
    "gru6_in = Reshape((6, 128*6))(gru6_in_perm)\n",
    "gru6 = GRU(32,kernel_regularizer=regularizers.l2(lam))(gru6_in)\n",
    "\n",
    "gru7_in_perm = Lambda(K.reverse,arguments={'axes':2})(gru5_in_perm)\n",
    "gru7_in = Reshape((6, 128*6))(gru7_in_perm)\n",
    "gru7 = GRU(32,kernel_regularizer=regularizers.l2(lam))(gru7_in)\n",
    "\n",
    "gru8_in_perm = Lambda(K.reverse,arguments={'axes':1})(gru6_in_perm)\n",
    "gru8_in = Reshape((6, 128*6))(gru8_in_perm)\n",
    "gru8 = GRU(32,kernel_regularizer=regularizers.l2(lam))(gru8_in)\n",
    "\n",
    "# gru1_in = Reshape((6, 128*6))(pool4)\n",
    "# gru1 = GRU(32)(gru1_in)\n",
    "\n",
    "# gru2_in_perm = K.permute_dimensions(pool4,pattern = (0,2,1,3))\n",
    "# gru2_in = Reshape((6, 128*6))(gru2_in_perm)\n",
    "# gru2 = GRU(32)(gru2_in)\n",
    "\n",
    "# gru3_in_perm = K.reverse(pool4, axes = 2)\n",
    "# gru3_in = Reshape((6, 128*6))(gru3_in_perm)\n",
    "# gru3 = GRU(32)(gru3_in)\n",
    "\n",
    "# gru4_in_perm = K.permute_dimensions(gru3_in_perm,pattern = (0,2,1,3))\n",
    "# gru4_in = Reshape((6, 128*6))(gru4_in_perm)\n",
    "# gru4 = GRU(32)(gru4_in)\n",
    "\n",
    "# gru5_in_perm = K.reverse(pool4, axes = 1)\n",
    "# gru5_in = Reshape((6, 128*6))(gru5_in_perm)\n",
    "# gru5 = GRU(32)(gru5_in)\n",
    "\n",
    "# gru6_in_perm = K.permute_dimensions(gru5_in_perm,pattern = (0,2,1,3))\n",
    "# gru6_in = Reshape((6, 128*6))(gru6_in_perm)\n",
    "# gru6 = GRU(32)(gru6_in)\n",
    "\n",
    "# gru7_in_perm = K.reverse(gru5_in_perm, axes = 2)\n",
    "# gru7_in = Reshape((6, 128*6))(gru7_in_perm)\n",
    "# gru7 = GRU(32)(gru7_in)\n",
    "\n",
    "# gru8_in_perm = K.reverse(gru6_in_perm, axes = 1)\n",
    "# gru8_in = Reshape((6, 128*6))(gru8_in_perm)\n",
    "# gru8 = GRU(32)(gru8_in)\n",
    "\n",
    "gru = Concatenate()([gru1,gru2,gru3,gru4,gru5,gru6,gru7,gru8])\n",
    "gru_dropout = Dropout(0.5)(gru)\n",
    "fc = Dense(64, activation='elu',kernel_regularizer=regularizers.l2(lam))(gru_dropout)\n",
    "pred = Dense(50, activation='sigmoid')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam())\n",
    "\n",
    "filepath='C:/DT/model_save/cGrnn/'+\"{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "\n",
    "path = 'C:/DT'\n",
    "x_train = np.load(path+'\\\\x_train_MelSpec.npy')\n",
    "y_train = np.load(path+'\\\\y_train.npy')\n",
    "x_val = np.load(path+'\\\\x_validation_MelSpec.npy')\n",
    "y_val = np.load(path+'\\\\y_validation.npy')\n",
    "x_test = np.load(path+'\\\\x_test_MelSpec.npy')\n",
    "y_test = np.load(path+'\\\\y_test.npy')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "        self.aucs_all = []\n",
    "        self.recalls_1 = []\n",
    "        self.recalls_3 = []\n",
    "        self.recalls_5 = []\n",
    "        self.recalls_10 = []\n",
    "        self.ndcgs_50 = []\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        \n",
    "        recall_1 = recall(y_test,y_pred,1)\n",
    "        recall_3 = recall(y_test,y_pred,3)\n",
    "        recall_5 = recall(y_test,y_pred,5)\n",
    "        recall_10 = recall(y_test,y_pred,10)\n",
    "        self.recalls_1.append(recall_1)\n",
    "        self.recalls_3.append(recall_3)\n",
    "        self.recalls_5.append(recall_5)\n",
    "        self.recalls_10.append(recall_10)\n",
    "        \n",
    "        ndcg_50 = ndcg_score(y_test,y_pred,k=50,gains=\"exponential\")\n",
    "        self.ndcgs_50.append(ndcg_50)\n",
    "        \n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        self.aucs.append(auc)\n",
    "        auc_all = roc_auc_score(y_test, y_pred,average = None )\n",
    "        self.aucs_all.append(auc_all)\n",
    "        \n",
    "        print(\"Average AUC:\",auc)\n",
    "        print(\"Recalls:\",recall_1,recall_3,recall_5,recall_10)\n",
    "        print(\"NDCG:\",ndcg_50)\n",
    "        print(\"AUCs:\",auc_all)\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, validation_data=(x_val,y_val), callbacks=[histories,checkpoint])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "pickle.dump(histories.aucs,open(os.path.join(path,'project1/cGrnn_aucs.pkl'),'wb'))\n",
    "pickle.dump(histories.aucs_all,open(os.path.join(path,'project1/cGrnn_aucs_all.pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(path,'project1/cGrnn_losses.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_1,open(os.path.join(path,'project1/cGrnn_recalls_1.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_3,open(os.path.join(path,'project1/cGrnn_recalls_3.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_5,open(os.path.join(path,'project1/cGrnn_recalls_5.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls_10,open(os.path.join(path,'project1/cGrnn_recalls_10.pkl'),'wb'))\n",
    "pickle.dump(histories.ndcgs_50,open(os.path.join(path,'project1/cGrnn_ndcgs_10.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19908\n",
      "2503\n",
      "2571\n"
     ]
    }
   ],
   "source": [
    "# Merge into big files  (FMA)\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "x = np.zeros([19909,96,1360,1])\n",
    "file_list = pickle.load(open('C:/DT/fma_medium/train_list.pkl','rb'))\n",
    "for i,file in enumerate(file_list):\n",
    "    x[i] = np.load(os.path.join('C:/DT/fma_medium/train',file))[...,np.newaxis]\n",
    "np.save('C:/DT/fma_medium/x_train.npy',x)\n",
    "print(i)\n",
    "x = np.zeros([2504,96,1360,1])\n",
    "file_list = pickle.load(open('C:/DT/fma_medium/val_list.pkl','rb'))\n",
    "for i,file in enumerate(file_list):\n",
    "    x[i] = np.load(os.path.join('C:/DT/fma_medium/val',file))[...,np.newaxis]\n",
    "np.save('C:/DT/fma_medium/x_val.npy',x)\n",
    "print(i)\n",
    "x = np.zeros([2572,96,1360,1])\n",
    "file_list = pickle.load(open('C:/DT/fma_medium/test_list.pkl','rb'))\n",
    "for i,file in enumerate(file_list):\n",
    "    x[i] = np.load(os.path.join('C:/DT/fma_medium/test',file))[...,np.newaxis]\n",
    "np.save('C:/DT/fma_medium/x_test.npy',x)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 1360, 128)     1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 1360, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 1360, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 340, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 340, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 340, 384)      442752    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 340, 384)      1536      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 340, 384)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 85, 384)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 85, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 85, 768)       2654976   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 85, 768)       3072      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 85, 768)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 22, 768)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 22, 768)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 8, 2048)        14157824  \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 8, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 8, 2048)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                32784     \n",
      "=================================================================\n",
      "Total params: 17,302,928\n",
      "Trainable params: 17,296,272\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "19909/19909 [==============================] - 940s 47ms/step - loss: 2.7233 - categorical_accuracy: 0.4019\n",
      "Weighted AUCs: [0.8451780367037037]\n",
      "weighted average Recalls: 0.5451010886469674\n",
      "unweighted average Recalls (macro): 0.26697681813858626\n",
      "weighted average Precisions: 0.4647377099787376\n",
      "unweighted average Precisions(macro): 0.2564431391222285\n",
      "weighted average F1s: 0.47050039510179115\n",
      "unweighted average F1s(macro): 0.2327264760107801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Categorical Accuracy: 0.5451010886469674\n",
      "Epoch 2/30\n",
      "19909/19909 [==============================] - 930s 47ms/step - loss: 2.0545 - categorical_accuracy: 0.4881\n",
      "Weighted AUCs: [0.8487485560804802]\n",
      "weighted average Recalls: 0.4265163297045101\n",
      "unweighted average Recalls (macro): 0.2026837418116068\n",
      "weighted average Precisions: 0.4652523709554144\n",
      "unweighted average Precisions(macro): 0.24223745810785385\n",
      "weighted average F1s: 0.3352545726171395\n",
      "unweighted average F1s(macro): 0.150444676344648\n",
      "Test Categorical Accuracy: 0.4265163297972078\n",
      "Epoch 3/30\n",
      "19909/19909 [==============================] - 930s 47ms/step - loss: 1.7618 - categorical_accuracy: 0.5334\n",
      "Weighted AUCs: [0.8670945997416363]\n",
      "weighted average Recalls: 0.48833592534992226\n",
      "unweighted average Recalls (macro): 0.24411316931321492\n",
      "weighted average Precisions: 0.5327589232900457\n",
      "unweighted average Precisions(macro): 0.3139589867754276\n",
      "weighted average F1s: 0.45414189731130256\n",
      "unweighted average F1s(macro): 0.2424077975842247\n",
      "Test Categorical Accuracy: 0.48833592534992226\n",
      "Epoch 4/30\n",
      "19909/19909 [==============================] - 931s 47ms/step - loss: 1.5821 - categorical_accuracy: 0.5585\n",
      "Weighted AUCs: [0.8865787375633825]\n",
      "weighted average Recalls: 0.547045101088647\n",
      "unweighted average Recalls (macro): 0.3306877131394844\n",
      "weighted average Precisions: 0.5371346943532364\n",
      "unweighted average Precisions(macro): 0.3118124541451344\n",
      "weighted average F1s: 0.5080198104103721\n",
      "unweighted average F1s(macro): 0.2953433014943475\n",
      "Test Categorical Accuracy: 0.547045101088647\n",
      "Epoch 5/30\n",
      "19909/19909 [==============================] - 930s 47ms/step - loss: 1.4436 - categorical_accuracy: 0.5840\n",
      "Weighted AUCs: [0.8991059547762051]\n",
      "weighted average Recalls: 0.5890357698289269\n",
      "unweighted average Recalls (macro): 0.32182804082961214\n",
      "weighted average Precisions: 0.5517029955257824\n",
      "unweighted average Precisions(macro): 0.43264691794509025\n",
      "weighted average F1s: 0.5116932526631618\n",
      "unweighted average F1s(macro): 0.30438540310558826\n",
      "Test Categorical Accuracy: 0.5890357698289269\n",
      "Epoch 6/30\n",
      "19909/19909 [==============================] - 930s 47ms/step - loss: 1.3301 - categorical_accuracy: 0.6056\n",
      "Weighted AUCs: [0.8902543015713906]\n",
      "weighted average Recalls: 0.4735614307931571\n",
      "unweighted average Recalls (macro): 0.30937151607576585\n",
      "weighted average Precisions: 0.5554731770307316\n",
      "unweighted average Precisions(macro): 0.3028535975314361\n",
      "weighted average F1s: 0.41337381489338004\n",
      "unweighted average F1s(macro): 0.24696272695487795\n",
      "Test Categorical Accuracy: 0.47356143070045936\n",
      "Epoch 7/30\n",
      "19909/19909 [==============================] - 933s 47ms/step - loss: 1.2466 - categorical_accuracy: 0.6183\n",
      "Weighted AUCs: [0.8933499380020692]\n",
      "weighted average Recalls: 0.5466562986003111\n",
      "unweighted average Recalls (macro): 0.2597346574666748\n",
      "weighted average Precisions: 0.5276243422140918\n",
      "unweighted average Precisions(macro): 0.3115422024382942\n",
      "weighted average F1s: 0.48684730872076165\n",
      "unweighted average F1s(macro): 0.25034586276261084\n",
      "Test Categorical Accuracy: 0.5466562986003111\n",
      "Epoch 8/30\n",
      "19909/19909 [==============================] - 932s 47ms/step - loss: 1.1914 - categorical_accuracy: 0.6351\n",
      "Weighted AUCs: [0.8825045477350763]\n",
      "weighted average Recalls: 0.5073872472783826\n",
      "unweighted average Recalls (macro): 0.2933224259185986\n",
      "weighted average Precisions: 0.5896254663859241\n",
      "unweighted average Precisions(macro): 0.40107049872195666\n",
      "weighted average F1s: 0.5033023075431767\n",
      "unweighted average F1s(macro): 0.29175105023019365\n",
      "Test Categorical Accuracy: 0.5073872472783826\n",
      "Epoch 9/30\n",
      "19909/19909 [==============================] - 927s 47ms/step - loss: 1.1561 - categorical_accuracy: 0.6448\n",
      "Weighted AUCs: [0.9037398337303962]\n",
      "weighted average Recalls: 0.6228615863141524\n",
      "unweighted average Recalls (macro): 0.32774626114605854\n",
      "weighted average Precisions: 0.6012277371755518\n",
      "unweighted average Precisions(macro): 0.44688346169158033\n",
      "weighted average F1s: 0.5827217948952065\n",
      "unweighted average F1s(macro): 0.33712440955060397\n",
      "Test Categorical Accuracy: 0.6228615863141524\n",
      "Epoch 10/30\n",
      "19909/19909 [==============================] - 925s 46ms/step - loss: 1.1239 - categorical_accuracy: 0.6541\n",
      "Weighted AUCs: [0.8887275780883882]\n",
      "weighted average Recalls: 0.5279937791601866\n",
      "unweighted average Recalls (macro): 0.28210000488780523\n",
      "weighted average Precisions: 0.5628526270628115\n",
      "unweighted average Precisions(macro): 0.3910443832776398\n",
      "weighted average F1s: 0.49166134493392666\n",
      "unweighted average F1s(macro): 0.29947775434976576\n",
      "Test Categorical Accuracy: 0.5279937791601866\n",
      "Epoch 11/30\n",
      "19909/19909 [==============================] - 926s 46ms/step - loss: 1.0949 - categorical_accuracy: 0.6582\n",
      "Weighted AUCs: [0.9011991978385224]\n",
      "weighted average Recalls: 0.5979782270606532\n",
      "unweighted average Recalls (macro): 0.3856298137252385\n",
      "weighted average Precisions: 0.6160762858444809\n",
      "unweighted average Precisions(macro): 0.4041383570679824\n",
      "weighted average F1s: 0.5763176085227908\n",
      "unweighted average F1s(macro): 0.3579409568155176\n",
      "Test Categorical Accuracy: 0.5979782271533509\n",
      "Epoch 12/30\n",
      "19909/19909 [==============================] - 925s 46ms/step - loss: 1.0795 - categorical_accuracy: 0.6644\n",
      "Weighted AUCs: [0.9021066634917919]\n",
      "weighted average Recalls: 0.619751166407465\n",
      "unweighted average Recalls (macro): 0.43691305577049167\n",
      "weighted average Precisions: 0.6235461460727424\n",
      "unweighted average Precisions(macro): 0.37710726538638006\n",
      "weighted average F1s: 0.607296888145626\n",
      "unweighted average F1s(macro): 0.38625118978767764\n",
      "Test Categorical Accuracy: 0.6197511663611162\n",
      "Epoch 13/30\n",
      "19909/19909 [==============================] - 925s 46ms/step - loss: 1.0578 - categorical_accuracy: 0.6704\n",
      "Weighted AUCs: [0.9055587778726322]\n",
      "weighted average Recalls: 0.6216951788491446\n",
      "unweighted average Recalls (macro): 0.3471638344717903\n",
      "weighted average Precisions: 0.6129626534980007\n",
      "unweighted average Precisions(macro): 0.4382267033509609\n",
      "weighted average F1s: 0.5949989383365232\n",
      "unweighted average F1s(macro): 0.35773430058785655\n",
      "Test Categorical Accuracy: 0.6216951788607319\n",
      "Epoch 14/30\n",
      "19909/19909 [==============================] - 926s 47ms/step - loss: 1.0257 - categorical_accuracy: 0.6812\n",
      "Weighted AUCs: [0.91151015307726]\n",
      "weighted average Recalls: 0.6213063763608087\n",
      "unweighted average Recalls (macro): 0.3458303160238901\n",
      "weighted average Precisions: 0.5846248581225328\n",
      "unweighted average Precisions(macro): 0.35534161448016005\n",
      "weighted average F1s: 0.5812405387906506\n",
      "unweighted average F1s(macro): 0.3294686100853874\n",
      "Test Categorical Accuracy: 0.6213063764071576\n",
      "Epoch 15/30\n",
      "19909/19909 [==============================] - 925s 46ms/step - loss: 1.0190 - categorical_accuracy: 0.6834\n",
      "Weighted AUCs: [0.9033394876321035]\n",
      "weighted average Recalls: 0.5777604976671851\n",
      "unweighted average Recalls (macro): 0.42273552860840496\n",
      "weighted average Precisions: 0.5742507412225423\n",
      "unweighted average Precisions(macro): 0.4139288643788231\n",
      "weighted average F1s: 0.5450357705987262\n",
      "unweighted average F1s(macro): 0.38061023859505544\n",
      "Test Categorical Accuracy: 0.5777604976208363\n",
      "Epoch 16/30\n",
      "19909/19909 [==============================] - 925s 46ms/step - loss: 0.9955 - categorical_accuracy: 0.6881\n",
      "Weighted AUCs: [0.9002316912821782]\n",
      "weighted average Recalls: 0.5816485225505443\n",
      "unweighted average Recalls (macro): 0.33265009627566305\n",
      "weighted average Precisions: 0.5791662085396351\n",
      "unweighted average Precisions(macro): 0.3531524873778988\n",
      "weighted average F1s: 0.5417001225974295\n",
      "unweighted average F1s(macro): 0.30183174554368\n",
      "Test Categorical Accuracy: 0.5816485225505443\n",
      "Epoch 17/30\n",
      "19909/19909 [==============================] - 926s 46ms/step - loss: 0.9761 - categorical_accuracy: 0.6952\n",
      "Weighted AUCs: [0.9009884599077589]\n",
      "weighted average Recalls: 0.6073094867807154\n",
      "unweighted average Recalls (macro): 0.36837651335637833\n",
      "weighted average Precisions: 0.6224994203119641\n",
      "unweighted average Precisions(macro): 0.47609372772859226\n",
      "weighted average F1s: 0.5793740083387148\n",
      "unweighted average F1s(macro): 0.3737031361642188\n",
      "Test Categorical Accuracy: 0.6073094867807154\n",
      "Epoch 18/30\n",
      "19909/19909 [==============================] - 926s 46ms/step - loss: 0.9601 - categorical_accuracy: 0.6958\n",
      "Weighted AUCs: [0.9099447416616997]\n",
      "weighted average Recalls: 0.6349144634525661\n",
      "unweighted average Recalls (macro): 0.4426736686566293\n",
      "weighted average Precisions: 0.652920287901274\n",
      "unweighted average Precisions(macro): 0.49562137124683914\n",
      "weighted average F1s: 0.6145769680657293\n",
      "unweighted average F1s(macro): 0.42403005646488134\n",
      "Test Categorical Accuracy: 0.6349144634757405\n",
      "Epoch 19/30\n",
      "19909/19909 [==============================] - 926s 47ms/step - loss: 0.9512 - categorical_accuracy: 0.6994\n",
      "Weighted AUCs: [0.9098567176750746]\n",
      "weighted average Recalls: 0.6263608087091758\n",
      "unweighted average Recalls (macro): 0.42375119188059696\n",
      "weighted average Precisions: 0.6402719107626424\n",
      "unweighted average Precisions(macro): 0.5109854818272119\n",
      "weighted average F1s: 0.6064782656682087\n",
      "unweighted average F1s(macro): 0.3972777616378801\n",
      "Test Categorical Accuracy: 0.6263608087091758\n",
      "Epoch 20/30\n",
      "19909/19909 [==============================] - 928s 47ms/step - loss: 0.9347 - categorical_accuracy: 0.7065\n",
      "Weighted AUCs: [0.8969790517635947]\n",
      "weighted average Recalls: 0.583203732503888\n",
      "unweighted average Recalls (macro): 0.381036051379555\n",
      "weighted average Precisions: 0.5663992014336539\n",
      "unweighted average Precisions(macro): 0.4175543102027787\n",
      "weighted average F1s: 0.5421782507895025\n",
      "unweighted average F1s(macro): 0.36649104294626367\n",
      "Test Categorical Accuracy: 0.5832037324575392\n",
      "Epoch 21/30\n",
      "19909/19909 [==============================] - 929s 47ms/step - loss: 0.9116 - categorical_accuracy: 0.7061\n",
      "Weighted AUCs: [0.9107901984397087]\n",
      "weighted average Recalls: 0.6368584758942457\n",
      "unweighted average Recalls (macro): 0.3984561030526159\n",
      "weighted average Precisions: 0.6337039795033174\n",
      "unweighted average Precisions(macro): 0.5404540189503257\n",
      "weighted average F1s: 0.6043402522252018\n",
      "unweighted average F1s(macro): 0.40246220442587044\n",
      "Test Categorical Accuracy: 0.6368584759405946\n",
      "Epoch 22/30\n",
      "19909/19909 [==============================] - 926s 47ms/step - loss: 0.9051 - categorical_accuracy: 0.7118\n",
      "Weighted AUCs: [0.9080698087350727]\n",
      "weighted average Recalls: 0.614696734059098\n",
      "unweighted average Recalls (macro): 0.45088357628889064\n",
      "weighted average Precisions: 0.6411023807492509\n",
      "unweighted average Precisions(macro): 0.4656427549162262\n",
      "weighted average F1s: 0.6037290877477827\n",
      "unweighted average F1s(macro): 0.40003452411415574\n",
      "Test Categorical Accuracy: 0.614696734059098\n",
      "Epoch 23/30\n",
      "19909/19909 [==============================] - 929s 47ms/step - loss: 0.8877 - categorical_accuracy: 0.7132\n",
      "Weighted AUCs: [0.9060398230994127]\n",
      "weighted average Recalls: 0.6267496111975117\n",
      "unweighted average Recalls (macro): 0.44948002797680003\n",
      "weighted average Precisions: 0.6285233482863084\n",
      "unweighted average Precisions(macro): 0.4836827833850881\n",
      "weighted average F1s: 0.6037600769912524\n",
      "unweighted average F1s(macro): 0.4213322109778866\n",
      "Test Categorical Accuracy: 0.626749611104814\n",
      "Epoch 24/30\n",
      "19909/19909 [==============================] - 930s 47ms/step - loss: 0.8697 - categorical_accuracy: 0.7222\n",
      "Weighted AUCs: [0.9062093510998361]\n",
      "weighted average Recalls: 0.6178071539657853\n",
      "unweighted average Recalls (macro): 0.3913820729207149\n",
      "weighted average Precisions: 0.6145319719348211\n",
      "unweighted average Precisions(macro): 0.5110175449950437\n",
      "weighted average F1s: 0.5875742005676848\n",
      "unweighted average F1s(macro): 0.39113808927688365\n",
      "Test Categorical Accuracy: 0.6178071538730876\n",
      "Epoch 25/30\n",
      "19909/19909 [==============================] - 929s 47ms/step - loss: 0.8529 - categorical_accuracy: 0.7247\n",
      "Weighted AUCs: [0.9069842589756809]\n",
      "weighted average Recalls: 0.6388024883359253\n",
      "unweighted average Recalls (macro): 0.42989226541538683\n",
      "weighted average Precisions: 0.6289996476732065\n",
      "unweighted average Precisions(macro): 0.5024159725822291\n",
      "weighted average F1s: 0.599875830409635\n",
      "unweighted average F1s(macro): 0.4024650049046359\n",
      "Test Categorical Accuracy: 0.6388024882895765\n",
      "Epoch 26/30\n",
      "19909/19909 [==============================] - 929s 47ms/step - loss: 0.8395 - categorical_accuracy: 0.7284\n",
      "Weighted AUCs: [0.9099362537674826]\n",
      "weighted average Recalls: 0.6368584758942457\n",
      "unweighted average Recalls (macro): 0.4241532213823901\n",
      "weighted average Precisions: 0.6287567521789083\n",
      "unweighted average Precisions(macro): 0.4801900726928947\n",
      "weighted average F1s: 0.6087158897413038\n",
      "unweighted average F1s(macro): 0.40384495585228775\n",
      "Test Categorical Accuracy: 0.6368584759174202\n",
      "Epoch 27/30\n",
      "19909/19909 [==============================] - 930s 47ms/step - loss: 0.8158 - categorical_accuracy: 0.7358\n",
      "Weighted AUCs: [0.9028381114655374]\n",
      "weighted average Recalls: 0.6158631415241057\n",
      "unweighted average Recalls (macro): 0.4311985586090104\n",
      "weighted average Precisions: 0.5901605300685433\n",
      "unweighted average Precisions(macro): 0.3928478899663299\n",
      "weighted average F1s: 0.5860875983970212\n",
      "unweighted average F1s(macro): 0.39226166048488853\n",
      "Test Categorical Accuracy: 0.615863141535693\n",
      "Epoch 28/30\n",
      "19909/19909 [==============================] - 930s 47ms/step - loss: 0.7992 - categorical_accuracy: 0.7387\n",
      "Weighted AUCs: [0.9082313672724551]\n",
      "weighted average Recalls: 0.6174183514774495\n",
      "unweighted average Recalls (macro): 0.42541486053856425\n",
      "weighted average Precisions: 0.6397985737058877\n",
      "unweighted average Precisions(macro): 0.47495493737067346\n",
      "weighted average F1s: 0.6039581604805051\n",
      "unweighted average F1s(macro): 0.40366176991241054\n",
      "Test Categorical Accuracy: 0.6174183513847518\n",
      "Epoch 29/30\n",
      "19909/19909 [==============================] - 930s 47ms/step - loss: 0.7972 - categorical_accuracy: 0.7429\n",
      "Weighted AUCs: [0.8993103935156248]\n",
      "weighted average Recalls: 0.5863141524105754\n",
      "unweighted average Recalls (macro): 0.37940677171164056\n",
      "weighted average Precisions: 0.6192960276033862\n",
      "unweighted average Precisions(macro): 0.4470038012563188\n",
      "weighted average F1s: 0.5746452795873679\n",
      "unweighted average F1s(macro): 0.37105253815208766\n",
      "Test Categorical Accuracy: 0.5863141524105754\n",
      "Epoch 30/30\n",
      "19909/19909 [==============================] - 930s 47ms/step - loss: 0.7701 - categorical_accuracy: 0.7485\n",
      "Weighted AUCs: [0.9074905025544807]\n",
      "weighted average Recalls: 0.6193623639191291\n",
      "unweighted average Recalls (macro): 0.4552775250762693\n",
      "weighted average Precisions: 0.6453382554815201\n",
      "unweighted average Precisions(macro): 0.4680304308840145\n",
      "weighted average F1s: 0.6169744490521445\n",
      "unweighted average F1s(macro): 0.43940165076455845\n",
      "Test Categorical Accuracy: 0.6193623638264314\n",
      "AUC_max: 0.91151015307726 Recall_weighted_max: 0.6388024883359253 Recall_macro_max: 0.4552775250762693 Precision_weighted_max: 0.652920287901274 Precision_macro_max: 0.5404540189503257 F1_score_weighted_max: 0.6169744490521445 F1_score_macro_max: 0.43940165076455845 ACC_max: 0.6388024882895765\n"
     ]
    }
   ],
   "source": [
    "#  FCN-4 + output  (FMA)\n",
    "import numpy as np \n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Flatten,Dense,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 30\n",
    "input_shape = (96,1360,1)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,4),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(384,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4,5),strides=(2,4),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(768,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,8),strides=(2,4),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2048,(3,3),strides=(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4,8),strides=(4,8),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(),metrics=['categorical_accuracy'])\n",
    "\n",
    "filepath='C:/DT/model_save/fma/fcn/'+\"{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "\n",
    "path = 'C:/DT/fma_medium'\n",
    "x_train = np.load(path+'\\\\x_train.npy')\n",
    "y_train = np.load(path+'\\\\train_y.npy')\n",
    "y_train_idx = np.argmax(y_train,axis = -1)\n",
    "x_test = np.load(path+'\\\\x_test.npy')\n",
    "y_test = np.load(path+'\\\\test_y.npy')\n",
    "y_test_idx = np.argmax(y_test,axis = -1)\n",
    "\n",
    "AUC_max = 0\n",
    "Recall_weighted_max = 0\n",
    "Recall_macro_max = 0\n",
    "Precision_weighted_max = 0\n",
    "Precision_macro_max = 0\n",
    "F1_score_weighted_max = 0\n",
    "F1_score_macro_max = 0\n",
    "ACC_max = 0\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,recall_score,precision_score,f1_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # all evaluation metrics include train, val, test except accs\n",
    "        self.aucs = [] # weighted AUC\n",
    "        self.recalls = [] # 16 recalls on each class and 1 mean recall\n",
    "        self.precisions = [] # 16 precisions on each class and 1 mean precision\n",
    "        self.f1s = [] # 16 f1s on each class and 1 mean f1 \n",
    "        self.accs = [] # mean accuracy without take imblance into account\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global AUC_max, Recall_weighted_max, Recall_macro_max, Precision_weighted_max, Precision_macro_max, \\\n",
    "                F1_score_weighted_max, F1_score_macro_max, ACC_max\n",
    "        y_pred_test = self.model.predict(x_test)\n",
    "        y_pred_test_idx = np.argmax(y_pred_test,axis = -1)\n",
    "                \n",
    "        auc = []\n",
    "        auc_test = roc_auc_score(y_test, y_pred_test,'weighted')\n",
    "        if auc_test > AUC_max:\n",
    "            AUC_max = auc_test\n",
    "        auc.append(auc_test)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"Weighted AUCs:\",auc)\n",
    "        \n",
    "        recall = []\n",
    "        recall_all = recall_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        recall.append(recall_all)\n",
    "        recall_mean = recall_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        if recall_mean > Recall_weighted_max:\n",
    "            Recall_weighted_max = recall_mean\n",
    "        recall.append(recall_mean)\n",
    "        recall_mean = recall_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        if recall_mean > Recall_macro_max:\n",
    "            Recall_macro_max = recall_mean\n",
    "        recall.append(recall_mean)\n",
    "        self.recalls.append(recall)\n",
    "        print(\"weighted average Recalls:\",recall[1])\n",
    "        print(\"unweighted average Recalls (macro):\",recall[2])\n",
    "        \n",
    "        precision = []\n",
    "        precision_all = precision_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        precision.append(precision_all)\n",
    "        precision_mean = precision_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        if precision_mean > Precision_weighted_max:\n",
    "            Precision_weighted_max = precision_mean\n",
    "        precision.append(precision_mean)\n",
    "        precision_mean = precision_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        if precision_mean > Precision_macro_max:\n",
    "            Precision_macro_max = precision_mean\n",
    "        precision.append(precision_mean)\n",
    "        self.precisions.append(precision)\n",
    "        print(\"weighted average Precisions:\",precision[1])\n",
    "        print(\"unweighted average Precisions(macro):\",precision[2])\n",
    "        \n",
    "        f1 = []\n",
    "        f1_all = f1_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        f1.append(f1_all)\n",
    "        f1_mean = f1_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        if f1_mean > F1_score_weighted_max:\n",
    "            F1_score_weighted_max = f1_mean\n",
    "        f1.append(f1_mean)\n",
    "        f1_mean = f1_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        if f1_mean > F1_score_macro_max:\n",
    "            F1_score_macro_max = f1_mean\n",
    "        f1.append(f1_mean)\n",
    "        self.f1s.append(f1)\n",
    "        print(\"weighted average F1s:\",f1[1])\n",
    "        print(\"unweighted average F1s(macro):\",f1[2])\n",
    "        \n",
    "        loss, acc = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "        if acc > ACC_max:\n",
    "            ACC_max = acc\n",
    "        self.accs.append(acc)\n",
    "        print(\"Test Categorical Accuracy:\",acc)              \n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, batch_size = 16, epochs = epochs, callbacks=[histories,checkpoint])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "pickle.dump(histories.aucs,open(os.path.join(path,'metrics_save/fcn_aucs.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls,open(os.path.join(path,'metrics_save/fcn_recalls.pkl'),'wb'))\n",
    "pickle.dump(histories.precisions,open(os.path.join(path,'metrics_save/fcn_precisions.pkl'),'wb'))\n",
    "pickle.dump(histories.f1s,open(os.path.join(path,'metrics_save/fcn_f1s.pkl'),'wb'))\n",
    "pickle.dump(histories.accs,open(os.path.join(path,'metrics_save/fcn_accs.pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(path,'metrics_save/fcn_history.pkl'),'wb'))\n",
    "print('AUC_max:',AUC_max,'Recall_weighted_max:',Recall_weighted_max,'Recall_macro_max:',Recall_macro_max,\n",
    "     'Precision_weighted_max:',Precision_weighted_max,'Precision_macro_max:',Precision_macro_max,\n",
    "     'F1_score_weighted_max:',F1_score_weighted_max,'F1_score_macro_max:',F1_score_macro_max,\n",
    "     'ACC_max:',ACC_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 1360, 10) 970         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 96, 1360, 6)  1734        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 96, 1360, 3)  1443        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 96, 1360, 3)  2019        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 96, 1360, 15) 1140        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 96, 1360, 6)  1356        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 96, 1360, 3)  1128        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 96, 1360, 3)  1578        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 96, 1360, 15) 390         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 96, 1360, 10) 760         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 96, 1360, 5)  630         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 96, 1360, 5)  880         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 1360, 10) 40          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 96, 1360, 6)  24          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 96, 1360, 3)  12          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 96, 1360, 3)  12          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 96, 1360, 15) 60          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 96, 1360, 6)  24          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 96, 1360, 3)  12          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 96, 1360, 3)  12          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 96, 1360, 15) 60          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 96, 1360, 10) 40          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 96, 1360, 5)  20          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 96, 1360, 5)  20          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 1360, 10) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 96, 1360, 6)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 96, 1360, 3)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 96, 1360, 3)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 96, 1360, 15) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 96, 1360, 6)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 96, 1360, 3)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 96, 1360, 3)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 96, 1360, 15) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 96, 1360, 10) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 96, 1360, 5)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 96, 1360, 5)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 24, 340, 10)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 340, 6)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 24, 340, 3)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 24, 340, 3)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 24, 340, 15)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 24, 340, 6)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 24, 340, 3)   0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 24, 340, 3)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 24, 340, 15)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 24, 340, 10)  0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 24, 340, 5)   0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 24, 340, 5)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 24, 340, 84)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 24, 340, 32)  172064      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 24, 340, 32)  128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 24, 340, 32)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 6, 85, 32)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16320)        0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16320)        0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          1632100     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           1616        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,820,272\n",
      "Trainable params: 1,820,040\n",
      "Non-trainable params: 232\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "19909/19909 [==============================] - 1293s 65ms/step - loss: 2.6427 - categorical_accuracy: 0.4026\n",
      "Weighted AUCs: [0.7925201599897662]\n",
      "weighted average Recalls: 0.44673405909797825\n",
      "unweighted average Recalls (macro): 0.1091589615139203\n",
      "weighted average Precisions: 0.2561530497334488\n",
      "unweighted average Precisions(macro): 0.06375844357226926\n",
      "weighted average F1s: 0.32345479103544394\n",
      "unweighted average F1s(macro): 0.07993222355192925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Categorical Accuracy: 0.44673405909797825\n",
      "Epoch 2/30\n",
      "19909/19909 [==============================] - 1284s 64ms/step - loss: 1.6756 - categorical_accuracy: 0.4644\n",
      "Weighted AUCs: [0.8179792056822771]\n",
      "weighted average Recalls: 0.45295489891135304\n",
      "unweighted average Recalls (macro): 0.12753095419433472\n",
      "weighted average Precisions: 0.314055836590573\n",
      "unweighted average Precisions(macro): 0.09402403618436266\n",
      "weighted average F1s: 0.3592544642441051\n",
      "unweighted average F1s(macro): 0.10081937767546441\n",
      "Test Categorical Accuracy: 0.45295489891135304\n",
      "Epoch 3/30\n",
      "19909/19909 [==============================] - 1281s 64ms/step - loss: 1.5601 - categorical_accuracy: 0.5029\n",
      "Weighted AUCs: [0.8410250616251833]\n",
      "weighted average Recalls: 0.5217729393468118\n",
      "unweighted average Recalls (macro): 0.2519197826708527\n",
      "weighted average Precisions: 0.44058402750578324\n",
      "unweighted average Precisions(macro): 0.2138336431736346\n",
      "weighted average F1s: 0.46298426581505986\n",
      "unweighted average F1s(macro): 0.2185681658102513\n",
      "Test Categorical Accuracy: 0.5217729393468118\n",
      "Epoch 4/30\n",
      "19909/19909 [==============================] - 1285s 65ms/step - loss: 1.4198 - categorical_accuracy: 0.5552\n",
      "Weighted AUCs: [0.8632820467749243]\n",
      "weighted average Recalls: 0.5594867807153966\n",
      "unweighted average Recalls (macro): 0.28426059006849697\n",
      "weighted average Precisions: 0.47774343673039754\n",
      "unweighted average Precisions(macro): 0.24747276968496018\n",
      "weighted average F1s: 0.4992599241574601\n",
      "unweighted average F1s(macro): 0.24733538662852336\n",
      "Test Categorical Accuracy: 0.5594867807153966\n",
      "Epoch 5/30\n",
      "19909/19909 [==============================] - 1285s 65ms/step - loss: 1.3429 - categorical_accuracy: 0.5846\n",
      "Weighted AUCs: [0.8687181497853491]\n",
      "weighted average Recalls: 0.5688180404354588\n",
      "unweighted average Recalls (macro): 0.29188671468829275\n",
      "weighted average Precisions: 0.4938958198927758\n",
      "unweighted average Precisions(macro): 0.2545042332527773\n",
      "weighted average F1s: 0.5056061997767758\n",
      "unweighted average F1s(macro): 0.24986250920422134\n",
      "Test Categorical Accuracy: 0.5688180404354588\n",
      "Epoch 6/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 1.2857 - categorical_accuracy: 0.6020\n",
      "Weighted AUCs: [0.859409536584749]\n",
      "weighted average Recalls: 0.5128304821150855\n",
      "unweighted average Recalls (macro): 0.23566989269483496\n",
      "weighted average Precisions: 0.5108209469635028\n",
      "unweighted average Precisions(macro): 0.3268280732423904\n",
      "weighted average F1s: 0.4564906268449824\n",
      "unweighted average F1s(macro): 0.2435272469678863\n",
      "Test Categorical Accuracy: 0.5128304821150855\n",
      "Epoch 7/30\n",
      "19909/19909 [==============================] - 1285s 65ms/step - loss: 1.2452 - categorical_accuracy: 0.6153\n",
      "Weighted AUCs: [0.8733956928416131]\n",
      "weighted average Recalls: 0.5742612752721618\n",
      "unweighted average Recalls (macro): 0.30937568855441233\n",
      "weighted average Precisions: 0.5306735377805091\n",
      "unweighted average Precisions(macro): 0.292055860749902\n",
      "weighted average F1s: 0.5374623749825531\n",
      "unweighted average F1s(macro): 0.29055683170522945\n",
      "Test Categorical Accuracy: 0.5742612752721618\n",
      "Epoch 8/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 1.2070 - categorical_accuracy: 0.6283\n",
      "Weighted AUCs: [0.8672050104129618]\n",
      "weighted average Recalls: 0.5594867807153966\n",
      "unweighted average Recalls (macro): 0.25221045633404315\n",
      "weighted average Precisions: 0.5749966063820388\n",
      "unweighted average Precisions(macro): 0.36769948828665144\n",
      "weighted average F1s: 0.5146016620233438\n",
      "unweighted average F1s(macro): 0.25017442710530335\n",
      "Test Categorical Accuracy: 0.5594867807153966\n",
      "Epoch 9/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 1.1703 - categorical_accuracy: 0.6387\n",
      "Weighted AUCs: [0.8759076717018018]\n",
      "weighted average Recalls: 0.5738724727838258\n",
      "unweighted average Recalls (macro): 0.28568880841783717\n",
      "weighted average Precisions: 0.4978550045057537\n",
      "unweighted average Precisions(macro): 0.2726175399871883\n",
      "weighted average F1s: 0.5223707190486273\n",
      "unweighted average F1s(macro): 0.27172676660093337\n",
      "Test Categorical Accuracy: 0.5738724727838258\n",
      "Epoch 10/30\n",
      "19909/19909 [==============================] - 1284s 64ms/step - loss: 1.1362 - categorical_accuracy: 0.6479\n",
      "Weighted AUCs: [0.8842357017167758]\n",
      "weighted average Recalls: 0.593701399688958\n",
      "unweighted average Recalls (macro): 0.3103752488320066\n",
      "weighted average Precisions: 0.5082206278304876\n",
      "unweighted average Precisions(macro): 0.31415634725016517\n",
      "weighted average F1s: 0.5357453217657011\n",
      "unweighted average F1s(macro): 0.3026832432852263\n",
      "Test Categorical Accuracy: 0.5937013997121324\n",
      "Epoch 11/30\n",
      "19909/19909 [==============================] - 1284s 64ms/step - loss: 1.0980 - categorical_accuracy: 0.6572\n",
      "Weighted AUCs: [0.8812030009442073]\n",
      "weighted average Recalls: 0.5762052877138414\n",
      "unweighted average Recalls (macro): 0.3204603238705961\n",
      "weighted average Precisions: 0.5161235937793056\n",
      "unweighted average Precisions(macro): 0.3158727505341482\n",
      "weighted average F1s: 0.5240299116654801\n",
      "unweighted average F1s(macro): 0.2957318579181742\n",
      "Test Categorical Accuracy: 0.5762052877370158\n",
      "Epoch 12/30\n",
      "19909/19909 [==============================] - 1284s 64ms/step - loss: 1.0590 - categorical_accuracy: 0.6686\n",
      "Weighted AUCs: [0.8749174984351226]\n",
      "weighted average Recalls: 0.5824261275272161\n",
      "unweighted average Recalls (macro): 0.3270137269856098\n",
      "weighted average Precisions: 0.543409865842271\n",
      "unweighted average Precisions(macro): 0.32984704276205734\n",
      "weighted average F1s: 0.549738680396275\n",
      "unweighted average F1s(macro): 0.31862915080720466\n",
      "Test Categorical Accuracy: 0.5824261275272161\n",
      "Epoch 13/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 1.0338 - categorical_accuracy: 0.6767\n",
      "Weighted AUCs: [0.8843092534642916]\n",
      "weighted average Recalls: 0.6026438569206843\n",
      "unweighted average Recalls (macro): 0.3541282148472711\n",
      "weighted average Precisions: 0.5461885591432615\n",
      "unweighted average Precisions(macro): 0.3341508835651754\n",
      "weighted average F1s: 0.5620390617011607\n",
      "unweighted average F1s(macro): 0.3323478364187559\n",
      "Test Categorical Accuracy: 0.6026438569206843\n",
      "Epoch 14/30\n",
      "19909/19909 [==============================] - 1285s 65ms/step - loss: 0.9976 - categorical_accuracy: 0.6845\n",
      "Weighted AUCs: [0.8910840622346404]\n",
      "weighted average Recalls: 0.6170295489891136\n",
      "unweighted average Recalls (macro): 0.3549958729546517\n",
      "weighted average Precisions: 0.553085903051425\n",
      "unweighted average Precisions(macro): 0.33473526553702776\n",
      "weighted average F1s: 0.5725750010528728\n",
      "unweighted average F1s(macro): 0.33223067831727193\n",
      "Test Categorical Accuracy: 0.6170295489891136\n",
      "Epoch 15/30\n",
      "19909/19909 [==============================] - 1285s 65ms/step - loss: 0.9769 - categorical_accuracy: 0.6944\n",
      "Weighted AUCs: [0.8771824313644362]\n",
      "weighted average Recalls: 0.5738724727838258\n",
      "unweighted average Recalls (macro): 0.2714779037891974\n",
      "weighted average Precisions: 0.5154339164924775\n",
      "unweighted average Precisions(macro): 0.316534190722603\n",
      "weighted average F1s: 0.5286899485225254\n",
      "unweighted average F1s(macro): 0.27810423260842576\n",
      "Test Categorical Accuracy: 0.5738724727838258\n",
      "Epoch 16/30\n",
      "19909/19909 [==============================] - 1285s 65ms/step - loss: 0.9486 - categorical_accuracy: 0.6990\n",
      "Weighted AUCs: [0.8813926649501154]\n",
      "weighted average Recalls: 0.5917573872472783\n",
      "unweighted average Recalls (macro): 0.315391047094692\n",
      "weighted average Precisions: 0.5468198306694184\n",
      "unweighted average Precisions(macro): 0.33735107368207057\n",
      "weighted average F1s: 0.5539972718387698\n",
      "unweighted average F1s(macro): 0.3130676963430188\n",
      "Test Categorical Accuracy: 0.5917573872472783\n",
      "Epoch 17/30\n",
      "19909/19909 [==============================] - 1285s 65ms/step - loss: 0.9215 - categorical_accuracy: 0.7111\n",
      "Weighted AUCs: [0.8787815324477695]\n",
      "weighted average Recalls: 0.5750388802488335\n",
      "unweighted average Recalls (macro): 0.29236739361431396\n",
      "weighted average Precisions: 0.5229192809764887\n",
      "unweighted average Precisions(macro): 0.30527566931300637\n",
      "weighted average F1s: 0.5290186254226504\n",
      "unweighted average F1s(macro): 0.2870728671469395\n",
      "Test Categorical Accuracy: 0.5750388802488335\n",
      "Epoch 18/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 0.8967 - categorical_accuracy: 0.7155\n",
      "Weighted AUCs: [0.8864789085143306]\n",
      "weighted average Recalls: 0.6076982892690513\n",
      "unweighted average Recalls (macro): 0.35417720687193055\n",
      "weighted average Precisions: 0.561272894868798\n",
      "unweighted average Precisions(macro): 0.3558070925984645\n",
      "weighted average F1s: 0.5740593233455968\n",
      "unweighted average F1s(macro): 0.3433840399721012\n",
      "Test Categorical Accuracy: 0.6076982892690513\n",
      "Epoch 19/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 0.8646 - categorical_accuracy: 0.7209\n",
      "Weighted AUCs: [0.8811819483951103]\n",
      "weighted average Recalls: 0.5913685847589425\n",
      "unweighted average Recalls (macro): 0.31483605330476333\n",
      "weighted average Precisions: 0.5450574594549271\n",
      "unweighted average Precisions(macro): 0.32631560654813707\n",
      "weighted average F1s: 0.5590604851469284\n",
      "unweighted average F1s(macro): 0.3099819625666558\n",
      "Test Categorical Accuracy: 0.5913685847589425\n",
      "Epoch 20/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 0.8429 - categorical_accuracy: 0.7297\n",
      "Weighted AUCs: [0.8776134699351724]\n",
      "weighted average Recalls: 0.588646967340591\n",
      "unweighted average Recalls (macro): 0.3161145887936954\n",
      "weighted average Precisions: 0.543757669944458\n",
      "unweighted average Precisions(macro): 0.34125850569805305\n",
      "weighted average F1s: 0.5567016770047014\n",
      "unweighted average F1s(macro): 0.32087290860642026\n",
      "Test Categorical Accuracy: 0.588646967340591\n",
      "Epoch 21/30\n",
      "19909/19909 [==============================] - 1285s 65ms/step - loss: 0.8168 - categorical_accuracy: 0.7394\n",
      "Weighted AUCs: [0.8784936874093229]\n",
      "weighted average Recalls: 0.5913685847589425\n",
      "unweighted average Recalls (macro): 0.3271161734859549\n",
      "weighted average Precisions: 0.5603719218518269\n",
      "unweighted average Precisions(macro): 0.3440778157415799\n",
      "weighted average F1s: 0.5710403597225988\n",
      "unweighted average F1s(macro): 0.3323253139012555\n",
      "Test Categorical Accuracy: 0.5913685847589425\n",
      "Epoch 22/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 0.7991 - categorical_accuracy: 0.7436\n",
      "Weighted AUCs: [0.8761511803255069]\n",
      "weighted average Recalls: 0.5948678071539658\n",
      "unweighted average Recalls (macro): 0.363733386341635\n",
      "weighted average Precisions: 0.559413946077061\n",
      "unweighted average Precisions(macro): 0.34542324614330183\n",
      "weighted average F1s: 0.5724286999787807\n",
      "unweighted average F1s(macro): 0.34956641696733814\n",
      "Test Categorical Accuracy: 0.5948678071539658\n",
      "Epoch 23/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 0.7683 - categorical_accuracy: 0.7510\n",
      "Weighted AUCs: [0.8744516745519267]\n",
      "weighted average Recalls: 0.5777604976671851\n",
      "unweighted average Recalls (macro): 0.31164680829320424\n",
      "weighted average Precisions: 0.5410829909604963\n",
      "unweighted average Precisions(macro): 0.3259007549796731\n",
      "weighted average F1s: 0.5486573626790715\n",
      "unweighted average F1s(macro): 0.30852737080585874\n",
      "Test Categorical Accuracy: 0.5777604976787722\n",
      "Epoch 24/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 0.7446 - categorical_accuracy: 0.7628\n",
      "Weighted AUCs: [0.862832489843631]\n",
      "weighted average Recalls: 0.5629860031104199\n",
      "unweighted average Recalls (macro): 0.33768223643600115\n",
      "weighted average Precisions: 0.5778240702814482\n",
      "unweighted average Precisions(macro): 0.31297005849046866\n",
      "weighted average F1s: 0.5610250566623017\n",
      "unweighted average F1s(macro): 0.31279355840210377\n",
      "Test Categorical Accuracy: 0.5629860031104199\n",
      "Epoch 25/30\n",
      "19909/19909 [==============================] - 1285s 65ms/step - loss: 0.7184 - categorical_accuracy: 0.7692\n",
      "Weighted AUCs: [0.8756400538395369]\n",
      "weighted average Recalls: 0.5851477449455676\n",
      "unweighted average Recalls (macro): 0.31416915648909155\n",
      "weighted average Precisions: 0.5386657188375864\n",
      "unweighted average Precisions(macro): 0.3328014418897657\n",
      "weighted average F1s: 0.5536471751325162\n",
      "unweighted average F1s(macro): 0.31672901434038503\n",
      "Test Categorical Accuracy: 0.5851477449687421\n",
      "Epoch 26/30\n",
      "19909/19909 [==============================] - 1283s 64ms/step - loss: 0.6916 - categorical_accuracy: 0.7739\n",
      "Weighted AUCs: [0.8787979699924003]\n",
      "weighted average Recalls: 0.5933125972006221\n",
      "unweighted average Recalls (macro): 0.3404134621167866\n",
      "weighted average Precisions: 0.5632256658436652\n",
      "unweighted average Precisions(macro): 0.329956146890641\n",
      "weighted average F1s: 0.5750133202662328\n",
      "unweighted average F1s(macro): 0.33222638363986073\n",
      "Test Categorical Accuracy: 0.5933125972122093\n",
      "Epoch 27/30\n",
      "19909/19909 [==============================] - 1284s 64ms/step - loss: 0.6728 - categorical_accuracy: 0.7780\n",
      "Weighted AUCs: [0.8701767274794607]\n",
      "weighted average Recalls: 0.5808709175738724\n",
      "unweighted average Recalls (macro): 0.3088766671478616\n",
      "weighted average Precisions: 0.5389730208361929\n",
      "unweighted average Precisions(macro): 0.31945652301149463\n",
      "weighted average F1s: 0.5529512262200758\n",
      "unweighted average F1s(macro): 0.30740965607468523\n",
      "Test Categorical Accuracy: 0.5808709175854597\n",
      "Epoch 28/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 0.6514 - categorical_accuracy: 0.7863\n",
      "Weighted AUCs: [0.8643559291838036]\n",
      "weighted average Recalls: 0.5423794712286159\n",
      "unweighted average Recalls (macro): 0.277151773250687\n",
      "weighted average Precisions: 0.5144792571946342\n",
      "unweighted average Precisions(macro): 0.3265764037933152\n",
      "weighted average F1s: 0.5018958079195165\n",
      "unweighted average F1s(macro): 0.28349357182257945\n",
      "Test Categorical Accuracy: 0.5423794712517903\n",
      "Epoch 29/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 0.6307 - categorical_accuracy: 0.7940\n",
      "Weighted AUCs: [0.8722725272456371]\n",
      "weighted average Recalls: 0.583592534992224\n",
      "unweighted average Recalls (macro): 0.27539378777231927\n",
      "weighted average Precisions: 0.522226028904066\n",
      "unweighted average Precisions(macro): 0.3400377674175086\n",
      "weighted average F1s: 0.5320807112420544\n",
      "unweighted average F1s(macro): 0.2782703920072822\n",
      "Test Categorical Accuracy: 0.583592534992224\n",
      "Epoch 30/30\n",
      "19909/19909 [==============================] - 1284s 65ms/step - loss: 0.6030 - categorical_accuracy: 0.8004\n",
      "Weighted AUCs: [0.865586673301058]\n",
      "weighted average Recalls: 0.5633748055987559\n",
      "unweighted average Recalls (macro): 0.3055167442637581\n",
      "weighted average Precisions: 0.5681218043965391\n",
      "unweighted average Precisions(macro): 0.34239808995406956\n",
      "weighted average F1s: 0.5574661498861675\n",
      "unweighted average F1s(macro): 0.31106048083237425\n",
      "Test Categorical Accuracy: 0.5633748055987559\n",
      "AUC_max: 0.8910840622346404 Recall_weighted_max: 0.6170295489891136 Recall_macro_max: 0.363733386341635 Precision_weighted_max: 0.5778240702814482 Precision_macro_max: 0.36769948828665144 F1_score_weighted_max: 0.5750133202662328 F1_score_macro_max: 0.34956641696733814 ACC_max: 0.6170295489891136\n"
     ]
    }
   ],
   "source": [
    "#  Timbre CNN  (FMA)\n",
    "import numpy as np \n",
    "from keras.layers import Input,Conv2D,BatchNormalization,Activation,MaxPooling2D,Concatenate,Flatten,Dropout,Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "epochs = 30\n",
    "pool_size = (4,4)\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape)\n",
    "\n",
    "conv1_10_96_1 = Conv2D(10,(96,1),padding='same')(input_melS)\n",
    "bn1_10_96_1 = BatchNormalization()(conv1_10_96_1)\n",
    "act1_10_96_1 = Activation('relu')(bn1_10_96_1)\n",
    "max1_10_96_1 = MaxPooling2D(pool_size,padding='same')(act1_10_96_1)\n",
    "conv1_6_96_3 = Conv2D(6,(96,3),padding='same')(input_melS)\n",
    "bn1_6_96_3 = BatchNormalization()(conv1_6_96_3)\n",
    "act1_6_96_3 = Activation('relu')(bn1_6_96_3)\n",
    "max1_6_96_3 = MaxPooling2D(pool_size,padding='same')(act1_6_96_3)\n",
    "conv1_3_96_5 = Conv2D(3,(96,5),padding='same')(input_melS)\n",
    "bn1_3_96_5 = BatchNormalization()(conv1_3_96_5)\n",
    "act1_3_96_5 = Activation('relu')(bn1_3_96_5)\n",
    "max1_3_96_5 = MaxPooling2D(pool_size,padding='same')(act1_3_96_5)\n",
    "conv1_3_96_7 = Conv2D(3,(96,7),padding='same')(input_melS)\n",
    "bn1_3_96_7 = BatchNormalization()(conv1_3_96_7)\n",
    "act1_3_96_7 = Activation('relu')(bn1_3_96_7)\n",
    "max1_3_96_7 = MaxPooling2D(pool_size,padding='same')(act1_3_96_7)\n",
    "conv1_15_75_1 = Conv2D(15,(75,1),padding='same')(input_melS)\n",
    "bn1_15_75_1 = BatchNormalization()(conv1_15_75_1)\n",
    "act1_15_75_1 = Activation('relu')(bn1_15_75_1)\n",
    "max1_15_75_1 = MaxPooling2D(pool_size,padding='same')(act1_15_75_1)\n",
    "conv1_10_75_3 = Conv2D(6,(75,3),padding='same')(input_melS)\n",
    "bn1_10_75_3 = BatchNormalization()(conv1_10_75_3)\n",
    "act1_10_75_3 = Activation('relu')(bn1_10_75_3)\n",
    "max1_10_75_3 = MaxPooling2D(pool_size,padding='same')(act1_10_75_3)\n",
    "conv1_5_75_5 = Conv2D(3,(75,5),padding='same')(input_melS)\n",
    "bn1_5_75_5 = BatchNormalization()(conv1_5_75_5)\n",
    "act1_5_75_5 = Activation('relu')(bn1_5_75_5)\n",
    "max1_5_75_5 = MaxPooling2D(pool_size,padding='same')(act1_5_75_5)\n",
    "conv1_5_75_7 = Conv2D(3,(75,7),padding='same')(input_melS)\n",
    "bn1_5_75_7 = BatchNormalization()(conv1_5_75_7)\n",
    "act1_5_75_7 = Activation('relu')(bn1_5_75_7)\n",
    "max1_5_75_7 = MaxPooling2D(pool_size,padding='same')(act1_5_75_7)\n",
    "conv1_15_25_1 = Conv2D(15,(25,1),padding='same')(input_melS)\n",
    "bn1_15_25_1 = BatchNormalization()(conv1_15_25_1)\n",
    "act1_15_25_1 = Activation('relu')(bn1_15_25_1)\n",
    "max1_15_25_1 = MaxPooling2D(pool_size,padding='same')(act1_15_25_1)\n",
    "conv1_10_25_3 = Conv2D(10,(25,3),padding='same')(input_melS)\n",
    "bn1_10_25_3 = BatchNormalization()(conv1_10_25_3)\n",
    "act1_10_25_3 = Activation('relu')(bn1_10_25_3)\n",
    "max1_10_25_3 = MaxPooling2D(pool_size,padding='same')(act1_10_25_3)\n",
    "conv1_5_25_5 = Conv2D(5,(25,5),padding='same')(input_melS)\n",
    "bn1_5_25_5 = BatchNormalization()(conv1_5_25_5)\n",
    "act1_5_25_5 = Activation('relu')(bn1_5_25_5)\n",
    "max1_5_25_5 = MaxPooling2D(pool_size,padding='same')(act1_5_25_5)\n",
    "conv1_5_25_7 = Conv2D(5,(25,7),padding='same')(input_melS)\n",
    "bn1_5_25_7 = BatchNormalization()(conv1_5_25_7)\n",
    "act1_5_25_7 = Activation('relu')(bn1_5_25_7)\n",
    "max1_5_25_7= MaxPooling2D(pool_size,padding='same')(act1_5_25_7)\n",
    "\n",
    "max1 = Concatenate()([max1_10_96_1,max1_6_96_3,max1_3_96_5,max1_3_96_7,max1_15_75_1,max1_10_75_3,\n",
    "                        max1_5_75_5,max1_5_75_7,max1_15_25_1,max1_10_25_3,max1_5_25_5,max1_5_25_7])\n",
    "\n",
    "conv2 = Conv2D(32,(8,8),padding='same')(max1)\n",
    "bn2 = BatchNormalization()(conv2)\n",
    "act2 = Activation('relu')(bn2)\n",
    "max2 = MaxPooling2D(pool_size,padding='same')(act2)\n",
    "\n",
    "flat_max_2 = Flatten()(max2)\n",
    "drop = Dropout(0.5)(flat_max_2)\n",
    "fc1 = Dense(100, activation='relu')(drop)\n",
    "out = Dense(16, activation='softmax')(fc1)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [out])\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(),metrics=['categorical_accuracy'])\n",
    "\n",
    "filepath='C:/DT/model_save/fma/timbrecnn/'+\"{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "\n",
    "path = 'C:/DT/fma_medium'\n",
    "x_train = np.load(path+'\\\\x_train.npy')\n",
    "y_train = np.load(path+'\\\\train_y.npy')\n",
    "y_train_idx = np.argmax(y_train,axis = -1)\n",
    "x_test = np.load(path+'\\\\x_test.npy')\n",
    "y_test = np.load(path+'\\\\test_y.npy')\n",
    "y_test_idx = np.argmax(y_test,axis = -1)\n",
    "\n",
    "AUC_max = 0\n",
    "Recall_weighted_max = 0\n",
    "Recall_macro_max = 0\n",
    "Precision_weighted_max = 0\n",
    "Precision_macro_max = 0\n",
    "F1_score_weighted_max = 0\n",
    "F1_score_macro_max = 0\n",
    "ACC_max = 0\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,recall_score,precision_score,f1_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # all evaluation metrics include train, val, test except accs\n",
    "        self.aucs = [] # weighted AUC\n",
    "        self.recalls = [] # 16 recalls on each class and 1 mean recall\n",
    "        self.precisions = [] # 16 precisions on each class and 1 mean precision\n",
    "        self.f1s = [] # 16 f1s on each class and 1 mean f1 \n",
    "        self.accs = [] # mean accuracy without take imblance into account\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global AUC_max, Recall_weighted_max, Recall_macro_max, Precision_weighted_max, Precision_macro_max, \\\n",
    "                F1_score_weighted_max, F1_score_macro_max, ACC_max\n",
    "        y_pred_test = self.model.predict(x_test)\n",
    "        y_pred_test_idx = np.argmax(y_pred_test,axis = -1)\n",
    "                \n",
    "        auc = [] \n",
    "        auc_test = roc_auc_score(y_test, y_pred_test,'weighted')\n",
    "        if auc_test > AUC_max:\n",
    "            AUC_max = auc_test\n",
    "        auc.append(auc_test)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"Weighted AUCs:\",auc)\n",
    "        \n",
    "        recall = []\n",
    "        recall_all = recall_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        recall.append(recall_all)\n",
    "        recall_mean = recall_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        if recall_mean > Recall_weighted_max:\n",
    "            Recall_weighted_max = recall_mean\n",
    "        recall.append(recall_mean)\n",
    "        recall_mean = recall_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        if recall_mean > Recall_macro_max:\n",
    "            Recall_macro_max = recall_mean\n",
    "        recall.append(recall_mean)\n",
    "        self.recalls.append(recall)\n",
    "        print(\"weighted average Recalls:\",recall[1])\n",
    "        print(\"unweighted average Recalls (macro):\",recall[2])\n",
    "        \n",
    "        precision = []\n",
    "        precision_all = precision_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        precision.append(precision_all)\n",
    "        precision_mean = precision_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        if precision_mean > Precision_weighted_max:\n",
    "            Precision_weighted_max = precision_mean\n",
    "        precision.append(precision_mean)\n",
    "        precision_mean = precision_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        if precision_mean > Precision_macro_max:\n",
    "            Precision_macro_max = precision_mean\n",
    "        precision.append(precision_mean)\n",
    "        self.precisions.append(precision)\n",
    "        print(\"weighted average Precisions:\",precision[1])\n",
    "        print(\"unweighted average Precisions(macro):\",precision[2])\n",
    "        \n",
    "        f1 = []\n",
    "        f1_all = f1_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        f1.append(f1_all)\n",
    "        f1_mean = f1_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        if f1_mean > F1_score_weighted_max:\n",
    "            F1_score_weighted_max = f1_mean\n",
    "        f1.append(f1_mean)\n",
    "        f1_mean = f1_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        if f1_mean > F1_score_macro_max:\n",
    "            F1_score_macro_max = f1_mean\n",
    "        f1.append(f1_mean)\n",
    "        self.f1s.append(f1)\n",
    "        print(\"weighted average F1s:\",f1[1])\n",
    "        print(\"unweighted average F1s(macro):\",f1[2])\n",
    "        \n",
    "        loss, acc = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "        if acc > ACC_max:\n",
    "            ACC_max = acc\n",
    "        self.accs.append(acc)\n",
    "        print(\"Test Categorical Accuracy:\",acc)\n",
    "                \n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, batch_size = 16, epochs = epochs, callbacks=[histories,checkpoint])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "pickle.dump(histories.aucs,open(os.path.join(path,'metrics_save/timbrecnn_aucs.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls,open(os.path.join(path,'metrics_save/timbrecnn_recalls.pkl'),'wb'))\n",
    "pickle.dump(histories.precisions,open(os.path.join(path,'metrics_save/timbrecnn_precisions.pkl'),'wb'))\n",
    "pickle.dump(histories.f1s,open(os.path.join(path,'metrics_save/timbrecnn_f1s.pkl'),'wb'))\n",
    "pickle.dump(histories.accs,open(os.path.join(path,'metrics_save/timbrecnn_accs.pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(path,'metrics_save/timbrecnn_history.pkl'),'wb'))\n",
    "print('AUC_max:',AUC_max,'Recall_weighted_max:',Recall_weighted_max,'Recall_macro_max:',Recall_macro_max,\n",
    "     'Precision_weighted_max:',Precision_weighted_max,'Precision_macro_max:',Precision_macro_max,\n",
    "     'F1_score_weighted_max:',F1_score_weighted_max,'F1_score_macro_max:',F1_score_macro_max,\n",
    "     'ACC_max:',ACC_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 96, 1360, 64) 640         main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn_1 (BatchNormalization)       (None, 96, 1360, 64) 256         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_1 (Activation)              (None, 96, 1360, 64) 0           bn_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_1 (MaxPooling2D)           (None, 48, 340, 64)  0           act_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 48, 340, 128) 73856       pool_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_2 (BatchNormalization)       (None, 48, 340, 128) 512         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_2 (Activation)              (None, 48, 340, 128) 0           bn_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_2 (MaxPooling2D)           (None, 24, 85, 128)  0           act_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 24, 85, 128)  147584      pool_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_3 (BatchNormalization)       (None, 24, 85, 128)  512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_3 (Activation)              (None, 24, 85, 128)  0           bn_3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_3 (MaxPooling2D)           (None, 12, 22, 128)  0           act_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 12, 22, 128)  147584      pool_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_4 (BatchNormalization)       (None, 12, 22, 128)  512         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_4 (Activation)              (None, 12, 22, 128)  0           bn_4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_4 (MaxPooling2D)           (None, 6, 6, 128)    0           act_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru5_in_perm (Lambda)           (None, 6, 6, 128)    0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru3_in_perm (Lambda)           (None, 6, 6, 128)    0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru6_in_perm (Lambda)           (None, 6, 6, 128)    0           gru5_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru2_in_perm (Lambda)           (None, 6, 6, 128)    0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru4_in_perm (Lambda)           (None, 6, 6, 128)    0           gru3_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru7_in_perm (Lambda)           (None, 6, 6, 128)    0           gru5_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru8_in_perm (Lambda)           (None, 6, 6, 128)    0           gru6_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru1_in (Reshape)               (None, 6, 768)       0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2_in (Reshape)               (None, 6, 768)       0           gru2_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru3_in (Reshape)               (None, 6, 768)       0           gru3_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru4_in (Reshape)               (None, 6, 768)       0           gru4_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru5_in (Reshape)               (None, 6, 768)       0           gru5_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru6_in (Reshape)               (None, 6, 768)       0           gru6_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru7_in (Reshape)               (None, 6, 768)       0           gru7_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru8_in (Reshape)               (None, 6, 768)       0           gru8_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 32)           76896       gru1_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 32)           76896       gru2_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru3 (GRU)                      (None, 32)           76896       gru3_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru4 (GRU)                      (None, 32)           76896       gru4_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru5 (GRU)                      (None, 32)           76896       gru5_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru6 (GRU)                      (None, 32)           76896       gru6_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru7 (GRU)                      (None, 32)           76896       gru7_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru8 (GRU)                      (None, 32)           76896       gru8_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_conc (Concatenate)          (None, 256)          0           gru1[0][0]                       \n",
      "                                                                 gru2[0][0]                       \n",
      "                                                                 gru3[0][0]                       \n",
      "                                                                 gru4[0][0]                       \n",
      "                                                                 gru5[0][0]                       \n",
      "                                                                 gru6[0][0]                       \n",
      "                                                                 gru7[0][0]                       \n",
      "                                                                 gru8[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gru_conc_dropout (Dropout)      (None, 256)          0           gru_conc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 64)           16448       gru_conc_dropout[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pred (Dense)                    (None, 16)           1040        fc[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 1,004,112\n",
      "Trainable params: 1,003,216\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "19909/19909 [==============================] - 402s 20ms/step - loss: 1.5229 - categorical_accuracy: 0.5314\n",
      "Weighted AUCs: [0.851950546450343]\n",
      "weighted average Recalls: 0.3856920684292379\n",
      "unweighted average Recalls (macro): 0.17034852585925814\n",
      "weighted average Precisions: 0.49625511703505965\n",
      "unweighted average Precisions(macro): 0.2865410979927044\n",
      "weighted average F1s: 0.32785143594046234\n",
      "unweighted average F1s(macro): 0.17627082319784015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Categorical Accuracy: 0.3856920684292379\n",
      "Epoch 2/40\n",
      "19909/19909 [==============================] - 393s 20ms/step - loss: 1.3157 - categorical_accuracy: 0.5953\n",
      "Weighted AUCs: [0.7610444715035509]\n",
      "weighted average Recalls: 0.19828926905132194\n",
      "unweighted average Recalls (macro): 0.1826501857934314\n",
      "weighted average Precisions: 0.47376740908386067\n",
      "unweighted average Precisions(macro): 0.26257289043588417\n",
      "weighted average F1s: 0.15380298047914617\n",
      "unweighted average F1s(macro): 0.13610893686925687\n",
      "Test Categorical Accuracy: 0.19828926914401968\n",
      "Epoch 3/40\n",
      "19909/19909 [==============================] - 393s 20ms/step - loss: 1.2489 - categorical_accuracy: 0.6149\n",
      "Weighted AUCs: [0.8976067434023407]\n",
      "weighted average Recalls: 0.5991446345256609\n",
      "unweighted average Recalls (macro): 0.3675070066628865\n",
      "weighted average Precisions: 0.56930891624832\n",
      "unweighted average Precisions(macro): 0.35018987545639385\n",
      "weighted average F1s: 0.5638099356465712\n",
      "unweighted average F1s(macro): 0.33539106533481927\n",
      "Test Categorical Accuracy: 0.5991446345372482\n",
      "Epoch 4/40\n",
      "19909/19909 [==============================] - 395s 20ms/step - loss: 1.1951 - categorical_accuracy: 0.6316\n",
      "Weighted AUCs: [0.8839801309124269]\n",
      "weighted average Recalls: 0.5610419906687403\n",
      "unweighted average Recalls (macro): 0.24969115383036708\n",
      "weighted average Precisions: 0.5418431855650021\n",
      "unweighted average Precisions(macro): 0.310361051144715\n",
      "weighted average F1s: 0.5052066014534234\n",
      "unweighted average F1s(macro): 0.23909902019782592\n",
      "Test Categorical Accuracy: 0.5610419906687403\n",
      "Epoch 5/40\n",
      "19909/19909 [==============================] - 395s 20ms/step - loss: 1.1724 - categorical_accuracy: 0.6419\n",
      "Weighted AUCs: [0.9012521133989706]\n",
      "weighted average Recalls: 0.5975894245723172\n",
      "unweighted average Recalls (macro): 0.2672480830262526\n",
      "weighted average Precisions: 0.5362239876127372\n",
      "unweighted average Precisions(macro): 0.34270202752835754\n",
      "weighted average F1s: 0.5324521929135602\n",
      "unweighted average F1s(macro): 0.2740681858412317\n",
      "Test Categorical Accuracy: 0.5975894245723172\n",
      "Epoch 6/40\n",
      "19909/19909 [==============================] - 394s 20ms/step - loss: 1.1404 - categorical_accuracy: 0.6468\n",
      "Weighted AUCs: [0.9014148613480834]\n",
      "weighted average Recalls: 0.6135303265940902\n",
      "unweighted average Recalls (macro): 0.381808129494024\n",
      "weighted average Precisions: 0.5922890320424409\n",
      "unweighted average Precisions(macro): 0.3602822282802802\n",
      "weighted average F1s: 0.5852207213068759\n",
      "unweighted average F1s(macro): 0.35306397609395795\n",
      "Test Categorical Accuracy: 0.6135303265940902\n",
      "Epoch 7/40\n",
      "19909/19909 [==============================] - 394s 20ms/step - loss: 1.1284 - categorical_accuracy: 0.6486\n",
      "Weighted AUCs: [0.9057377963102643]\n",
      "weighted average Recalls: 0.6255832037325039\n",
      "unweighted average Recalls (macro): 0.3609122218328084\n",
      "weighted average Precisions: 0.5640998346707787\n",
      "unweighted average Precisions(macro): 0.3585459735793126\n",
      "weighted average F1s: 0.5765363430881901\n",
      "unweighted average F1s(macro): 0.34008429584587013\n",
      "Test Categorical Accuracy: 0.6255832037440912\n",
      "Epoch 8/40\n",
      "19909/19909 [==============================] - 395s 20ms/step - loss: 1.1000 - categorical_accuracy: 0.6566\n",
      "Weighted AUCs: [0.8919281362651219]\n",
      "weighted average Recalls: 0.5933125972006221\n",
      "unweighted average Recalls (macro): 0.3352041564732844\n",
      "weighted average Precisions: 0.5762073488855675\n",
      "unweighted average Precisions(macro): 0.36957094481846803\n",
      "weighted average F1s: 0.5623194996755544\n",
      "unweighted average F1s(macro): 0.3275728253951935\n",
      "Test Categorical Accuracy: 0.5933125972006221\n",
      "Epoch 9/40\n",
      "19909/19909 [==============================] - 394s 20ms/step - loss: 1.0877 - categorical_accuracy: 0.6609\n",
      "Weighted AUCs: [0.8923739686216097]\n",
      "weighted average Recalls: 0.5692068429237948\n",
      "unweighted average Recalls (macro): 0.2873459377606423\n",
      "weighted average Precisions: 0.5571877611273662\n",
      "unweighted average Precisions(macro): 0.3706722964803997\n",
      "weighted average F1s: 0.523636167257758\n",
      "unweighted average F1s(macro): 0.28561167831372364\n",
      "Test Categorical Accuracy: 0.5692068429237948\n",
      "Epoch 10/40\n",
      "19909/19909 [==============================] - 395s 20ms/step - loss: 1.0610 - categorical_accuracy: 0.6706\n",
      "Weighted AUCs: [0.9015270768503163]\n",
      "weighted average Recalls: 0.604199066874028\n",
      "unweighted average Recalls (macro): 0.36771394608191216\n",
      "weighted average Precisions: 0.572942732839995\n",
      "unweighted average Precisions(macro): 0.3663919336607651\n",
      "weighted average F1s: 0.5617951541510836\n",
      "unweighted average F1s(macro): 0.34390456548856474\n",
      "Test Categorical Accuracy: 0.6041990668972024\n",
      "Epoch 11/40\n",
      "19909/19909 [==============================] - 396s 20ms/step - loss: 1.0474 - categorical_accuracy: 0.6731\n",
      "Weighted AUCs: [0.8930158207612954]\n",
      "weighted average Recalls: 0.5940902021772939\n",
      "unweighted average Recalls (macro): 0.36230646787121457\n",
      "weighted average Precisions: 0.5960320307080978\n",
      "unweighted average Precisions(macro): 0.42965074825346583\n",
      "weighted average F1s: 0.572591106995709\n",
      "unweighted average F1s(macro): 0.3508904538817894\n",
      "Test Categorical Accuracy: 0.5940902021772939\n",
      "Epoch 12/40\n",
      "19909/19909 [==============================] - 395s 20ms/step - loss: 1.0322 - categorical_accuracy: 0.6786\n",
      "Weighted AUCs: [0.8902292815783033]\n",
      "weighted average Recalls: 0.5855365474339036\n",
      "unweighted average Recalls (macro): 0.3012864247570691\n",
      "weighted average Precisions: 0.5788689637424476\n",
      "unweighted average Precisions(macro): 0.3505845900846687\n",
      "weighted average F1s: 0.5585954916745495\n",
      "unweighted average F1s(macro): 0.29835437977950496\n",
      "Test Categorical Accuracy: 0.5855365474339036\n",
      "Epoch 13/40\n",
      "19909/19909 [==============================] - 395s 20ms/step - loss: 1.0130 - categorical_accuracy: 0.6850\n",
      "Weighted AUCs: [0.8920101773361603]\n",
      "weighted average Recalls: 0.5641524105754276\n",
      "unweighted average Recalls (macro): 0.33490504171191127\n",
      "weighted average Precisions: 0.572651501228507\n",
      "unweighted average Precisions(macro): 0.39214159432417384\n",
      "weighted average F1s: 0.5289307983070843\n",
      "unweighted average F1s(macro): 0.3270688460378696\n",
      "Test Categorical Accuracy: 0.5641524105754276\n",
      "Epoch 14/40\n",
      "19909/19909 [==============================] - 395s 20ms/step - loss: 0.9967 - categorical_accuracy: 0.6890\n",
      "Weighted AUCs: [0.8862805191768365]\n",
      "weighted average Recalls: 0.5229393468118196\n",
      "unweighted average Recalls (macro): 0.2540682540508328\n",
      "weighted average Precisions: 0.5495581745819955\n",
      "unweighted average Precisions(macro): 0.3436348445600781\n",
      "weighted average F1s: 0.4702167911549858\n",
      "unweighted average F1s(macro): 0.25956558536570284\n",
      "Test Categorical Accuracy: 0.5229393468118196\n",
      "Epoch 15/40\n",
      "19909/19909 [==============================] - 395s 20ms/step - loss: 0.9759 - categorical_accuracy: 0.6932\n",
      "Weighted AUCs: [0.9107291631278178]\n",
      "weighted average Recalls: 0.6337480559875583\n",
      "unweighted average Recalls (macro): 0.3740977450884164\n",
      "weighted average Precisions: 0.5997519383924536\n",
      "unweighted average Precisions(macro): 0.4070098765101965\n",
      "weighted average F1s: 0.603044199557777\n",
      "unweighted average F1s(macro): 0.36596450343267484\n",
      "Test Categorical Accuracy: 0.6337480560339072\n",
      "Epoch 16/40\n",
      "19909/19909 [==============================] - 393s 20ms/step - loss: 0.9649 - categorical_accuracy: 0.6958\n",
      "Weighted AUCs: [0.904381504673988]\n",
      "weighted average Recalls: 0.6267496111975117\n",
      "unweighted average Recalls (macro): 0.3689049071802788\n",
      "weighted average Precisions: 0.5826886136266023\n",
      "unweighted average Precisions(macro): 0.42158699518517456\n",
      "weighted average F1s: 0.5883237565431518\n",
      "unweighted average F1s(macro): 0.3733916624891294\n",
      "Test Categorical Accuracy: 0.6267496112206861\n",
      "Epoch 17/40\n",
      "19909/19909 [==============================] - 393s 20ms/step - loss: 0.9456 - categorical_accuracy: 0.7017\n",
      "Weighted AUCs: [0.8953492134798796]\n",
      "weighted average Recalls: 0.5758164852255054\n",
      "unweighted average Recalls (macro): 0.2877175406175893\n",
      "weighted average Precisions: 0.5872465690664596\n",
      "unweighted average Precisions(macro): 0.38165491947926883\n",
      "weighted average F1s: 0.5413284709692656\n",
      "unweighted average F1s(macro): 0.3013099503818135\n",
      "Test Categorical Accuracy: 0.5758164852255054\n",
      "Epoch 18/40\n",
      "19909/19909 [==============================] - 394s 20ms/step - loss: 0.9266 - categorical_accuracy: 0.7090\n",
      "Weighted AUCs: [0.9048918379450812]\n",
      "weighted average Recalls: 0.6329704510108864\n",
      "unweighted average Recalls (macro): 0.36856722945008796\n",
      "weighted average Precisions: 0.6101497299891594\n",
      "unweighted average Precisions(macro): 0.4116954753784906\n",
      "weighted average F1s: 0.5911309478732133\n",
      "unweighted average F1s(macro): 0.36522525597369554\n",
      "Test Categorical Accuracy: 0.6329704510224737\n",
      "Epoch 19/40\n",
      "19909/19909 [==============================] - 388s 19ms/step - loss: 0.9088 - categorical_accuracy: 0.7128\n",
      "Weighted AUCs: [0.892859894967585]\n",
      "weighted average Recalls: 0.578538102643857\n",
      "unweighted average Recalls (macro): 0.38425238999928013\n",
      "weighted average Precisions: 0.5963624610311745\n",
      "unweighted average Precisions(macro): 0.38751148981877126\n",
      "weighted average F1s: 0.5675764679916204\n",
      "unweighted average F1s(macro): 0.3625707424283366\n",
      "Test Categorical Accuracy: 0.578538102597508\n",
      "Epoch 20/40\n",
      "19909/19909 [==============================] - 389s 20ms/step - loss: 0.8942 - categorical_accuracy: 0.7181\n",
      "Weighted AUCs: [0.9093501314663113]\n",
      "weighted average Recalls: 0.6349144634525661\n",
      "unweighted average Recalls (macro): 0.371221244324315\n",
      "weighted average Precisions: 0.6163440160847506\n",
      "unweighted average Precisions(macro): 0.4183564179845818\n",
      "weighted average F1s: 0.6111631132437411\n",
      "unweighted average F1s(macro): 0.37878808283480836\n",
      "Test Categorical Accuracy: 0.6349144634525661\n",
      "Epoch 21/40\n",
      "19909/19909 [==============================] - 392s 20ms/step - loss: 0.8677 - categorical_accuracy: 0.7234\n",
      "Weighted AUCs: [0.9067269621323819]\n",
      "weighted average Recalls: 0.6228615863141524\n",
      "unweighted average Recalls (macro): 0.39388180611928175\n",
      "weighted average Precisions: 0.6230678022942114\n",
      "unweighted average Precisions(macro): 0.41890558169229275\n",
      "weighted average F1s: 0.5976536863767234\n",
      "unweighted average F1s(macro): 0.3843841617061961\n",
      "Test Categorical Accuracy: 0.6228615863141524\n",
      "Epoch 22/40\n",
      "19909/19909 [==============================] - 392s 20ms/step - loss: 0.8518 - categorical_accuracy: 0.7279\n",
      "Weighted AUCs: [0.9041501318824372]\n",
      "weighted average Recalls: 0.6411353032659409\n",
      "unweighted average Recalls (macro): 0.39794362124213695\n",
      "weighted average Precisions: 0.608018994561944\n",
      "unweighted average Precisions(macro): 0.4128309555165073\n",
      "weighted average F1s: 0.6163230857434073\n",
      "unweighted average F1s(macro): 0.3960370060102383\n",
      "Test Categorical Accuracy: 0.6411353032659409\n",
      "Epoch 23/40\n",
      "19909/19909 [==============================] - 391s 20ms/step - loss: 0.8246 - categorical_accuracy: 0.7367\n",
      "Weighted AUCs: [0.9054139804402669]\n",
      "weighted average Recalls: 0.6224727838258165\n",
      "unweighted average Recalls (macro): 0.37400410080101343\n",
      "weighted average Precisions: 0.5997944675458254\n",
      "unweighted average Precisions(macro): 0.3867317104894058\n",
      "weighted average F1s: 0.5876417063169505\n",
      "unweighted average F1s(macro): 0.3656130584617272\n",
      "Test Categorical Accuracy: 0.6224727838258165\n",
      "Epoch 24/40\n",
      "19909/19909 [==============================] - 390s 20ms/step - loss: 0.8045 - categorical_accuracy: 0.7419\n",
      "Weighted AUCs: [0.9045884065168599]\n",
      "weighted average Recalls: 0.6349144634525661\n",
      "unweighted average Recalls (macro): 0.4323869664120785\n",
      "weighted average Precisions: 0.619372420576596\n",
      "unweighted average Precisions(macro): 0.3920448181696976\n",
      "weighted average F1s: 0.610733861583705\n",
      "unweighted average F1s(macro): 0.39076335371073917\n",
      "Test Categorical Accuracy: 0.634914463498915\n",
      "Epoch 25/40\n",
      "19909/19909 [==============================] - 389s 20ms/step - loss: 0.7737 - categorical_accuracy: 0.7507\n",
      "Weighted AUCs: [0.9070891464398542]\n",
      "weighted average Recalls: 0.6244167962674961\n",
      "unweighted average Recalls (macro): 0.34077057354586593\n",
      "weighted average Precisions: 0.6081679829532538\n",
      "unweighted average Precisions(macro): 0.4334751938658708\n",
      "weighted average F1s: 0.5863751011938705\n",
      "unweighted average F1s(macro): 0.3552944484404656\n",
      "Test Categorical Accuracy: 0.6244167962674961\n",
      "Epoch 26/40\n",
      "19909/19909 [==============================] - 390s 20ms/step - loss: 0.7434 - categorical_accuracy: 0.7616\n",
      "Weighted AUCs: [0.9042169996013222]\n",
      "weighted average Recalls: 0.6259720062208398\n",
      "unweighted average Recalls (macro): 0.38286348743139886\n",
      "weighted average Precisions: 0.6367109663620789\n",
      "unweighted average Precisions(macro): 0.43755626552287297\n",
      "weighted average F1s: 0.6112010600821091\n",
      "unweighted average F1s(macro): 0.38536727801957593\n",
      "Test Categorical Accuracy: 0.6259720062208398\n",
      "Epoch 27/40\n",
      "19909/19909 [==============================] - 390s 20ms/step - loss: 0.7274 - categorical_accuracy: 0.7654\n",
      "Weighted AUCs: [0.9080106352133481]\n",
      "weighted average Recalls: 0.645800933125972\n",
      "unweighted average Recalls (macro): 0.388000854950148\n",
      "weighted average Precisions: 0.5929883736595625\n",
      "unweighted average Precisions(macro): 0.40251469537367096\n",
      "weighted average F1s: 0.6065329929020338\n",
      "unweighted average F1s(macro): 0.3833577676673939\n",
      "Test Categorical Accuracy: 0.645800933125972\n",
      "Epoch 28/40\n",
      "19909/19909 [==============================] - 391s 20ms/step - loss: 0.6899 - categorical_accuracy: 0.7743\n",
      "Weighted AUCs: [0.8956854528143322]\n",
      "weighted average Recalls: 0.6022550544323484\n",
      "unweighted average Recalls (macro): 0.31986680691904373\n",
      "weighted average Precisions: 0.5881542392544529\n",
      "unweighted average Precisions(macro): 0.42424534796864277\n",
      "weighted average F1s: 0.5731846563300431\n",
      "unweighted average F1s(macro): 0.3372131392121751\n",
      "Test Categorical Accuracy: 0.6022550544439356\n",
      "Epoch 29/40\n",
      "19909/19909 [==============================] - 391s 20ms/step - loss: 0.6629 - categorical_accuracy: 0.7846\n",
      "Weighted AUCs: [0.8959272679879122]\n",
      "weighted average Recalls: 0.6166407465007776\n",
      "unweighted average Recalls (macro): 0.3343665546417907\n",
      "weighted average Precisions: 0.5932561503528501\n",
      "unweighted average Precisions(macro): 0.4329299712609429\n",
      "weighted average F1s: 0.5704195415430042\n",
      "unweighted average F1s(macro): 0.34878445748183656\n",
      "Test Categorical Accuracy: 0.6166407465239521\n",
      "Epoch 30/40\n",
      "19909/19909 [==============================] - 391s 20ms/step - loss: 0.6302 - categorical_accuracy: 0.7938\n",
      "Weighted AUCs: [0.8976725718484289]\n",
      "weighted average Recalls: 0.6244167962674961\n",
      "unweighted average Recalls (macro): 0.39874378113874304\n",
      "weighted average Precisions: 0.5997953299349866\n",
      "unweighted average Precisions(macro): 0.40963097499178197\n",
      "weighted average F1s: 0.6034827456113097\n",
      "unweighted average F1s(macro): 0.38875282779115006\n",
      "Test Categorical Accuracy: 0.624416796313845\n",
      "Epoch 31/40\n",
      "19909/19909 [==============================] - 391s 20ms/step - loss: 0.5940 - categorical_accuracy: 0.8051\n",
      "Weighted AUCs: [0.9002492525164651]\n",
      "weighted average Recalls: 0.6399688958009331\n",
      "unweighted average Recalls (macro): 0.39350576134033943\n",
      "weighted average Precisions: 0.617408126773883\n",
      "unweighted average Precisions(macro): 0.4213398617257852\n",
      "weighted average F1s: 0.6159751594585905\n",
      "unweighted average F1s(macro): 0.3891316209666872\n",
      "Test Categorical Accuracy: 0.6399688958125204\n",
      "Epoch 32/40\n",
      "19909/19909 [==============================] - 391s 20ms/step - loss: 0.5623 - categorical_accuracy: 0.8147\n",
      "Weighted AUCs: [0.9008966252259052]\n",
      "weighted average Recalls: 0.6372472783825817\n",
      "unweighted average Recalls (macro): 0.43160567675752004\n",
      "weighted average Precisions: 0.610311426141635\n",
      "unweighted average Precisions(macro): 0.43941164434543034\n",
      "weighted average F1s: 0.6161797698670745\n",
      "unweighted average F1s(macro): 0.42265597177818603\n",
      "Test Categorical Accuracy: 0.6372472784057561\n",
      "Epoch 33/40\n",
      "19909/19909 [==============================] - 392s 20ms/step - loss: 0.5278 - categorical_accuracy: 0.8255\n",
      "Weighted AUCs: [0.9000670685916471]\n",
      "weighted average Recalls: 0.6209175738724728\n",
      "unweighted average Recalls (macro): 0.3548743764444517\n",
      "weighted average Precisions: 0.5827395000935495\n",
      "unweighted average Precisions(macro): 0.39680123127925304\n",
      "weighted average F1s: 0.5823550993234674\n",
      "unweighted average F1s(macro): 0.3529710077459902\n",
      "Test Categorical Accuracy: 0.6209175738956472\n",
      "Epoch 34/40\n",
      "19909/19909 [==============================] - 393s 20ms/step - loss: 0.5013 - categorical_accuracy: 0.8345\n",
      "Weighted AUCs: [0.8928285849146763]\n",
      "weighted average Recalls: 0.5964230171073095\n",
      "unweighted average Recalls (macro): 0.3578846542411678\n",
      "weighted average Precisions: 0.6028305422844771\n",
      "unweighted average Precisions(macro): 0.42153182338094886\n",
      "weighted average F1s: 0.577020339450661\n",
      "unweighted average F1s(macro): 0.3720572625620403\n",
      "Test Categorical Accuracy: 0.5964230171188967\n",
      "Epoch 35/40\n",
      "19909/19909 [==============================] - 392s 20ms/step - loss: 0.4540 - categorical_accuracy: 0.8497\n",
      "Weighted AUCs: [0.8970058226292613]\n",
      "weighted average Recalls: 0.6283048211508554\n",
      "unweighted average Recalls (macro): 0.3923106813526015\n",
      "weighted average Precisions: 0.6143002432843455\n",
      "unweighted average Precisions(macro): 0.42923153247512424\n",
      "weighted average F1s: 0.6097437529801205\n",
      "unweighted average F1s(macro): 0.39136995304944566\n",
      "Test Categorical Accuracy: 0.6283048211508554\n",
      "Epoch 36/40\n",
      "19909/19909 [==============================] - 391s 20ms/step - loss: 0.4268 - categorical_accuracy: 0.8568\n",
      "Weighted AUCs: [0.8892287802176747]\n",
      "weighted average Recalls: 0.6104199066874028\n",
      "unweighted average Recalls (macro): 0.3759726852222371\n",
      "weighted average Precisions: 0.607458642716119\n",
      "unweighted average Precisions(macro): 0.40419295748879397\n",
      "weighted average F1s: 0.5997514648180219\n",
      "unweighted average F1s(macro): 0.3792473998230969\n",
      "Test Categorical Accuracy: 0.61041990669899\n",
      "Epoch 37/40\n",
      "19909/19909 [==============================] - 391s 20ms/step - loss: 0.3855 - categorical_accuracy: 0.8715\n",
      "Weighted AUCs: [0.8923482504069359]\n",
      "weighted average Recalls: 0.6158631415241057\n",
      "unweighted average Recalls (macro): 0.403562877914661\n",
      "weighted average Precisions: 0.6111489619389765\n",
      "unweighted average Precisions(macro): 0.43582665082239525\n",
      "weighted average F1s: 0.606226904614607\n",
      "unweighted average F1s(macro): 0.40696844703070517\n",
      "Test Categorical Accuracy: 0.6158631415241057\n",
      "Epoch 38/40\n",
      "19909/19909 [==============================] - 391s 20ms/step - loss: 0.3617 - categorical_accuracy: 0.8789\n",
      "Weighted AUCs: [0.8924854168421552]\n",
      "weighted average Recalls: 0.6150855365474339\n",
      "unweighted average Recalls (macro): 0.3938618054039154\n",
      "weighted average Precisions: 0.6160083701181399\n",
      "unweighted average Precisions(macro): 0.44739693627997557\n",
      "weighted average F1s: 0.6054718893262512\n",
      "unweighted average F1s(macro): 0.3911469265746739\n",
      "Test Categorical Accuracy: 0.6150855365706084\n",
      "Epoch 39/40\n",
      "19909/19909 [==============================] - 392s 20ms/step - loss: 0.3312 - categorical_accuracy: 0.8877\n",
      "Weighted AUCs: [0.8959580428936166]\n",
      "weighted average Recalls: 0.6170295489891136\n",
      "unweighted average Recalls (macro): 0.3629415604211835\n",
      "weighted average Precisions: 0.6022734489175847\n",
      "unweighted average Precisions(macro): 0.41617922150304437\n",
      "weighted average F1s: 0.5992904177535509\n",
      "unweighted average F1s(macro): 0.36524480394436043\n",
      "Test Categorical Accuracy: 0.617029549012288\n",
      "Epoch 40/40\n",
      "19909/19909 [==============================] - 390s 20ms/step - loss: 0.3022 - categorical_accuracy: 0.8981\n",
      "Weighted AUCs: [0.8924378873759411]\n",
      "weighted average Recalls: 0.6189735614307932\n",
      "unweighted average Recalls (macro): 0.4353983464016456\n",
      "weighted average Precisions: 0.5943168361474026\n",
      "unweighted average Precisions(macro): 0.40077977603042486\n",
      "weighted average F1s: 0.597578382224435\n",
      "unweighted average F1s(macro): 0.4061905986535777\n",
      "Test Categorical Accuracy: 0.6189735614307932\n",
      "AUC_max: 0.9107291631278178 Recall_weighted_max: 0.645800933125972 Recall_macro_max: 0.4353983464016456 Precision_weighted_max: 0.6367109663620789 Precision_macro_max: 0.44739693627997557 F1_score_weighted_max: 0.6163230857434073 F1_score_macro_max: 0.42265597177818603 ACC_max: 0.645800933125972\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output  (FMA)\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 40\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape,name='main_input')\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same',name='conv_1')(input_melS)\n",
    "bn1 = BatchNormalization(name='bn_1')(conv1)\n",
    "act1 = Activation('elu',name='act_1')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same',name='pool_1')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same',name='conv_2')(pool1)\n",
    "bn2 = BatchNormalization(name='bn_2')(conv2)\n",
    "act2 = Activation('elu',name='act_2')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same',name='pool_2')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same',name='conv_3')(pool2)\n",
    "bn3 = BatchNormalization(name='bn_3')(conv3)\n",
    "act3 = Activation('elu',name='act_3')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same',name='pool_3')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same',name='conv_4')(pool3)\n",
    "bn4 = BatchNormalization(name='bn_4')(conv4)\n",
    "act4 = Activation('elu',name='act_4')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same',name='pool_4')(act4)\n",
    "\n",
    "gru1_in = Reshape((6, 128*6),name='gru1_in')(pool4)\n",
    "gru1 = GRU(32,name='gru1')(gru1_in)\n",
    "\n",
    "gru2_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)},name='gru2_in_perm')(pool4)\n",
    "gru2_in = Reshape((6, 128*6),name='gru2_in')(gru2_in_perm)\n",
    "gru2 = GRU(32,name='gru2')(gru2_in)\n",
    "\n",
    "gru3_in_perm = Lambda(K.reverse,arguments={'axes':2},name='gru3_in_perm')(pool4)\n",
    "gru3_in = Reshape((6, 128*6),name='gru3_in')(gru3_in_perm)\n",
    "gru3 = GRU(32,name='gru3')(gru3_in)\n",
    "\n",
    "gru4_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)},name='gru4_in_perm')(gru3_in_perm)\n",
    "gru4_in = Reshape((6, 128*6),name='gru4_in')(gru4_in_perm)\n",
    "gru4 = GRU(32,name='gru4')(gru4_in)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1},name='gru5_in_perm')(pool4)\n",
    "gru5_in = Reshape((6, 128*6),name='gru5_in')(gru5_in_perm)\n",
    "gru5 = GRU(32,name='gru5')(gru5_in)\n",
    "\n",
    "gru6_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)},name='gru6_in_perm')(gru5_in_perm)\n",
    "gru6_in = Reshape((6, 128*6),name='gru6_in')(gru6_in_perm)\n",
    "gru6 = GRU(32,name='gru6')(gru6_in)\n",
    "\n",
    "gru7_in_perm = Lambda(K.reverse,arguments={'axes':2},name='gru7_in_perm')(gru5_in_perm)\n",
    "gru7_in = Reshape((6, 128*6),name='gru7_in')(gru7_in_perm)\n",
    "gru7 = GRU(32,name='gru7')(gru7_in)\n",
    "\n",
    "gru8_in_perm = Lambda(K.reverse,arguments={'axes':1},name='gru8_in_perm')(gru6_in_perm)\n",
    "gru8_in = Reshape((6, 128*6),name='gru8_in')(gru8_in_perm)\n",
    "gru8 = GRU(32,name='gru8')(gru8_in)\n",
    "\n",
    "gru = Concatenate(name='gru_conc')([gru1,gru2,gru3,gru4,gru5,gru6,gru7,gru8])\n",
    "gru_dropout = Dropout(0.5,name='gru_conc_dropout')(gru)\n",
    "fc = Dense(64, activation='elu',name='fc')(gru_dropout)\n",
    "pred = Dense(16, activation='softmax',name='pred')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(),metrics=['categorical_accuracy'])\n",
    "\n",
    "filepath='C:/DT/model_save/fma/cGrnn/'+\"{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "\n",
    "path = 'C:/DT/fma_medium'\n",
    "x_train = np.load(path+'\\\\x_train.npy')\n",
    "y_train = np.load(path+'\\\\train_y.npy')\n",
    "y_train_idx = np.argmax(y_train,axis = -1)\n",
    "x_test = np.load(path+'\\\\x_test.npy')\n",
    "y_test = np.load(path+'\\\\test_y.npy')\n",
    "y_test_idx = np.argmax(y_test,axis = -1)\n",
    "\n",
    "AUC_max = 0\n",
    "Recall_weighted_max = 0\n",
    "Recall_macro_max = 0\n",
    "Precision_weighted_max = 0\n",
    "Precision_macro_max = 0\n",
    "F1_score_weighted_max = 0\n",
    "F1_score_macro_max = 0\n",
    "ACC_max = 0\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,recall_score,precision_score,f1_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # all evaluation metrics include train, val, test except accs\n",
    "        self.aucs = [] # weighted AUC\n",
    "        self.recalls = [] # 16 recalls on each class and 1 mean recall\n",
    "        self.precisions = [] # 16 precisions on each class and 1 mean precision\n",
    "        self.f1s = [] # 16 f1s on each class and 1 mean f1 \n",
    "        self.accs = [] # mean accuracy without take imblance into account\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global AUC_max, Recall_weighted_max, Recall_macro_max, Precision_weighted_max, Precision_macro_max, \\\n",
    "                F1_score_weighted_max, F1_score_macro_max, ACC_max\n",
    "        y_pred_test = self.model.predict(x_test)\n",
    "        y_pred_test_idx = np.argmax(y_pred_test,axis = -1)\n",
    "                \n",
    "        auc = [] \n",
    "        auc_test = roc_auc_score(y_test, y_pred_test,'weighted')\n",
    "        if auc_test > AUC_max:\n",
    "            AUC_max = auc_test\n",
    "        auc.append(auc_test)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"Weighted AUCs:\",auc)\n",
    "        \n",
    "        recall = []\n",
    "        recall_all = recall_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        recall.append(recall_all)\n",
    "        recall_mean = recall_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        if recall_mean > Recall_weighted_max:\n",
    "            Recall_weighted_max = recall_mean\n",
    "        recall.append(recall_mean)\n",
    "        recall_mean = recall_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        if recall_mean > Recall_macro_max:\n",
    "            Recall_macro_max = recall_mean\n",
    "        recall.append(recall_mean)\n",
    "        self.recalls.append(recall)\n",
    "        print(\"weighted average Recalls:\",recall[1])\n",
    "        print(\"unweighted average Recalls (macro):\",recall[2])\n",
    "        \n",
    "        precision = []\n",
    "        precision_all = precision_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        precision.append(precision_all)\n",
    "        precision_mean = precision_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        if precision_mean > Precision_weighted_max:\n",
    "            Precision_weighted_max = precision_mean\n",
    "        precision.append(precision_mean)\n",
    "        precision_mean = precision_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        if precision_mean > Precision_macro_max:\n",
    "            Precision_macro_max = precision_mean\n",
    "        precision.append(precision_mean)\n",
    "        self.precisions.append(precision)\n",
    "        print(\"weighted average Precisions:\",precision[1])\n",
    "        print(\"unweighted average Precisions(macro):\",precision[2])\n",
    "        \n",
    "        f1 = []\n",
    "        f1_all = f1_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        f1.append(f1_all)\n",
    "        f1_mean = f1_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        if f1_mean > F1_score_weighted_max:\n",
    "            F1_score_weighted_max = f1_mean\n",
    "        f1.append(f1_mean)\n",
    "        f1_mean = f1_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        if f1_mean > F1_score_macro_max:\n",
    "            F1_score_macro_max = f1_mean\n",
    "        f1.append(f1_mean)\n",
    "        self.f1s.append(f1)\n",
    "        print(\"weighted average F1s:\",f1[1])\n",
    "        print(\"unweighted average F1s(macro):\",f1[2])\n",
    "        \n",
    "        loss, acc = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "        if acc > ACC_max:\n",
    "            ACC_max = acc\n",
    "        self.accs.append(acc)\n",
    "        print(\"Test Categorical Accuracy:\",acc)\n",
    "                \n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, callbacks=[histories,checkpoint])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "pickle.dump(histories.aucs,open(os.path.join(path,'metrics_save/cGrnn_aucs_1.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls,open(os.path.join(path,'metrics_save/cGrnn_recalls_1.pkl'),'wb'))\n",
    "pickle.dump(histories.precisions,open(os.path.join(path,'metrics_save/cGrnn_precisions_1.pkl'),'wb'))\n",
    "pickle.dump(histories.f1s,open(os.path.join(path,'metrics_save/cGrnn_f1s_1.pkl'),'wb'))\n",
    "pickle.dump(histories.accs,open(os.path.join(path,'metrics_save/cGrnn_accs_1.pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(path,'metrics_save/cGrnn_history_1.pkl'),'wb'))\n",
    "print('AUC_max:',AUC_max,'Recall_weighted_max:',Recall_weighted_max,'Recall_macro_max:',Recall_macro_max,\n",
    "     'Precision_weighted_max:',Precision_weighted_max,'Precision_macro_max:',Precision_macro_max,\n",
    "     'F1_score_weighted_max:',F1_score_weighted_max,'F1_score_macro_max:',F1_score_macro_max,\n",
    "     'ACC_max:',ACC_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 96, 1360, 32)      2080      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 96, 1360, 32)      128       \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 96, 1360, 32)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 24, 340, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 24, 340, 32)       65568     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 24, 340, 32)       128       \n",
      "_________________________________________________________________\n",
      "act2 (Activation)            (None, 24, 340, 32)       0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 6, 85, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16320)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16320)             0         \n",
      "_________________________________________________________________\n",
      "ds1 (Dense)                  (None, 100)               1632100   \n",
      "_________________________________________________________________\n",
      "ds2 (Dense)                  (None, 16)                1616      \n",
      "=================================================================\n",
      "Total params: 1,701,620\n",
      "Trainable params: 1,701,492\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 19909 samples, validate on 2504 samples\n",
      "Epoch 1/30\n",
      "19909/19909 [==============================] - 187s 9ms/step - loss: 2.1558 - categorical_accuracy: 0.4158 - val_loss: 2.3620 - val_categorical_accuracy: 0.3435\n",
      "Weighted AUCs: [0.750118136766738, 0.7582265585792235, 0.7590186925882942]\n",
      "weighted average Recalls: 0.3216133407001858 0.34345047923322686 0.33864696734059097\n",
      "unweighted average Recalls: 0.17306135540781428 0.17306135540781428 0.17306135540781428\n",
      "weighted average Precisions: 0.297858703108639 0.2977385462453902 0.3175216644581137\n",
      "unweighted average Precisions: 0.15608434797245357 0.15608434797245357 0.15608434797245357\n",
      "weighted average F1s: 0.2694814184522952 0.2827433583210907 0.27835640234757664\n",
      "unweighted average F1s: 0.13489167748562403 0.13489167748562403 0.13489167748562403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Categorical Accuracy: 0.3386469672942421\n",
      "Epoch 2/30\n",
      "19909/19909 [==============================] - 184s 9ms/step - loss: 1.5120 - categorical_accuracy: 0.5239 - val_loss: 1.4699 - val_categorical_accuracy: 0.5551\n",
      "Weighted AUCs: [0.8609552668221925, 0.8686564279469003, 0.8591723372193198]\n",
      "weighted average Recalls: 0.5344818926113818 0.555111821086262 0.5279937791601866\n",
      "unweighted average Recalls: 0.23372758033253554 0.23372758033253554 0.23372758033253554\n",
      "weighted average Precisions: 0.46536337748911244 0.4702855769069621 0.44067124686681375\n",
      "unweighted average Precisions: 0.2655367255563348 0.2655367255563348 0.2655367255563348\n",
      "weighted average F1s: 0.462912109103022 0.4805066983318777 0.4462165282347083\n",
      "unweighted average F1s: 0.21244256659358784 0.21244256659358784 0.21244256659358784\n",
      "Test Categorical Accuracy: 0.5279937791833611\n",
      "Epoch 3/30\n",
      "19909/19909 [==============================] - 184s 9ms/step - loss: 1.3958 - categorical_accuracy: 0.5703 - val_loss: 1.3856 - val_categorical_accuracy: 0.5839\n",
      "Weighted AUCs: [0.8693193147108049, 0.8745130636754067, 0.8502123333614754]\n",
      "weighted average Recalls: 0.544226229343513 0.5838658146964856 0.5233281493001555\n",
      "unweighted average Recalls: 0.30257992043522675 0.30257992043522675 0.30257992043522675\n",
      "weighted average Precisions: 0.5340547134821318 0.5649389692134887 0.4992966532927966\n",
      "unweighted average Precisions: 0.2459654893928115 0.2459654893928115 0.2459654893928115\n",
      "weighted average F1s: 0.5089194785736811 0.5474160449475208 0.48631785237114517\n",
      "unweighted average F1s: 0.23631508281598534 0.23631508281598534 0.23631508281598534\n",
      "Test Categorical Accuracy: 0.5233281493001555\n",
      "Epoch 4/30\n",
      "19909/19909 [==============================] - 185s 9ms/step - loss: 1.3261 - categorical_accuracy: 0.5932 - val_loss: 1.4049 - val_categorical_accuracy: 0.5935\n",
      "Weighted AUCs: [0.8833886983197615, 0.8885626162948015, 0.8645649830982534]\n",
      "weighted average Recalls: 0.5766738660907127 0.5934504792332268 0.5486003110419907\n",
      "unweighted average Recalls: 0.2989253854152506 0.2989253854152506 0.2989253854152506\n",
      "weighted average Precisions: 0.5563669562229037 0.5907673323897045 0.49734075800910565\n",
      "unweighted average Precisions: 0.31677974833011546 0.31677974833011546 0.31677974833011546\n",
      "weighted average F1s: 0.5386994553868438 0.5480950194579715 0.5031129693941815\n",
      "unweighted average F1s: 0.2833556853669289 0.2833556853669289 0.2833556853669289\n",
      "Test Categorical Accuracy: 0.5486003110419907\n",
      "Epoch 5/30\n",
      "19909/19909 [==============================] - 185s 9ms/step - loss: 1.2759 - categorical_accuracy: 0.6079 - val_loss: 1.2950 - val_categorical_accuracy: 0.6022\n",
      "Weighted AUCs: [0.8951440063949387, 0.8894550937338614, 0.8684669504370854]\n",
      "weighted average Recalls: 0.6093224169973379 0.6022364217252396 0.567651632970451\n",
      "unweighted average Recalls: 0.3278512020001413 0.3278512020001413 0.3278512020001413\n",
      "weighted average Precisions: 0.5712941137562015 0.5695850348691689 0.5152401868324418\n",
      "unweighted average Precisions: 0.32338040103289745 0.32338040103289745 0.32338040103289745\n",
      "weighted average F1s: 0.5707575889688101 0.5593028542317803 0.5260797941964372\n",
      "unweighted average F1s: 0.3071323716604428 0.3071323716604428 0.3071323716604428\n",
      "Test Categorical Accuracy: 0.567651632970451\n",
      "Epoch 6/30\n",
      "19909/19909 [==============================] - 185s 9ms/step - loss: 1.2437 - categorical_accuracy: 0.6148 - val_loss: 1.2406 - val_categorical_accuracy: 0.6166\n",
      "Weighted AUCs: [0.9040140789241242, 0.8992193972393495, 0.8836904993252048]\n",
      "weighted average Recalls: 0.6131397860264202 0.6166134185303515 0.5808709175738724\n",
      "unweighted average Recalls: 0.3293028563993806 0.3293028563993806 0.3293028563993806\n",
      "weighted average Precisions: 0.5684503555469593 0.5536441135798786 0.5083839885786112\n",
      "unweighted average Precisions: 0.35853663928815116 0.35853663928815116 0.35853663928815116\n",
      "weighted average F1s: 0.5650846393639612 0.5657948853526154 0.5242314087213752\n",
      "unweighted average F1s: 0.3173107302185137 0.3173107302185137 0.3173107302185137\n",
      "Test Categorical Accuracy: 0.5808709175970469\n",
      "Epoch 7/30\n",
      "19909/19909 [==============================] - 184s 9ms/step - loss: 1.1964 - categorical_accuracy: 0.6307 - val_loss: 1.2240 - val_categorical_accuracy: 0.6374\n",
      "Weighted AUCs: [0.914258755892857, 0.9004978062571922, 0.8829905208464898]\n",
      "weighted average Recalls: 0.6450349088352002 0.6373801916932907 0.5909797822706065\n",
      "unweighted average Recalls: 0.37146871650821645 0.37146871650821645 0.37146871650821645\n",
      "weighted average Precisions: 0.5963268687490632 0.5881552447802558 0.527572227058237\n",
      "unweighted average Precisions: 0.35528569807695376 0.35528569807695376 0.35528569807695376\n",
      "weighted average F1s: 0.6047415763643625 0.5965557890099925 0.5397675323802844\n",
      "unweighted average F1s: 0.3403476897517349 0.3403476897517349 0.3403476897517349\n",
      "Test Categorical Accuracy: 0.5909797822821937\n",
      "Epoch 8/30\n",
      "19909/19909 [==============================] - 184s 9ms/step - loss: 1.1701 - categorical_accuracy: 0.6389 - val_loss: 1.2715 - val_categorical_accuracy: 0.6286\n",
      "Weighted AUCs: [0.9113198402152957, 0.8978202272568051, 0.8737427438247946]\n",
      "weighted average Recalls: 0.6247928072730926 0.6285942492012779 0.5824261275272161\n",
      "unweighted average Recalls: 0.34043055564406205 0.34043055564406205 0.34043055564406205\n",
      "weighted average Precisions: 0.598815170323195 0.5761895912375271 0.5299030397442087\n",
      "unweighted average Precisions: 0.38475699701151994 0.38475699701151994 0.38475699701151994\n",
      "weighted average F1s: 0.5904169967390989 0.5909795491552391 0.5369655602889117\n",
      "unweighted average F1s: 0.3272855922532074 0.3272855922532074 0.3272855922532074\n",
      "Test Categorical Accuracy: 0.5824261275388034\n",
      "Epoch 9/30\n",
      "19909/19909 [==============================] - 185s 9ms/step - loss: 1.1399 - categorical_accuracy: 0.6468 - val_loss: 1.2316 - val_categorical_accuracy: 0.6314\n",
      "Weighted AUCs: [0.920189110172561, 0.9061063486902733, 0.8881240268630948]\n",
      "weighted average Recalls: 0.6454367371540509 0.6313897763578274 0.588646967340591\n",
      "unweighted average Recalls: 0.3679743343136055 0.3679743343136055 0.3679743343136055\n",
      "weighted average Precisions: 0.6143335912397723 0.5870806757292776 0.5847401401666368\n",
      "unweighted average Precisions: 0.3995556565984431 0.3995556565984431 0.3995556565984431\n",
      "weighted average F1s: 0.6139478900081741 0.594218174581585 0.5459593846669064\n",
      "unweighted average F1s: 0.3711237109795056 0.3711237109795056 0.3711237109795056\n",
      "Test Categorical Accuracy: 0.5886469673521783\n",
      "Epoch 10/30\n",
      "19909/19909 [==============================] - 185s 9ms/step - loss: 1.1083 - categorical_accuracy: 0.6583 - val_loss: 1.1880 - val_categorical_accuracy: 0.6645\n",
      "Weighted AUCs: [0.9268475924721398, 0.903318956737257, 0.8880621084228817]\n",
      "weighted average Recalls: 0.6795921442563665 0.6645367412140575 0.609642301710731\n",
      "unweighted average Recalls: 0.41692425737040245 0.41692425737040245 0.41692425737040245\n",
      "weighted average Precisions: 0.6380355176088359 0.6078097472761198 0.6020733634752558\n",
      "unweighted average Precisions: 0.40019984123026386 0.40019984123026386 0.40019984123026386\n",
      "weighted average F1s: 0.6428123333213581 0.6278814040173875 0.56805623814695\n",
      "unweighted average F1s: 0.38742111165860926 0.38742111165860926 0.38742111165860926\n",
      "Test Categorical Accuracy: 0.6096423017339054\n",
      "Epoch 11/30\n",
      "19909/19909 [==============================] - 184s 9ms/step - loss: 1.0788 - categorical_accuracy: 0.6644 - val_loss: 1.3330 - val_categorical_accuracy: 0.6114\n",
      "Weighted AUCs: [0.9255901187805613, 0.8953259792183424, 0.8857219543101534]\n",
      "weighted average Recalls: 0.6475463358280175 0.6114217252396166 0.5847589424572317\n",
      "unweighted average Recalls: 0.3748568395695677 0.3748568395695677 0.3748568395695677\n",
      "weighted average Precisions: 0.6348694111274468 0.6218711539971352 0.5973063849795142\n",
      "unweighted average Precisions: 0.4061240948001017 0.4061240948001017 0.4061240948001017\n",
      "weighted average F1s: 0.6146627252422968 0.5754892457412093 0.542878413660079\n",
      "unweighted average F1s: 0.3626094573980022 0.3626094573980022 0.3626094573980022\n",
      "Test Categorical Accuracy: 0.5847589424572317\n",
      "Epoch 12/30\n",
      "19909/19909 [==============================] - 184s 9ms/step - loss: 1.0464 - categorical_accuracy: 0.6737 - val_loss: 1.3842 - val_categorical_accuracy: 0.6134\n",
      "Weighted AUCs: [0.9240074141008009, 0.8904347492144522, 0.8750306564785424]\n",
      "weighted average Recalls: 0.6480988497664373 0.6134185303514377 0.5723172628304821\n",
      "unweighted average Recalls: 0.40052939621752476 0.40052939621752476 0.40052939621752476\n",
      "weighted average Precisions: 0.6386966906694804 0.6088655925103043 0.5754306101719047\n",
      "unweighted average Precisions: 0.41137899734501043 0.41137899734501043 0.41137899734501043\n",
      "weighted average F1s: 0.6225372835439924 0.5854819207127594 0.5395737985809462\n",
      "unweighted average F1s: 0.38696104668497366 0.38696104668497366 0.38696104668497366\n",
      "Test Categorical Accuracy: 0.5723172628420693\n",
      "Epoch 13/30\n",
      "19909/19909 [==============================] - 184s 9ms/step - loss: 1.0221 - categorical_accuracy: 0.6827 - val_loss: 1.2920 - val_categorical_accuracy: 0.6310\n",
      "Weighted AUCs: [0.9306024117964454, 0.8961614063835778, 0.8789566662278213]\n",
      "weighted average Recalls: 0.671555577879351 0.6309904153354633 0.5855365474339036\n",
      "unweighted average Recalls: 0.39989526563076594 0.39989526563076594 0.39989526563076594\n",
      "weighted average Precisions: 0.6680955903837629 0.601381737017941 0.5657086807217717\n",
      "unweighted average Precisions: 0.46773410235415924 0.46773410235415924 0.46773410235415924\n",
      "weighted average F1s: 0.6452726357152154 0.6022398275954852 0.547415128550536\n",
      "unweighted average F1s: 0.4043702891266605 0.4043702891266605 0.4043702891266605\n",
      "Test Categorical Accuracy: 0.5855365474339036\n",
      "Epoch 14/30\n",
      "19909/19909 [==============================] - 186s 9ms/step - loss: 0.9925 - categorical_accuracy: 0.6924 - val_loss: 1.2418 - val_categorical_accuracy: 0.6378\n",
      "Weighted AUCs: [0.9423883866918411, 0.898344546943058, 0.8830862838286692]\n",
      "weighted average Recalls: 0.7034004721482746 0.637779552715655 0.6030326594090202\n",
      "unweighted average Recalls: 0.44739351258283044 0.44739351258283044 0.44739351258283044\n",
      "weighted average Precisions: 0.6934991706294912 0.6068468686143802 0.5598868883373223\n",
      "unweighted average Precisions: 0.47500976499139225 0.47500976499139225 0.47500976499139225\n",
      "weighted average F1s: 0.6807671262848158 0.6090853838775472 0.5687882018189144\n",
      "unweighted average F1s: 0.43091075474048757 0.43091075474048757 0.43091075474048757\n",
      "Test Categorical Accuracy: 0.6030326594090202\n",
      "Epoch 15/30\n",
      "19909/19909 [==============================] - 186s 9ms/step - loss: 0.9707 - categorical_accuracy: 0.6957 - val_loss: 1.1869 - val_categorical_accuracy: 0.6506\n",
      "Weighted AUCs: [0.9513578443310429, 0.9090986189121951, 0.8914951176831908]\n",
      "weighted average Recalls: 0.7259028580039179 0.6505591054313099 0.609642301710731\n",
      "unweighted average Recalls: 0.44871657383985436 0.44871657383985436 0.44871657383985436\n",
      "weighted average Precisions: 0.697508093920821 0.6106387366085153 0.5412730863411145\n",
      "unweighted average Precisions: 0.5182434671367765 0.5182434671367765 0.5182434671367765\n",
      "weighted average F1s: 0.6936411081259202 0.6121602552166311 0.5597874034042398\n",
      "unweighted average F1s: 0.4601343752003546 0.4601343752003546 0.4601343752003546\n",
      "Test Categorical Accuracy: 0.609642301710731\n",
      "Epoch 16/30\n",
      "19909/19909 [==============================] - 185s 9ms/step - loss: 0.9392 - categorical_accuracy: 0.7034 - val_loss: 1.2657 - val_categorical_accuracy: 0.6486\n",
      "Weighted AUCs: [0.9530216280184198, 0.9078618400002806, 0.8914674406462209]\n",
      "weighted average Recalls: 0.7284645135365915 0.6485623003194888 0.5999222395023328\n",
      "unweighted average Recalls: 0.4476550336892685 0.4476550336892685 0.4476550336892685\n",
      "weighted average Precisions: 0.7103140634818171 0.6048972710736122 0.5488942034441513\n",
      "unweighted average Precisions: 0.5634648155172064 0.5634648155172064 0.5634648155172064\n",
      "weighted average F1s: 0.6959577188041288 0.6094769739330153 0.5580230530454668\n",
      "unweighted average F1s: 0.4667720366679587 0.4667720366679587 0.4667720366679587\n",
      "Test Categorical Accuracy: 0.59992223951392\n",
      "Epoch 17/30\n",
      "19909/19909 [==============================] - 185s 9ms/step - loss: 0.9105 - categorical_accuracy: 0.7130 - val_loss: 1.3263 - val_categorical_accuracy: 0.6170\n",
      "Weighted AUCs: [0.943418118296693, 0.8984444192983183, 0.8744173489809683]\n",
      "weighted average Recalls: 0.6935054497965745 0.6170127795527156 0.5727060653188181\n",
      "unweighted average Recalls: 0.44674483325807113 0.44674483325807113 0.44674483325807113\n",
      "weighted average Precisions: 0.6851223949503392 0.57871915489355 0.5461066950195321\n",
      "unweighted average Precisions: 0.5265993387654773 0.5265993387654773 0.5265993387654773\n",
      "weighted average F1s: 0.669640832770615 0.5871782763198954 0.5475470970537414\n",
      "unweighted average F1s: 0.43918435769433734 0.43918435769433734 0.43918435769433734\n",
      "Test Categorical Accuracy: 0.5727060653304052\n",
      "Epoch 18/30\n",
      "19909/19909 [==============================] - 186s 9ms/step - loss: 0.8910 - categorical_accuracy: 0.7160 - val_loss: 1.3840 - val_categorical_accuracy: 0.5958\n",
      "Weighted AUCs: [0.947401560342589, 0.899151471249678, 0.8787683439188708]\n",
      "weighted average Recalls: 0.6692450650459592 0.5958466453674122 0.5563763608087092\n",
      "unweighted average Recalls: 0.4356911970219722 0.4356911970219722 0.4356911970219722\n",
      "weighted average Precisions: 0.6915084668847143 0.5528728739428637 0.5313815090083422\n",
      "unweighted average Precisions: 0.5708033836513186 0.5708033836513186 0.5708033836513186\n",
      "weighted average F1s: 0.6340787136865811 0.5494126269535677 0.5086954553834563\n",
      "unweighted average F1s: 0.4316011475550762 0.4316011475550762 0.4316011475550762\n",
      "Test Categorical Accuracy: 0.5563763607623603\n",
      "Epoch 19/30\n",
      "19909/19909 [==============================] - 187s 9ms/step - loss: 0.8633 - categorical_accuracy: 0.7243 - val_loss: 1.2383 - val_categorical_accuracy: 0.6342\n",
      "Weighted AUCs: [0.9620728848806206, 0.9009467707366594, 0.884519810302171]\n",
      "weighted average Recalls: 0.7503139283741022 0.634185303514377 0.6073094867807154\n",
      "unweighted average Recalls: 0.49086029955259336 0.49086029955259336 0.49086029955259336\n",
      "weighted average Precisions: 0.7329254313721459 0.5846719701779384 0.5461028876961584\n",
      "unweighted average Precisions: 0.5648035425255916 0.5648035425255916 0.5648035425255916\n",
      "weighted average F1s: 0.7213503689388662 0.5918861647829583 0.5619092919364399\n",
      "unweighted average F1s: 0.49945897004089945 0.49945897004089945 0.49945897004089945\n",
      "Test Categorical Accuracy: 0.6073094867807154\n",
      "Epoch 20/30\n",
      "19909/19909 [==============================] - 187s 9ms/step - loss: 0.8472 - categorical_accuracy: 0.7284 - val_loss: 1.2582 - val_categorical_accuracy: 0.6482\n",
      "Weighted AUCs: [0.9676607342953681, 0.9027140342435093, 0.8877671147715033]\n",
      "weighted average Recalls: 0.7731679140087397 0.6481629392971247 0.6073094867807154\n",
      "unweighted average Recalls: 0.5062823631093891 0.5062823631093891 0.5062823631093891\n",
      "weighted average Precisions: 0.7606818537326163 0.6070559300867191 0.5779076389977252\n",
      "unweighted average Precisions: 0.5859799433376518 0.5859799433376518 0.5859799433376518\n",
      "weighted average F1s: 0.7497112766970434 0.6155132174243632 0.5714642481150187\n",
      "unweighted average F1s: 0.5060147626262103 0.5060147626262103 0.5060147626262103\n",
      "Test Categorical Accuracy: 0.6073094867807154\n",
      "Epoch 21/30\n",
      "19909/19909 [==============================] - 185s 9ms/step - loss: 0.8130 - categorical_accuracy: 0.7383 - val_loss: 1.3883 - val_categorical_accuracy: 0.6366\n",
      "Weighted AUCs: [0.9649543309635129, 0.8965207126450151, 0.8815839667907445]\n",
      "weighted average Recalls: 0.753478326385052 0.6365814696485623 0.5929237947122862\n",
      "unweighted average Recalls: 0.5090324189759021 0.5090324189759021 0.5090324189759021\n",
      "weighted average Precisions: 0.7522488868062569 0.616410459291039 0.5622369523163301\n",
      "unweighted average Precisions: 0.5836899859665717 0.5836899859665717 0.5836899859665717\n",
      "weighted average F1s: 0.7375276294948826 0.6122546990299477 0.5654234934822377\n",
      "unweighted average F1s: 0.5175161685397909 0.5175161685397909 0.5175161685397909\n",
      "Test Categorical Accuracy: 0.5929237947238734\n",
      "Epoch 22/30\n",
      "19909/19909 [==============================] - 186s 9ms/step - loss: 0.7959 - categorical_accuracy: 0.7447 - val_loss: 1.4960 - val_categorical_accuracy: 0.6134\n",
      "Weighted AUCs: [0.964987814491166, 0.89406845153074, 0.8794070576092887]\n",
      "weighted average Recalls: 0.7486061580189863 0.6134185303514377 0.5820373250388803\n",
      "unweighted average Recalls: 0.4954288024738132 0.4954288024738132 0.4954288024738132\n",
      "weighted average Precisions: 0.7642167943636398 0.6064352221621304 0.5611744419927225\n",
      "unweighted average Precisions: 0.6343973009864522 0.6343973009864522 0.6343973009864522\n",
      "weighted average F1s: 0.7304648430579224 0.5885975651666209 0.5542068554488175\n",
      "unweighted average F1s: 0.5075249920650836 0.5075249920650836 0.5075249920650836\n",
      "Test Categorical Accuracy: 0.5820373250388803\n",
      "Epoch 23/30\n",
      "19909/19909 [==============================] - 188s 9ms/step - loss: 0.7818 - categorical_accuracy: 0.7481 - val_loss: 1.3597 - val_categorical_accuracy: 0.6314\n",
      "Weighted AUCs: [0.9703144281144721, 0.8961725665800853, 0.8815831201275569]\n",
      "weighted average Recalls: 0.7698528303782209 0.6313897763578274 0.5940902021772939\n",
      "unweighted average Recalls: 0.5345073536509413 0.5345073536509413 0.5345073536509413\n",
      "weighted average Precisions: 0.771887267302471 0.6216620657054401 0.5792099865593797\n",
      "unweighted average Precisions: 0.5828301336418236 0.5828301336418236 0.5828301336418236\n",
      "weighted average F1s: 0.758703528160593 0.615597994649626 0.5769589323696099\n",
      "unweighted average F1s: 0.5321067472299875 0.5321067472299875 0.5321067472299875\n",
      "Test Categorical Accuracy: 0.5940902021772939\n",
      "Epoch 24/30\n",
      "19909/19909 [==============================] - 189s 9ms/step - loss: 0.7498 - categorical_accuracy: 0.7574 - val_loss: 1.2942 - val_categorical_accuracy: 0.6410\n",
      "Weighted AUCs: [0.9756338192031525, 0.8990975586719404, 0.8859185531759798]\n",
      "weighted average Recalls: 0.8052639509769451 0.6409744408945687 0.6065318818040435\n",
      "unweighted average Recalls: 0.5833476638414085 0.5833476638414085 0.5833476638414085\n",
      "weighted average Precisions: 0.8019721394825567 0.6282501671675006 0.5800716726561761\n",
      "unweighted average Precisions: 0.6456468386467793 0.6456468386467793 0.6456468386467793\n",
      "weighted average F1s: 0.7966874181444911 0.626358073748128 0.5890060835457094\n",
      "unweighted average F1s: 0.5857576773000107 0.5857576773000107 0.5857576773000107\n",
      "Test Categorical Accuracy: 0.6065318818040435\n",
      "Epoch 25/30\n",
      "19909/19909 [==============================] - 189s 10ms/step - loss: 0.7357 - categorical_accuracy: 0.7591 - val_loss: 1.4595 - val_categorical_accuracy: 0.6314\n",
      "Weighted AUCs: [0.9746728752991481, 0.8935238212059278, 0.8683961799074732]\n",
      "weighted average Recalls: 0.7752272841428499 0.6313897763578274 0.5703732503888025\n",
      "unweighted average Recalls: 0.5605853229837232 0.5605853229837232 0.5605853229837232\n",
      "weighted average Precisions: 0.7899334892608469 0.6136895842804415 0.576715322983313\n",
      "unweighted average Precisions: 0.6104679626504718 0.6104679626504718 0.6104679626504718\n",
      "weighted average F1s: 0.763209407703822 0.6098152632761495 0.5553056509029091\n",
      "unweighted average F1s: 0.5437706044956737 0.5437706044956737 0.5437706044956737\n",
      "Test Categorical Accuracy: 0.5703732503424537\n",
      "Epoch 26/30\n",
      "19909/19909 [==============================] - 184s 9ms/step - loss: 0.7147 - categorical_accuracy: 0.7643 - val_loss: 1.3994 - val_categorical_accuracy: 0.6350\n",
      "Weighted AUCs: [0.9789024696271633, 0.8980260360510235, 0.8814351506152933]\n",
      "weighted average Recalls: 0.808880405846602 0.6349840255591054 0.5999222395023328\n",
      "unweighted average Recalls: 0.5339252940829123 0.5339252940829123 0.5339252940829123\n",
      "weighted average Precisions: 0.8059697550726962 0.5852040669806223 0.5489243667863201\n",
      "unweighted average Precisions: 0.7326704882972872 0.7326704882972872 0.7326704882972872\n",
      "weighted average F1s: 0.7905637199293923 0.5997151638567734 0.5592105868535953\n",
      "unweighted average F1s: 0.5736419602167468 0.5736419602167468 0.5736419602167468\n",
      "Test Categorical Accuracy: 0.59992223951392\n",
      "Epoch 27/30\n",
      "19909/19909 [==============================] - 184s 9ms/step - loss: 0.7054 - categorical_accuracy: 0.7664 - val_loss: 1.3721 - val_categorical_accuracy: 0.6302\n",
      "Weighted AUCs: [0.9791208450489889, 0.8900669533997326, 0.8769771649593238]\n",
      "weighted average Recalls: 0.806419207393641 0.6301916932907349 0.5859253499222395\n",
      "unweighted average Recalls: 0.5577581686795976 0.5577581686795976 0.5577581686795976\n",
      "weighted average Precisions: 0.8028255590237298 0.6064704642789649 0.558467845679804\n",
      "unweighted average Precisions: 0.6641491675568434 0.6641491675568434 0.6641491675568434\n",
      "weighted average F1s: 0.793701751112923 0.6085619516701699 0.5610005717805274\n",
      "unweighted average F1s: 0.5824295315608607 0.5824295315608607 0.5824295315608607\n",
      "Test Categorical Accuracy: 0.5859253499222395\n",
      "Epoch 28/30\n",
      "19909/19909 [==============================] - 184s 9ms/step - loss: 0.6869 - categorical_accuracy: 0.7722 - val_loss: 1.4330 - val_categorical_accuracy: 0.6430\n",
      "Weighted AUCs: [0.9848837538717782, 0.8964009516651861, 0.8823514270494487]\n",
      "weighted average Recalls: 0.844844040383746 0.6429712460063898 0.6034214618973561\n",
      "unweighted average Recalls: 0.5987363950727707 0.5987363950727707 0.5987363950727707\n",
      "weighted average Precisions: 0.839562772547209 0.5946842434554557 0.5577808046828263\n",
      "unweighted average Precisions: 0.7530132335920918 0.7530132335920918 0.7530132335920918\n",
      "weighted average F1s: 0.8320164760619138 0.6094002007185038 0.5696928959995584\n",
      "unweighted average F1s: 0.6318536755384616 0.6318536755384616 0.6318536755384616\n",
      "Test Categorical Accuracy: 0.6034214619089434\n",
      "Epoch 29/30\n",
      "19909/19909 [==============================] - 184s 9ms/step - loss: 0.6618 - categorical_accuracy: 0.7825 - val_loss: 1.4443 - val_categorical_accuracy: 0.6454\n",
      "Weighted AUCs: [0.986204566213047, 0.8928601654455266, 0.8764694659681223]\n",
      "weighted average Recalls: 0.8603144306595008 0.645367412140575 0.5960342146189735\n",
      "unweighted average Recalls: 0.6414102881258621 0.6414102881258621 0.6414102881258621\n",
      "weighted average Precisions: 0.854172714110364 0.6064789075269429 0.5696567814302863\n",
      "unweighted average Precisions: 0.7450243570837921 0.7450243570837921 0.7450243570837921\n",
      "weighted average F1s: 0.8515836412915034 0.6199075366309692 0.5722812783679685\n",
      "unweighted average F1s: 0.6683456810936281 0.6683456810936281 0.6683456810936281\n",
      "Test Categorical Accuracy: 0.5960342146305608\n",
      "Epoch 30/30\n",
      "19909/19909 [==============================] - 184s 9ms/step - loss: 0.6347 - categorical_accuracy: 0.7919 - val_loss: 1.4746 - val_categorical_accuracy: 0.6402\n",
      "Weighted AUCs: [0.9875580798206645, 0.899251076098082, 0.884880462188983]\n",
      "weighted average Recalls: 0.8601135165000754 0.6401757188498403 0.604587869362364\n",
      "unweighted average Recalls: 0.665811803056815 0.665811803056815 0.665811803056815\n",
      "weighted average Precisions: 0.8555441859417141 0.599411703401796 0.5543937787424466\n",
      "unweighted average Precisions: 0.7430803555078833 0.7430803555078833 0.7430803555078833\n",
      "weighted average F1s: 0.8522181657884726 0.6123663635056982 0.5713661939834198\n",
      "unweighted average F1s: 0.6917059093213263 0.6917059093213263 0.6917059093213263\n",
      "Test Categorical Accuracy: 0.6045878693739511\n"
     ]
    }
   ],
   "source": [
    "# #  2 CNNs + FC + output  (FMA)\n",
    "# import numpy as np \n",
    "# from keras.callbacks import Callback\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Flatten,Dense,Dropout\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# epochs = 30\n",
    "# input_shape = (96,1360,1)\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32,(8,8),padding='same',input_shape=input_shape))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D((4,4),padding='same'))\n",
    "\n",
    "# model.add(Conv2D(32,(8,8),padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D((4,4),padding='same'))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dense(16, activation='sigmoid'))\n",
    "\n",
    "# model.summary()\n",
    "# model.compile(loss = 'binary_crossentropy', optimizer = Adam(),metrics=['categorical_accuracy'])\n",
    "\n",
    "# filepath='C:/DT/model_save/fma/cnn/'+\"{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath,save_best_only = 'True',mode = 'min')\n",
    "\n",
    "# path = 'C:/DT/fma_medium'\n",
    "# x_train = np.load(path+'\\\\x_train.npy')\n",
    "# y_train = np.load(path+'\\\\train_y.npy')\n",
    "# x_val = np.load(path+'\\\\x_val.npy')\n",
    "# y_val = np.load(path+'\\\\val_y.npy')\n",
    "# x_test = np.load(path+'\\\\x_test.npy')\n",
    "# y_test = np.load(path+'\\\\test_y.npy')\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# class Histories(Callback):\n",
    "#     def on_train_begin(self, logs={}):\n",
    "#         self.aucs = []\n",
    "#         self.accs = []\n",
    "\n",
    "#     def on_train_end(self, logs={}):\n",
    "#         return\n",
    "\n",
    "#     def on_epoch_begin(self, epoch, logs={}):\n",
    "#         return\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         auc = []\n",
    "#         y_pred = self.model.predict(x_train)\n",
    "#         auc_train = roc_auc_score(y_train, y_pred)\n",
    "#         auc.append(auc_train)\n",
    "#         y_pred = self.model.predict(x_val)\n",
    "#         auc_val = roc_auc_score(y_val, y_pred)\n",
    "#         auc.append(auc_val)\n",
    "#         y_pred = self.model.predict(x_test)\n",
    "#         auc_test = roc_auc_score(y_test, y_pred)\n",
    "#         auc.append(auc_test)\n",
    "#         self.aucs.append(auc)\n",
    "#         print(\"AUCs:\",auc) \n",
    "        \n",
    "#         loss, acc = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "#         self.accs.append(acc)\n",
    "#         print(\"Test Acc:\",acc)\n",
    "        \n",
    "        \n",
    "#         return\n",
    "\n",
    "#     def on_batch_begin(self, batch, logs={}):\n",
    "#         return\n",
    "\n",
    "#     def on_batch_end(self, batch, logs={}):\n",
    "#         return\n",
    "\n",
    "# histories = Histories()\n",
    "# history = model.fit(x_train, y_train, epochs = epochs, validation_data=(x_val,y_val), callbacks=[histories,checkpoint])\n",
    "\n",
    "# import pickle\n",
    "# import os\n",
    "# pickle.dump(histories.accs,open(os.path.join(path,'cnn_accs_test.pkl'),'wb'))\n",
    "# pickle.dump(history.history,open(os.path.join(path,'cnn_accLoss_trainVal.pkl'),'wb'))\n",
    "\n",
    "\n",
    "#  2 CNNs + FC + output  (FMA)\n",
    "import numpy as np \n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Flatten,Dense,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 30\n",
    "input_shape = (96,1360,1)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(8,8),padding='same',input_shape=input_shape,name='conv1'))\n",
    "model.add(BatchNormalization(name='bn1'))\n",
    "model.add(Activation('relu',name='act1'))\n",
    "model.add(MaxPooling2D((4,4),padding='same',name='pool1'))\n",
    "\n",
    "model.add(Conv2D(32,(8,8),padding='same',name='conv2'))\n",
    "model.add(BatchNormalization(name='bn2'))\n",
    "model.add(Activation('relu',name='act2'))\n",
    "model.add(MaxPooling2D((4,4),padding='same',name='pool2'))\n",
    "\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dropout(0.5,name='dropout'))\n",
    "model.add(Dense(100, activation='relu',name='ds1'))\n",
    "model.add(Dense(16, activation='softmax',name='ds2'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(),metrics=['categorical_accuracy'])\n",
    "\n",
    "filepath='C:/DT/model_save/fma/cnn/'+\"{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "\n",
    "path = 'C:/DT/fma_medium'\n",
    "x_train = np.load(path+'\\\\x_train.npy')\n",
    "y_train = np.load(path+'\\\\train_y.npy')\n",
    "y_train_idx = np.argmax(y_train,axis = -1)\n",
    "x_val = np.load(path+'\\\\x_val.npy')\n",
    "y_val = np.load(path+'\\\\val_y.npy')\n",
    "y_val_idx = np.argmax(y_val,axis = -1)\n",
    "x_test = np.load(path+'\\\\x_test.npy')\n",
    "y_test = np.load(path+'\\\\test_y.npy')\n",
    "y_test_idx = np.argmax(y_test,axis = -1)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,recall_score,precision_score,f1_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # all evaluation metrics include train, val, test except accs\n",
    "        self.aucs = [] # weighted AUC\n",
    "        self.recalls = [] # 16 recalls on each class and 1 mean recall\n",
    "        self.precisions = [] # 16 precisions on each class and 1 mean precision\n",
    "        self.f1s = [] # 16 f1s on each class and 1 mean f1 \n",
    "        self.accs = [] # mean accuracy without take imblance into account\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred_train = self.model.predict(x_train)\n",
    "        y_pred_val = self.model.predict(x_val)\n",
    "        y_pred_test = self.model.predict(x_test)\n",
    "        \n",
    "        y_pred_train_idx = np.argmax(y_pred_train,axis = -1)\n",
    "        y_pred_val_idx = np.argmax(y_pred_val,axis = -1)\n",
    "        y_pred_test_idx = np.argmax(y_pred_test,axis = -1)\n",
    "                \n",
    "        auc = [] #[train,val,test]\n",
    "        auc_train = roc_auc_score(y_train, y_pred_train,'weighted')\n",
    "        auc.append(auc_train)\n",
    "        auc_val = roc_auc_score(y_val, y_pred_val,'weighted')\n",
    "        auc.append(auc_val)\n",
    "        auc_test = roc_auc_score(y_test, y_pred_test,'weighted')\n",
    "        auc.append(auc_test)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"Weighted AUCs:\",auc)\n",
    "        \n",
    "        recall = []\n",
    "        recall_all = recall_score(y_train_idx,y_pred_train_idx,average=None)\n",
    "        recall.append(recall_all)\n",
    "        recall_mean = recall_score(y_train_idx,y_pred_train_idx,average='weighted')\n",
    "        recall.append(recall_mean)\n",
    "        recall_mean = recall_score(y_train_idx,y_pred_train_idx,average='macro')\n",
    "        recall.append(recall_mean)\n",
    "        recall_all = recall_score(y_val_idx,y_pred_val_idx,average=None)\n",
    "        recall.append(recall_all)\n",
    "        recall_mean = recall_score(y_val_idx,y_pred_val_idx,average='weighted')\n",
    "        recall.append(recall_mean)\n",
    "        recall_mean = recall_score(y_val_idx,y_pred_val_idx,average='macro')\n",
    "        recall.append(recall_mean)\n",
    "        recall_all = recall_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        recall.append(recall_all)\n",
    "        recall_mean = recall_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        recall.append(recall_mean)\n",
    "        recall_mean = recall_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        recall.append(recall_mean)\n",
    "        self.recalls.append(recall)\n",
    "        print(\"weighted average Recalls:\",recall[1],recall[4],recall[7])\n",
    "        print(\"unweighted average Recalls (macro):\",recall[2],recall[5],recall[8])\n",
    "        \n",
    "        precision = []\n",
    "        precision_all = precision_score(y_train_idx,y_pred_train_idx,average=None)\n",
    "        precision.append(precision_all)\n",
    "        precision_mean = precision_score(y_train_idx,y_pred_train_idx,average='weighted')\n",
    "        precision.append(precision_mean)\n",
    "        precision_mean = precision_score(y_train_idx,y_pred_train_idx,average='macro')\n",
    "        precision.append(precision_mean)\n",
    "        precision_all = precision_score(y_val_idx,y_pred_val_idx,average=None)\n",
    "        precision.append(precision_all)\n",
    "        precision_mean = precision_score(y_val_idx,y_pred_val_idx,average='weighted')\n",
    "        precision.append(precision_mean)\n",
    "        precision_mean = precision_score(y_val_idx,y_pred_val_idx,average='macro')\n",
    "        precision.append(precision_mean)\n",
    "        precision_all = precision_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        precision.append(precision_all)\n",
    "        precision_mean = precision_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        precision.append(precision_mean)\n",
    "        precision_mean = precision_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        precision.append(precision_mean)\n",
    "        self.precisions.append(precision)\n",
    "        print(\"weighted average Precisions:\",precision[1],precision[4],precision[7])\n",
    "        print(\"unweighted average Precisions(macro):\",precision[2],precision[5],precision[8])\n",
    "        \n",
    "        f1 = []\n",
    "        f1_all = f1_score(y_train_idx,y_pred_train_idx,average=None)\n",
    "        f1.append(f1_all)\n",
    "        f1_mean = f1_score(y_train_idx,y_pred_train_idx,average='weighted')\n",
    "        f1.append(f1_mean)\n",
    "        f1_mean = f1_score(y_train_idx,y_pred_train_idx,average='macro')\n",
    "        f1.append(f1_mean)\n",
    "        f1_all = f1_score(y_val_idx,y_pred_val_idx,average=None)\n",
    "        f1.append(f1_all)\n",
    "        f1_mean = f1_score(y_val_idx,y_pred_val_idx,average='weighted')\n",
    "        f1.append(f1_mean)\n",
    "        f1_mean = f1_score(y_val_idx,y_pred_val_idx,average='macro')\n",
    "        f1.append(f1_mean)\n",
    "        f1_all = f1_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        f1.append(f1_all)\n",
    "        f1_mean = f1_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        f1.append(f1_mean)\n",
    "        f1_mean = f1_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        f1.append(f1_mean)\n",
    "        self.f1s.append(f1)\n",
    "        print(\"weighted average F1s:\",f1[1],f1[4],f1[7])\n",
    "        print(\"unweighted average F1s(macro):\",f1[2],f1[5],f1[8])\n",
    "        \n",
    "        loss, acc = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "        self.accs.append(acc)\n",
    "        print(\"Test Categorical Accuracy:\",acc)\n",
    "                \n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, validation_data=(x_val,y_val), callbacks=[histories,checkpoint])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "pickle.dump(histories.aucs,open(os.path.join(path,'metrics_save/cnn_aucs.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls,open(os.path.join(path,'metrics_save/cnn_recalls.pkl'),'wb'))\n",
    "pickle.dump(histories.precisions,open(os.path.join(path,'metrics_save/cnn_precisions.pkl'),'wb'))\n",
    "pickle.dump(histories.f1s,open(os.path.join(path,'metrics_save/cnn_f1s.pkl'),'wb'))\n",
    "pickle.dump(histories.accs,open(os.path.join(path,'metrics_save/cnn_accs.pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(path,'metrics_save/cnn_history.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 96, 1360, 64)      640       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 96, 1360, 64)      256       \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 96, 1360, 64)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 48, 680, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 48, 680, 128)      73856     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 48, 680, 128)      512       \n",
      "_________________________________________________________________\n",
      "act2 (Activation)            (None, 48, 680, 128)      0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 16, 227, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 16, 227, 128)      147584    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 16, 227, 128)      512       \n",
      "_________________________________________________________________\n",
      "act3 (Activation)            (None, 16, 227, 128)      0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 4, 57, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 4, 57, 128)        147584    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 4, 57, 128)        512       \n",
      "_________________________________________________________________\n",
      "act4 (Activation)            (None, 4, 57, 128)        0         \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 1, 15, 128)        0         \n",
      "_________________________________________________________________\n",
      "rs (Reshape)                 (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru1 (GRU)                   (None, 15, 32)            15456     \n",
      "_________________________________________________________________\n",
      "gru2 (GRU)                   (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "ds (Dense)                   (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 393,680\n",
      "Trainable params: 392,784\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 19909 samples, validate on 2504 samples\n",
      "Epoch 1/30\n",
      "19909/19909 [==============================] - 472s 24ms/step - loss: 1.5502 - categorical_accuracy: 0.5343 - val_loss: 1.3274 - val_categorical_accuracy: 0.5974\n",
      "Weighted AUCs: [0.8854564044026086, 0.893474397196616, 0.8783797895715504]\n",
      "weighted average Recalls: 0.5895323722939374 0.597444089456869 0.5664852255054432\n",
      "unweighted average Recalls (macro): 0.30023441895385833 0.30023441895385833 0.30023441895385833\n",
      "weighted average Precisions: 0.5516249151344307 0.5377959890735173 0.5119049446096001\n",
      "unweighted average Precisions(macro): 0.31156411451036703 0.31156411451036703 0.31156411451036703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted average F1s: 0.5453544806774784 0.5438579120280509 0.5175797745370245\n",
      "unweighted average F1s(macro): 0.2852599383683506 0.2852599383683506 0.2852599383683506\n",
      "Test Categorical Accuracy: 0.5664852255170304\n",
      "Epoch 2/30\n",
      "19909/19909 [==============================] - 459s 23ms/step - loss: 1.2910 - categorical_accuracy: 0.6122 - val_loss: 1.3111 - val_categorical_accuracy: 0.5954\n",
      "Weighted AUCs: [0.9037243006918845, 0.9028138121005853, 0.8970642171902545]\n",
      "weighted average Recalls: 0.5981214526093727 0.5954472843450479 0.578538102643857\n",
      "unweighted average Recalls (macro): 0.27112109502531767 0.27112109502531767 0.27112109502531767\n",
      "weighted average Precisions: 0.6036399837632257 0.5838515942732995 0.5489423524421031\n",
      "unweighted average Precisions(macro): 0.37753490201979434 0.37753490201979434 0.37753490201979434\n",
      "weighted average F1s: 0.5508942979952743 0.5401261681328033 0.5197114398613617\n",
      "unweighted average F1s(macro): 0.2804164398964806 0.2804164398964806 0.2804164398964806\n",
      "Test Categorical Accuracy: 0.578538102643857\n",
      "Epoch 3/30\n",
      "19909/19909 [==============================] - 459s 23ms/step - loss: 1.2081 - categorical_accuracy: 0.6372 - val_loss: 1.3102 - val_categorical_accuracy: 0.5938\n",
      "Weighted AUCs: [0.907086106837082, 0.8971540291058673, 0.8908630334718931]\n",
      "weighted average Recalls: 0.603395449294289 0.5938498402555911 0.55248833592535\n",
      "unweighted average Recalls (macro): 0.32842742386094015 0.32842742386094015 0.32842742386094015\n",
      "weighted average Precisions: 0.5908451027869389 0.5638730651363075 0.5291228728204473\n",
      "unweighted average Precisions(macro): 0.3959457136134644 0.3959457136134644 0.3959457136134644\n",
      "weighted average F1s: 0.5662522343425658 0.5526981435480962 0.5126636765335859\n",
      "unweighted average F1s(macro): 0.32641770029609873 0.32641770029609873 0.32641770029609873\n",
      "Test Categorical Accuracy: 0.552488335879001\n",
      "Epoch 4/30\n",
      "19909/19909 [==============================] - 459s 23ms/step - loss: 1.1521 - categorical_accuracy: 0.6545 - val_loss: 1.1565 - val_categorical_accuracy: 0.6526\n",
      "Weighted AUCs: [0.9220573484637566, 0.9178333972986463, 0.9075059696937217]\n",
      "weighted average Recalls: 0.6467426791903159 0.652555910543131 0.6119751166407466\n",
      "unweighted average Recalls (macro): 0.3225198202082955 0.3225198202082955 0.3225198202082955\n",
      "weighted average Precisions: 0.6443616375171124 0.6026506041866677 0.5743054628325762\n",
      "unweighted average Precisions(macro): 0.4754433288542062 0.4754433288542062 0.4754433288542062\n",
      "weighted average F1s: 0.604591089861305 0.6059377105693008 0.5502964504440665\n",
      "unweighted average F1s(macro): 0.32408571006641573 0.32408571006641573 0.32408571006641573\n",
      "Test Categorical Accuracy: 0.6119751166523337\n",
      "Epoch 5/30\n",
      "19909/19909 [==============================] - 460s 23ms/step - loss: 1.1195 - categorical_accuracy: 0.6618 - val_loss: 1.1991 - val_categorical_accuracy: 0.6418\n",
      "Weighted AUCs: [0.9150899615802283, 0.9171569839738931, 0.9005820911465796]\n",
      "weighted average Recalls: 0.6291124617007383 0.6417731629392971 0.5991446345256609\n",
      "unweighted average Recalls (macro): 0.33710144473806436 0.33710144473806436 0.33710144473806436\n",
      "weighted average Precisions: 0.6202011043963916 0.6053713167409551 0.5489252298801058\n",
      "unweighted average Precisions(macro): 0.398441116180982 0.398441116180982 0.398441116180982\n",
      "weighted average F1s: 0.5818125361150398 0.5899781958844525 0.5374390198680619\n",
      "unweighted average F1s(macro): 0.3225106276427575 0.3225106276427575 0.3225106276427575\n",
      "Test Categorical Accuracy: 0.5991446345256609\n",
      "Epoch 6/30\n",
      "19909/19909 [==============================] - 461s 23ms/step - loss: 1.0818 - categorical_accuracy: 0.6753 - val_loss: 1.5151 - val_categorical_accuracy: 0.5288\n",
      "Weighted AUCs: [0.8914969783105116, 0.8902831267536792, 0.8769924904855081]\n",
      "weighted average Recalls: 0.5282535536691948 0.5287539936102237 0.49300155520995337\n",
      "unweighted average Recalls (macro): 0.31014061487573996 0.31014061487573996 0.31014061487573996\n",
      "weighted average Precisions: 0.6060262838109056 0.5826966416590826 0.5498934129069448\n",
      "unweighted average Precisions(macro): 0.3854753653806638 0.3854753653806638 0.3854753653806638\n",
      "weighted average F1s: 0.5089277087034358 0.5049302057850187 0.46361937629805783\n",
      "unweighted average F1s(macro): 0.30393264906828044 0.30393264906828044 0.30393264906828044\n",
      "Test Categorical Accuracy: 0.4930015553026511\n",
      "Epoch 7/30\n",
      "19909/19909 [==============================] - 460s 23ms/step - loss: 1.0548 - categorical_accuracy: 0.6821 - val_loss: 1.1496 - val_categorical_accuracy: 0.6470\n",
      "Weighted AUCs: [0.9333008998542816, 0.9177022555718952, 0.9053643738310037]\n",
      "weighted average Recalls: 0.6705007785423678 0.646964856230032 0.6049766718506998\n",
      "unweighted average Recalls (macro): 0.4075418819566975 0.4075418819566975 0.4075418819566975\n",
      "weighted average Precisions: 0.655315393393301 0.5997566139428677 0.5680815974171123\n",
      "unweighted average Precisions(macro): 0.42974244925492794 0.42974244925492794 0.42974244925492794\n",
      "weighted average F1s: 0.643399779528986 0.6140684012323567 0.5674923680515709\n",
      "unweighted average F1s(macro): 0.39490916338010473 0.39490916338010473 0.39490916338010473\n",
      "Test Categorical Accuracy: 0.6049766718506998\n",
      "Epoch 8/30\n",
      "19909/19909 [==============================] - 461s 23ms/step - loss: 1.0261 - categorical_accuracy: 0.6887 - val_loss: 1.1434 - val_categorical_accuracy: 0.6406\n",
      "Weighted AUCs: [0.9298067477569723, 0.9225660767528087, 0.9015672634055296]\n",
      "weighted average Recalls: 0.6601536993319604 0.6405750798722045 0.593701399688958\n",
      "unweighted average Recalls (macro): 0.35209225013620093 0.35209225013620093 0.35209225013620093\n",
      "weighted average Precisions: 0.6474377505455043 0.5767840510453905 0.5825318918823578\n",
      "unweighted average Precisions(macro): 0.47032912287902684 0.47032912287902684 0.47032912287902684\n",
      "weighted average F1s: 0.6154848700900458 0.5836102261857653 0.524576954843005\n",
      "unweighted average F1s(macro): 0.3639382910810082 0.3639382910810082 0.3639382910810082\n",
      "Test Categorical Accuracy: 0.593701399688958\n",
      "Epoch 9/30\n",
      "19909/19909 [==============================] - 461s 23ms/step - loss: 1.0073 - categorical_accuracy: 0.6934 - val_loss: 1.2418 - val_categorical_accuracy: 0.6242\n",
      "Weighted AUCs: [0.9262563720171612, 0.9163382946931911, 0.8957238138233048]\n",
      "weighted average Recalls: 0.6272037771861972 0.6242012779552716 0.5867029548989113\n",
      "unweighted average Recalls (macro): 0.387103237636503 0.387103237636503 0.387103237636503\n",
      "weighted average Precisions: 0.6591555610758754 0.6394510112055631 0.6044085422257038\n",
      "unweighted average Precisions(macro): 0.3916056715269679 0.3916056715269679 0.3916056715269679\n",
      "weighted average F1s: 0.6161874426837258 0.6116394471021726 0.5719013964061864\n",
      "unweighted average F1s(macro): 0.36319128951936486 0.36319128951936486 0.36319128951936486\n",
      "Test Categorical Accuracy: 0.5867029549104986\n",
      "Epoch 10/30\n",
      "19909/19909 [==============================] - 461s 23ms/step - loss: 0.9774 - categorical_accuracy: 0.7040 - val_loss: 1.2431 - val_categorical_accuracy: 0.6298\n",
      "Weighted AUCs: [0.9324339776967318, 0.9076775072755908, 0.9028047949831283]\n",
      "weighted average Recalls: 0.6661308955748656 0.6297923322683706 0.6018662519440124\n",
      "unweighted average Recalls (macro): 0.41814551642532116 0.41814551642532116 0.41814551642532116\n",
      "weighted average Precisions: 0.6834442054910492 0.6572200846916288 0.6212713294433293\n",
      "unweighted average Precisions(macro): 0.4307707292188807 0.4307707292188807 0.4307707292188807\n",
      "weighted average F1s: 0.6591512617993454 0.622170968685982 0.5972618249454617\n",
      "unweighted average F1s(macro): 0.4025938761962245 0.4025938761962245 0.4025938761962245\n",
      "Test Categorical Accuracy: 0.6018662519440124\n",
      "Epoch 11/30\n",
      "19909/19909 [==============================] - 463s 23ms/step - loss: 0.9565 - categorical_accuracy: 0.7104 - val_loss: 1.2015 - val_categorical_accuracy: 0.6410\n",
      "Weighted AUCs: [0.9367382331943495, 0.9141103805684601, 0.9026964472014852]\n",
      "weighted average Recalls: 0.6840122557637249 0.6409744408945687 0.6034214618973561\n",
      "unweighted average Recalls (macro): 0.43321214194882113 0.43321214194882113 0.43321214194882113\n",
      "weighted average Precisions: 0.6893843285688833 0.6401698517036999 0.5958400546662547\n",
      "unweighted average Precisions(macro): 0.48084261601306955 0.48084261601306955 0.48084261601306955\n",
      "weighted average F1s: 0.6718379441430982 0.619526491345295 0.5860369731101135\n",
      "unweighted average F1s(macro): 0.42605801493429335 0.42605801493429335 0.42605801493429335\n",
      "Test Categorical Accuracy: 0.6034214619089434\n",
      "Epoch 12/30\n",
      "19909/19909 [==============================] - 462s 23ms/step - loss: 0.9234 - categorical_accuracy: 0.7194 - val_loss: 1.3126 - val_categorical_accuracy: 0.5831\n",
      "Weighted AUCs: [0.9317154301205803, 0.907953356183734, 0.8926236060614491]\n",
      "weighted average Recalls: 0.6379024561755989 0.5830670926517572 0.5699844479004665\n",
      "unweighted average Recalls (macro): 0.4221107779749295 0.4221107779749295 0.4221107779749295\n",
      "weighted average Precisions: 0.7049781382318994 0.6456855906849813 0.6220613776330751\n",
      "unweighted average Precisions(macro): 0.4602207782279569 0.4602207782279569 0.4602207782279569\n",
      "weighted average F1s: 0.6464752600450041 0.5931015903073587 0.5752299338570568\n",
      "unweighted average F1s(macro): 0.4031166931399328 0.4031166931399328 0.4031166931399328\n",
      "Test Categorical Accuracy: 0.5699844479004665\n",
      "Epoch 13/30\n",
      "19909/19909 [==============================] - 464s 23ms/step - loss: 0.8963 - categorical_accuracy: 0.7259 - val_loss: 1.0932 - val_categorical_accuracy: 0.6593\n",
      "Weighted AUCs: [0.9522209996217346, 0.9269071149029684, 0.9091774425199451]\n",
      "weighted average Recalls: 0.7187704053443167 0.6593450479233227 0.6294712286158631\n",
      "unweighted average Recalls (macro): 0.4169221696193074 0.4169221696193074 0.4169221696193074\n",
      "weighted average Precisions: 0.7172113023431878 0.6332663364036077 0.5696558735736648\n",
      "unweighted average Precisions(macro): 0.5960796890012814 0.5960796890012814 0.5960796890012814\n",
      "weighted average F1s: 0.6930168794851473 0.619977360235264 0.5782267484616066\n",
      "unweighted average F1s(macro): 0.4430307025734065 0.4430307025734065 0.4430307025734065\n",
      "Test Categorical Accuracy: 0.6294712286158631\n",
      "Epoch 14/30\n",
      "19909/19909 [==============================] - 461s 23ms/step - loss: 0.8682 - categorical_accuracy: 0.7371 - val_loss: 1.2377 - val_categorical_accuracy: 0.6258\n",
      "Weighted AUCs: [0.9480345352087602, 0.9144966795478134, 0.9058056539834455]\n",
      "weighted average Recalls: 0.6845647697021447 0.6257987220447284 0.6057542768273717\n",
      "unweighted average Recalls (macro): 0.4313537284715037 0.4313537284715037 0.4313537284715037\n",
      "weighted average Precisions: 0.7338774873100269 0.6652315701511851 0.6306357951997342\n",
      "unweighted average Precisions(macro): 0.5398108015250044 0.5398108015250044 0.5398108015250044\n",
      "weighted average F1s: 0.6788061589401014 0.6120987840324548 0.5889542760410258\n",
      "unweighted average F1s(macro): 0.43456345969183924 0.43456345969183924 0.43456345969183924\n",
      "Test Categorical Accuracy: 0.6057542768273717\n",
      "Epoch 15/30\n",
      "19909/19909 [==============================] - 462s 23ms/step - loss: 0.8345 - categorical_accuracy: 0.7442 - val_loss: 1.1844 - val_categorical_accuracy: 0.6334\n",
      "Weighted AUCs: [0.9562858979932695, 0.9189143737259208, 0.9074852182588772]\n",
      "weighted average Recalls: 0.7242453161886584 0.6333865814696485 0.5991446345256609\n",
      "unweighted average Recalls (macro): 0.5058843462407943 0.5058843462407943 0.5058843462407943\n",
      "weighted average Precisions: 0.7539798796041718 0.6747225882634139 0.6191664856914799\n",
      "unweighted average Precisions(macro): 0.5653586156827681 0.5653586156827681 0.5653586156827681\n",
      "weighted average F1s: 0.7260185043907081 0.6343830875682239 0.596897398984182\n",
      "unweighted average F1s(macro): 0.5066978335812553 0.5066978335812553 0.5066978335812553\n",
      "Test Categorical Accuracy: 0.5991446345256609\n",
      "Epoch 16/30\n",
      "19909/19909 [==============================] - 462s 23ms/step - loss: 0.7962 - categorical_accuracy: 0.7568 - val_loss: 1.5000 - val_categorical_accuracy: 0.5559\n",
      "Weighted AUCs: [0.9376037056396567, 0.8960138122445398, 0.8899145364110955]\n",
      "weighted average Recalls: 0.6133909287257019 0.5559105431309904 0.5349922239502333\n",
      "unweighted average Recalls (macro): 0.41945674161321667 0.41945674161321667 0.41945674161321667\n",
      "weighted average Precisions: 0.7070389579842165 0.6391415521362909 0.6160602037501637\n",
      "unweighted average Precisions(macro): 0.4619143788418224 0.4619143788418224 0.4619143788418224\n",
      "weighted average F1s: 0.6062304689520415 0.5450429890469752 0.521894713337437\n",
      "unweighted average F1s(macro): 0.3854054595293236 0.3854054595293236 0.3854054595293236\n",
      "Test Categorical Accuracy: 0.5349922239502333\n",
      "Epoch 17/30\n",
      "19909/19909 [==============================] - 463s 23ms/step - loss: 0.7605 - categorical_accuracy: 0.7693 - val_loss: 1.3241 - val_categorical_accuracy: 0.6122\n",
      "Weighted AUCs: [0.96126041527222, 0.907154214814222, 0.8952348152884215]\n",
      "weighted average Recalls: 0.7366015369933196 0.612220447284345 0.604199066874028\n",
      "unweighted average Recalls (macro): 0.4803801344894397 0.4803801344894397 0.4803801344894397\n",
      "weighted average Precisions: 0.7413394788046269 0.6005800071099621 0.5845229637768923\n",
      "unweighted average Precisions(macro): 0.5962990143531663 0.5962990143531663 0.5962990143531663\n",
      "weighted average F1s: 0.7192313296477058 0.5838101541221782 0.5740838496396634\n",
      "unweighted average F1s(macro): 0.49851565069896153 0.49851565069896153 0.49851565069896153\n",
      "Test Categorical Accuracy: 0.604199066874028\n",
      "Epoch 18/30\n",
      "19909/19909 [==============================] - 463s 23ms/step - loss: 0.7275 - categorical_accuracy: 0.7777 - val_loss: 1.3590 - val_categorical_accuracy: 0.6178\n",
      "Weighted AUCs: [0.9527864687588449, 0.9130866434446905, 0.8880309751661012]\n",
      "weighted average Recalls: 0.6878798533326637 0.6178115015974441 0.5711508553654744\n",
      "unweighted average Recalls (macro): 0.47667927818898426 0.47667927818898426 0.47667927818898426\n",
      "weighted average Precisions: 0.7357495964567162 0.6075218795880108 0.579609111211599\n",
      "unweighted average Precisions(macro): 0.6384114135878804 0.6384114135878804 0.6384114135878804\n",
      "weighted average F1s: 0.6618609785741506 0.5844351814129777 0.5322776254161178\n",
      "unweighted average F1s(macro): 0.4534071277238455 0.4534071277238455 0.4534071277238455\n",
      "Test Categorical Accuracy: 0.5711508553654744\n",
      "Epoch 19/30\n",
      "19909/19909 [==============================] - 464s 23ms/step - loss: 0.6823 - categorical_accuracy: 0.7910 - val_loss: 1.2730 - val_categorical_accuracy: 0.6597\n",
      "Weighted AUCs: [0.9687535899894513, 0.9169830652342625, 0.898482085188872]\n",
      "weighted average Recalls: 0.7786930533929378 0.6597444089456869 0.6236391912908242\n",
      "unweighted average Recalls (macro): 0.47728382426379423 0.47728382426379423 0.47728382426379423\n",
      "weighted average Precisions: 0.7742854820688488 0.6411288784944221 0.6026382000009954\n",
      "unweighted average Precisions(macro): 0.5967652103906976 0.5967652103906976 0.5967652103906976\n",
      "weighted average F1s: 0.7575907220859852 0.633295101009994 0.5939608423689848\n",
      "unweighted average F1s(macro): 0.49167040575720145 0.49167040575720145 0.49167040575720145\n",
      "Test Categorical Accuracy: 0.6236391913139987\n",
      "Epoch 20/30\n",
      "19909/19909 [==============================] - 464s 23ms/step - loss: 0.6258 - categorical_accuracy: 0.8086 - val_loss: 1.6412 - val_categorical_accuracy: 0.5663\n",
      "Weighted AUCs: [0.9571855678048083, 0.8970764905494419, 0.8915401943554173]\n",
      "weighted average Recalls: 0.6676377517705561 0.5662939297124601 0.562208398133748\n",
      "unweighted average Recalls (macro): 0.3488909211703293 0.3488909211703293 0.3488909211703293\n",
      "weighted average Precisions: 0.7334715649427093 0.6285157346346303 0.5597337347063193\n",
      "unweighted average Precisions(macro): 0.489139686044834 0.489139686044834 0.489139686044834\n",
      "weighted average F1s: 0.6503398700660151 0.5438078177913688 0.5266573560770373\n",
      "unweighted average F1s(macro): 0.3597055591837238 0.3597055591837238 0.3597055591837238\n",
      "Test Categorical Accuracy: 0.5622083981569225\n",
      "Epoch 21/30\n",
      "19909/19909 [==============================] - 464s 23ms/step - loss: 0.5756 - categorical_accuracy: 0.8253 - val_loss: 1.8295 - val_categorical_accuracy: 0.5096\n",
      "Weighted AUCs: [0.9542049805786952, 0.8767528610068535, 0.86160605357341]\n",
      "weighted average Recalls: 0.6322266311718319 0.5095846645367412 0.4615085536547434\n",
      "unweighted average Recalls (macro): 0.5170472012813094 0.5170472012813094 0.5170472012813094\n",
      "weighted average Precisions: 0.8016311138316321 0.6777752130722856 0.618532665944671\n",
      "unweighted average Precisions(macro): 0.5631759627448414 0.5631759627448414 0.5631759627448414\n",
      "weighted average F1s: 0.6589589112905917 0.532485704039791 0.4964381276524992\n",
      "unweighted average F1s(macro): 0.44942208691107555 0.44942208691107555 0.44942208691107555\n",
      "Test Categorical Accuracy: 0.4615085536547434\n",
      "Epoch 22/30\n",
      "19909/19909 [==============================] - 465s 23ms/step - loss: 0.5375 - categorical_accuracy: 0.8363 - val_loss: 1.5964 - val_categorical_accuracy: 0.6098\n",
      "Weighted AUCs: [0.9686841941911193, 0.8981561467723772, 0.8883027444313144]\n",
      "weighted average Recalls: 0.7333869104425135 0.6098242811501597 0.5964230171073095\n",
      "unweighted average Recalls (macro): 0.44576925572939063 0.44576925572939063 0.44576925572939063\n",
      "weighted average Precisions: 0.755664863227502 0.6226904301449248 0.5646560939961388\n",
      "unweighted average Precisions(macro): 0.6205844707699201 0.6205844707699201 0.6205844707699201\n",
      "weighted average F1s: 0.7012915759629075 0.5679814707482865 0.5459809683127075\n",
      "unweighted average F1s(macro): 0.47492064611711626 0.47492064611711626 0.47492064611711626\n",
      "Test Categorical Accuracy: 0.5964230171188967\n",
      "Epoch 23/30\n",
      "19909/19909 [==============================] - 465s 23ms/step - loss: 0.4887 - categorical_accuracy: 0.8519 - val_loss: 1.5941 - val_categorical_accuracy: 0.6154\n",
      "Weighted AUCs: [0.9812497227779156, 0.9028439479424062, 0.8937741120841477]\n",
      "weighted average Recalls: 0.7777387111356673 0.6154153354632588 0.5925349922239502\n",
      "unweighted average Recalls (macro): 0.5116646462222623 0.5116646462222623 0.5116646462222623\n",
      "weighted average Precisions: 0.8087730349043833 0.6468294344575745 0.6264848993247585\n",
      "unweighted average Precisions(macro): 0.7055643435275538 0.7055643435275538 0.7055643435275538\n",
      "weighted average F1s: 0.7704437847157443 0.6012779482935022 0.5811449045052076\n",
      "unweighted average F1s(macro): 0.5449224770817735 0.5449224770817735 0.5449224770817735\n",
      "Test Categorical Accuracy: 0.5925349922239502\n",
      "Epoch 24/30\n",
      "19909/19909 [==============================] - 465s 23ms/step - loss: 0.4514 - categorical_accuracy: 0.8608 - val_loss: 1.5734 - val_categorical_accuracy: 0.5986\n",
      "Weighted AUCs: [0.9804089101999266, 0.8998811269552198, 0.881297954784319]\n",
      "weighted average Recalls: 0.7863780199909589 0.5986421725239617 0.5587091757387247\n",
      "unweighted average Recalls (macro): 0.6219364500639445 0.6219364500639445 0.6219364500639445\n",
      "weighted average Precisions: 0.8329450217606417 0.6362766214684221 0.6022465033710097\n",
      "unweighted average Precisions(macro): 0.701003596348381 0.701003596348381 0.701003596348381\n",
      "weighted average F1s: 0.791855069498261 0.5924106580865155 0.5534866461282308\n",
      "unweighted average F1s(macro): 0.6147608627386383 0.6147608627386383 0.6147608627386383\n",
      "Test Categorical Accuracy: 0.5587091757618992\n",
      "Epoch 25/30\n",
      "19909/19909 [==============================] - 464s 23ms/step - loss: 0.4113 - categorical_accuracy: 0.8761 - val_loss: 1.5943 - val_categorical_accuracy: 0.6122\n",
      "Weighted AUCs: [0.9854196589203168, 0.901043179464819, 0.8789030581261082]\n",
      "weighted average Recalls: 0.8388166156009845 0.612220447284345 0.588646967340591\n",
      "unweighted average Recalls (macro): 0.6828318474218605 0.6828318474218605 0.6828318474218605\n",
      "weighted average Precisions: 0.8660658728623283 0.6450920469905737 0.6131547130014963\n",
      "unweighted average Precisions(macro): 0.6589429899430641 0.6589429899430641 0.6589429899430641\n",
      "weighted average F1s: 0.8447239880990675 0.6188252858480168 0.5940173861909105\n",
      "unweighted average F1s(macro): 0.6402316546372167 0.6402316546372167 0.6402316546372167\n",
      "Test Categorical Accuracy: 0.5886469673521783\n",
      "Epoch 26/30\n",
      "19909/19909 [==============================] - 464s 23ms/step - loss: 0.3746 - categorical_accuracy: 0.8849 - val_loss: 1.6199 - val_categorical_accuracy: 0.6138\n",
      "Weighted AUCs: [0.9885174120614587, 0.9080297165386247, 0.8933384764241115]\n",
      "weighted average Recalls: 0.8308302777638255 0.6138178913738019 0.5870917573872473\n",
      "unweighted average Recalls (macro): 0.5905633039668097 0.5905633039668097 0.5905633039668097\n",
      "weighted average Precisions: 0.8726535596153908 0.6543226723855192 0.6149986533565783\n",
      "unweighted average Precisions(macro): 0.7807071600327449 0.7807071600327449 0.7807071600327449\n",
      "weighted average F1s: 0.8323028126160257 0.6184953506739654 0.5856431770456654\n",
      "unweighted average F1s(macro): 0.610840201143608 0.610840201143608 0.610840201143608\n",
      "Test Categorical Accuracy: 0.5870917574104217\n",
      "Epoch 27/30\n",
      "19909/19909 [==============================] - 465s 23ms/step - loss: 0.3378 - categorical_accuracy: 0.8985 - val_loss: 1.9415 - val_categorical_accuracy: 0.5619\n",
      "Weighted AUCs: [0.9802287127951346, 0.8871273519752312, 0.8694707700106694]\n",
      "weighted average Recalls: 0.7564920387764328 0.5619009584664537 0.5252721617418351\n",
      "unweighted average Recalls (macro): 0.6133293868676766 0.6133293868676766 0.6133293868676766\n",
      "weighted average Precisions: 0.8165373916324489 0.5988079917101377 0.5716855759519212\n",
      "unweighted average Precisions(macro): 0.719917034789552 0.719917034789552 0.719917034789552\n",
      "weighted average F1s: 0.7436154603087288 0.5432891414100165 0.507038336640038\n",
      "unweighted average F1s(macro): 0.5993527434208268 0.5993527434208268 0.5993527434208268\n",
      "Test Categorical Accuracy: 0.5252721618345328\n",
      "Epoch 28/30\n",
      "19909/19909 [==============================] - 465s 23ms/step - loss: 0.3216 - categorical_accuracy: 0.9029 - val_loss: 1.7434 - val_categorical_accuracy: 0.5835\n",
      "Weighted AUCs: [0.991389460343832, 0.8954419567845605, 0.8779544898289254]\n",
      "weighted average Recalls: 0.8392184439198352 0.5834664536741214 0.55248833592535\n",
      "unweighted average Recalls (macro): 0.6987474454027751 0.6987474454027751 0.6987474454027751\n",
      "weighted average Precisions: 0.877313500914702 0.6437582706833432 0.6095140820160859\n",
      "unweighted average Precisions(macro): 0.6927474660252644 0.6927474660252644 0.6927474660252644\n",
      "weighted average F1s: 0.8433290260533264 0.592315875403008 0.5603002793118251\n",
      "unweighted average F1s(macro): 0.6721452039067276 0.6721452039067276 0.6721452039067276\n",
      "Test Categorical Accuracy: 0.55248833592535\n",
      "Epoch 29/30\n",
      "19909/19909 [==============================] - 465s 23ms/step - loss: 0.2865 - categorical_accuracy: 0.9116 - val_loss: 1.6814 - val_categorical_accuracy: 0.6338\n",
      "Weighted AUCs: [0.9927849128069988, 0.8971519939613954, 0.8864867877183065]\n",
      "weighted average Recalls: 0.8905017831131649 0.6337859424920128 0.6170295489891136\n",
      "unweighted average Recalls (macro): 0.6903150481381242 0.6903150481381242 0.6903150481381242\n",
      "weighted average Precisions: 0.8926723332026194 0.6345777140342894 0.5931190697165236\n",
      "unweighted average Precisions(macro): 0.8005953695085506 0.8005953695085506 0.8005953695085506\n",
      "weighted average F1s: 0.8876886728139025 0.6229859196947838 0.5953093082950427\n",
      "unweighted average F1s(macro): 0.7211201940675945 0.7211201940675945 0.7211201940675945\n",
      "Test Categorical Accuracy: 0.6170295490007007\n",
      "Epoch 30/30\n",
      "19909/19909 [==============================] - 465s 23ms/step - loss: 0.2748 - categorical_accuracy: 0.9156 - val_loss: 1.7225 - val_categorical_accuracy: 0.6370\n",
      "Weighted AUCs: [0.9922711579391318, 0.9040468611238104, 0.8851598878964579]\n",
      "weighted average Recalls: 0.8785976191672108 0.6369808306709265 0.6088646967340591\n",
      "unweighted average Recalls (macro): 0.664804872199354 0.664804872199354 0.664804872199354\n",
      "weighted average Precisions: 0.8868419879269805 0.6277628678066216 0.6122364836773987\n",
      "unweighted average Precisions(macro): 0.8030977588443805 0.8030977588443805 0.8030977588443805\n",
      "weighted average F1s: 0.8742400370929265 0.6240435255436746 0.5980227745593454\n",
      "unweighted average F1s(macro): 0.6910502846365814 0.6910502846365814 0.6910502846365814\n",
      "Test Categorical Accuracy: 0.6088646966877103\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + 2RNN + output  (FMA)\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Flatten,Dense,Dropout,Reshape,GRU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 30\n",
    "input_shape = (96,1360,1)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same',input_shape=input_shape,name='conv1'))\n",
    "model.add(BatchNormalization(name='bn1'))\n",
    "model.add(Activation('relu',name='act1'))\n",
    "model.add(MaxPooling2D((2,2),padding='same',name='pool1'))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',name='conv2'))\n",
    "model.add(BatchNormalization(name='bn2'))\n",
    "model.add(Activation('relu',name='act2'))\n",
    "model.add(MaxPooling2D((3,3),padding='same',name='pool2'))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',name='conv3'))\n",
    "model.add(BatchNormalization(name='bn3'))\n",
    "model.add(Activation('relu',name='act3'))\n",
    "model.add(MaxPooling2D((4,4),padding='same',name='pool3'))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',name='conv4'))\n",
    "model.add(BatchNormalization(name='bn4'))\n",
    "model.add(Activation('relu',name='act4'))\n",
    "model.add(MaxPooling2D((4,4),padding='same',name='pool4'))\n",
    "model.add(Reshape((15, 128),name='rs'))\n",
    "\n",
    "model.add(GRU(32,return_sequences=True,name='gru1'))\n",
    "model.add(GRU(32,name='gru2'))\n",
    "model.add(Dropout(0.3,name='dropout'))\n",
    "model.add(Dense(16, activation='softmax',name='ds'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(),metrics=['categorical_accuracy'])\n",
    "\n",
    "filepath='C:/DT/model_save/fma/crnn/'+\"{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "\n",
    "path = 'C:/DT/fma_medium'\n",
    "x_train = np.load(path+'\\\\x_train.npy')\n",
    "y_train = np.load(path+'\\\\train_y.npy')\n",
    "y_train_idx = np.argmax(y_train,axis = -1)\n",
    "x_val = np.load(path+'\\\\x_val.npy')\n",
    "y_val = np.load(path+'\\\\val_y.npy')\n",
    "y_val_idx = np.argmax(y_val,axis = -1)\n",
    "x_test = np.load(path+'\\\\x_test.npy')\n",
    "y_test = np.load(path+'\\\\test_y.npy')\n",
    "y_test_idx = np.argmax(y_test,axis = -1)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,recall_score,precision_score,f1_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # all evaluation metrics include train, val, test except accs\n",
    "        self.aucs = [] # weighted AUC\n",
    "        self.recalls = [] # 16 recalls on each class and 1 mean recall\n",
    "        self.precisions = [] # 16 precisions on each class and 1 mean precision\n",
    "        self.f1s = [] # 16 f1s on each class and 1 mean f1 \n",
    "        self.accs = [] # mean accuracy without take imblance into account\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred_train = self.model.predict(x_train)\n",
    "        y_pred_val = self.model.predict(x_val)\n",
    "        y_pred_test = self.model.predict(x_test)\n",
    "        \n",
    "        y_pred_train_idx = np.argmax(y_pred_train,axis = -1)\n",
    "        y_pred_val_idx = np.argmax(y_pred_val,axis = -1)\n",
    "        y_pred_test_idx = np.argmax(y_pred_test,axis = -1)\n",
    "                \n",
    "        auc = [] #[train,val,test]\n",
    "        auc_train = roc_auc_score(y_train, y_pred_train,'weighted')\n",
    "        auc.append(auc_train)\n",
    "        auc_val = roc_auc_score(y_val, y_pred_val,'weighted')\n",
    "        auc.append(auc_val)\n",
    "        auc_test = roc_auc_score(y_test, y_pred_test,'weighted')\n",
    "        auc.append(auc_test)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"Weighted AUCs:\",auc)\n",
    "        \n",
    "        recall = []\n",
    "        recall_all = recall_score(y_train_idx,y_pred_train_idx,average=None)\n",
    "        recall.append(recall_all)\n",
    "        recall_mean = recall_score(y_train_idx,y_pred_train_idx,average='weighted')\n",
    "        recall.append(recall_mean)\n",
    "        recall_mean = recall_score(y_train_idx,y_pred_train_idx,average='macro')\n",
    "        recall.append(recall_mean)\n",
    "        recall_all = recall_score(y_val_idx,y_pred_val_idx,average=None)\n",
    "        recall.append(recall_all)\n",
    "        recall_mean = recall_score(y_val_idx,y_pred_val_idx,average='weighted')\n",
    "        recall.append(recall_mean)\n",
    "        recall_mean = recall_score(y_val_idx,y_pred_val_idx,average='macro')\n",
    "        recall.append(recall_mean)\n",
    "        recall_all = recall_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        recall.append(recall_all)\n",
    "        recall_mean = recall_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        recall.append(recall_mean)\n",
    "        recall_mean = recall_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        recall.append(recall_mean)\n",
    "        self.recalls.append(recall)\n",
    "        print(\"weighted average Recalls:\",recall[1],recall[4],recall[7])\n",
    "        print(\"unweighted average Recalls (macro):\",recall[2],recall[5],recall[8])\n",
    "        \n",
    "        precision = []\n",
    "        precision_all = precision_score(y_train_idx,y_pred_train_idx,average=None)\n",
    "        precision.append(precision_all)\n",
    "        precision_mean = precision_score(y_train_idx,y_pred_train_idx,average='weighted')\n",
    "        precision.append(precision_mean)\n",
    "        precision_mean = precision_score(y_train_idx,y_pred_train_idx,average='macro')\n",
    "        precision.append(precision_mean)\n",
    "        precision_all = precision_score(y_val_idx,y_pred_val_idx,average=None)\n",
    "        precision.append(precision_all)\n",
    "        precision_mean = precision_score(y_val_idx,y_pred_val_idx,average='weighted')\n",
    "        precision.append(precision_mean)\n",
    "        precision_mean = precision_score(y_val_idx,y_pred_val_idx,average='macro')\n",
    "        precision.append(precision_mean)\n",
    "        precision_all = precision_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        precision.append(precision_all)\n",
    "        precision_mean = precision_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        precision.append(precision_mean)\n",
    "        precision_mean = precision_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        precision.append(precision_mean)\n",
    "        self.precisions.append(precision)\n",
    "        print(\"weighted average Precisions:\",precision[1],precision[4],precision[7])\n",
    "        print(\"unweighted average Precisions(macro):\",precision[2],precision[5],precision[8])\n",
    "        \n",
    "        f1 = []\n",
    "        f1_all = f1_score(y_train_idx,y_pred_train_idx,average=None)\n",
    "        f1.append(f1_all)\n",
    "        f1_mean = f1_score(y_train_idx,y_pred_train_idx,average='weighted')\n",
    "        f1.append(f1_mean)\n",
    "        f1_mean = f1_score(y_train_idx,y_pred_train_idx,average='macro')\n",
    "        f1.append(f1_mean)\n",
    "        f1_all = f1_score(y_val_idx,y_pred_val_idx,average=None)\n",
    "        f1.append(f1_all)\n",
    "        f1_mean = f1_score(y_val_idx,y_pred_val_idx,average='weighted')\n",
    "        f1.append(f1_mean)\n",
    "        f1_mean = f1_score(y_val_idx,y_pred_val_idx,average='macro')\n",
    "        f1.append(f1_mean)\n",
    "        f1_all = f1_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        f1.append(f1_all)\n",
    "        f1_mean = f1_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        f1.append(f1_mean)\n",
    "        f1_mean = f1_score(y_train_idx,y_pred_train_idx,average='macro')\n",
    "        f1.append(f1_mean)\n",
    "        self.f1s.append(f1)\n",
    "        print(\"weighted average F1s:\",f1[1],f1[4],f1[7])\n",
    "        print(\"unweighted average F1s(macro):\",f1[2],f1[5],f1[8])\n",
    "        \n",
    "        loss, acc = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "        self.accs.append(acc)\n",
    "        print(\"Test Categorical Accuracy:\",acc)\n",
    "                \n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, validation_data=(x_val,y_val), callbacks=[histories,checkpoint])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "pickle.dump(histories.aucs,open(os.path.join(path,'metrics_save/crnn_aucs.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls,open(os.path.join(path,'metrics_save/crnn_recalls.pkl'),'wb'))\n",
    "pickle.dump(histories.precisions,open(os.path.join(path,'metrics_save/crnn_precisions.pkl'),'wb'))\n",
    "pickle.dump(histories.f1s,open(os.path.join(path,'metrics_save/crnn_f1s.pkl'),'wb'))\n",
    "pickle.dump(histories.accs,open(os.path.join(path,'metrics_save/crnn_accs.pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(path,'metrics_save/crnn_history.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 96, 1360, 64) 640         main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn_1 (BatchNormalization)       (None, 96, 1360, 64) 256         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_1 (Activation)              (None, 96, 1360, 64) 0           bn_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_1 (MaxPooling2D)           (None, 48, 340, 64)  0           act_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 48, 340, 128) 73856       pool_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_2 (BatchNormalization)       (None, 48, 340, 128) 512         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_2 (Activation)              (None, 48, 340, 128) 0           bn_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_2 (MaxPooling2D)           (None, 24, 85, 128)  0           act_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 24, 85, 128)  147584      pool_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_3 (BatchNormalization)       (None, 24, 85, 128)  512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_3 (Activation)              (None, 24, 85, 128)  0           bn_3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_3 (MaxPooling2D)           (None, 12, 22, 128)  0           act_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 12, 22, 128)  147584      pool_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_4 (BatchNormalization)       (None, 12, 22, 128)  512         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_4 (Activation)              (None, 12, 22, 128)  0           bn_4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_4 (MaxPooling2D)           (None, 6, 6, 128)    0           act_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru5_in_perm (Lambda)           (None, 6, 6, 128)    0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru3_in_perm (Lambda)           (None, 6, 6, 128)    0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru6_in_perm (Lambda)           (None, 6, 6, 128)    0           gru5_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru2_in_perm (Lambda)           (None, 6, 6, 128)    0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru4_in_perm (Lambda)           (None, 6, 6, 128)    0           gru3_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru7_in_perm (Lambda)           (None, 6, 6, 128)    0           gru5_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru8_in_perm (Lambda)           (None, 6, 6, 128)    0           gru6_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru1_in (Reshape)               (None, 6, 768)       0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2_in (Reshape)               (None, 6, 768)       0           gru2_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru3_in (Reshape)               (None, 6, 768)       0           gru3_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru4_in (Reshape)               (None, 6, 768)       0           gru4_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru5_in (Reshape)               (None, 6, 768)       0           gru5_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru6_in (Reshape)               (None, 6, 768)       0           gru6_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru7_in (Reshape)               (None, 6, 768)       0           gru7_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru8_in (Reshape)               (None, 6, 768)       0           gru8_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 32)           76896       gru1_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 32)           76896       gru2_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru3 (GRU)                      (None, 32)           76896       gru3_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru4 (GRU)                      (None, 32)           76896       gru4_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru5 (GRU)                      (None, 32)           76896       gru5_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru6 (GRU)                      (None, 32)           76896       gru6_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru7 (GRU)                      (None, 32)           76896       gru7_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru8 (GRU)                      (None, 32)           76896       gru8_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_conc (Concatenate)          (None, 256)          0           gru1[0][0]                       \n",
      "                                                                 gru2[0][0]                       \n",
      "                                                                 gru3[0][0]                       \n",
      "                                                                 gru4[0][0]                       \n",
      "                                                                 gru5[0][0]                       \n",
      "                                                                 gru6[0][0]                       \n",
      "                                                                 gru7[0][0]                       \n",
      "                                                                 gru8[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gru_conc_dropout (Dropout)      (None, 256)          0           gru_conc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 64)           16448       gru_conc_dropout[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pred (Dense)                    (None, 16)           1040        fc[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 1,004,112\n",
      "Trainable params: 1,003,216\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Train on 19909 samples, validate on 2504 samples\n",
      "Epoch 1/30\n",
      "19909/19909 [==============================] - 422s 21ms/step - loss: 1.5334 - categorical_accuracy: 0.5291 - val_loss: 1.6174 - val_categorical_accuracy: 0.5012\n",
      "Weighted AUCs: [0.859306942873464, 0.8600268078897613, 0.8554570466115138]\n",
      "weighted average Recalls: 0.4687327339394244 0.5011980830670927 0.4665629860031104\n",
      "unweighted average Recalls (macro): 0.29703285177445543 0.29703285177445543 0.29703285177445543\n",
      "weighted average Precisions: 0.562961088536811 0.5700928211912623 0.5371464336630964\n",
      "unweighted average Precisions(macro): 0.29418978666288864 0.29418978666288864 0.29418978666288864\n",
      "weighted average F1s: 0.4666278829627735 0.4933775343992956 0.45540765180030995\n",
      "unweighted average F1s(macro): 0.24846198392721522 0.24846198392721522 0.24846198392721522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Categorical Accuracy: 0.46656298601469764\n",
      "Epoch 2/30\n",
      "19909/19909 [==============================] - 415s 21ms/step - loss: 1.3220 - categorical_accuracy: 0.5930 - val_loss: 1.3177 - val_categorical_accuracy: 0.5915\n",
      "Weighted AUCs: [0.894544945787742, 0.8905739771089058, 0.884717407211161]\n",
      "weighted average Recalls: 0.6002812798231956 0.5914536741214057 0.5692068429237948\n",
      "unweighted average Recalls (macro): 0.3319081494887667 0.3319081494887667 0.3319081494887667\n",
      "weighted average Precisions: 0.5771790931102986 0.5425203627980586 0.5278120763596411\n",
      "unweighted average Precisions(macro): 0.35519883561661686 0.35519883561661686 0.35519883561661686\n",
      "weighted average F1s: 0.5607342552468253 0.5476293738763767 0.5255285121705955\n",
      "unweighted average F1s(macro): 0.31213042841181626 0.31213042841181626 0.31213042841181626\n",
      "Test Categorical Accuracy: 0.5692068429237948\n",
      "Epoch 3/30\n",
      "19909/19909 [==============================] - 415s 21ms/step - loss: 1.2511 - categorical_accuracy: 0.6145 - val_loss: 1.4581 - val_categorical_accuracy: 0.5451\n",
      "Weighted AUCs: [0.8893604093128737, 0.8887576896903765, 0.8739698586936657]\n",
      "weighted average Recalls: 0.5435230297855241 0.5451277955271565 0.5256609642301711\n",
      "unweighted average Recalls (macro): 0.2580222618520186 0.2580222618520186 0.2580222618520186\n",
      "weighted average Precisions: 0.5972592010639988 0.5557846500211573 0.5504948527589236\n",
      "unweighted average Precisions(macro): 0.43157161650160114 0.43157161650160114 0.43157161650160114\n",
      "weighted average F1s: 0.4962538875195486 0.48934680309668066 0.47504844766628457\n",
      "unweighted average F1s(macro): 0.2685387226759281 0.2685387226759281 0.2685387226759281\n",
      "Test Categorical Accuracy: 0.5256609642301711\n",
      "Epoch 4/30\n",
      "19909/19909 [==============================] - 414s 21ms/step - loss: 1.2102 - categorical_accuracy: 0.6292 - val_loss: 1.2258 - val_categorical_accuracy: 0.6394\n",
      "Weighted AUCs: [0.9051076483996369, 0.9053250864213271, 0.8912445702358109]\n",
      "weighted average Recalls: 0.6080164749610729 0.6393769968051118 0.5824261275272161\n",
      "unweighted average Recalls (macro): 0.3762903164728034 0.3762903164728034 0.3762903164728034\n",
      "weighted average Precisions: 0.6031946246379205 0.6207541079503237 0.5755506438701838\n",
      "unweighted average Precisions(macro): 0.37502541417206586 0.37502541417206586 0.37502541417206586\n",
      "weighted average F1s: 0.5799363766918769 0.6057639088723893 0.55246573948528\n",
      "unweighted average F1s(macro): 0.35271887955725406 0.35271887955725406 0.35271887955725406\n",
      "Test Categorical Accuracy: 0.5824261275388034\n",
      "Epoch 5/30\n",
      "19909/19909 [==============================] - 414s 21ms/step - loss: 1.1716 - categorical_accuracy: 0.6374 - val_loss: 1.3242 - val_categorical_accuracy: 0.5871\n",
      "Weighted AUCs: [0.9007895812524053, 0.8997605063187136, 0.8826632752370622]\n",
      "weighted average Recalls: 0.5873725450801145 0.5870607028753994 0.5517107309486781\n",
      "unweighted average Recalls (macro): 0.33450604748159735 0.33450604748159735 0.33450604748159735\n",
      "weighted average Precisions: 0.6114028113517128 0.6023757863903366 0.5441508982313236\n",
      "unweighted average Precisions(macro): 0.41449650693963375 0.41449650693963375 0.41449650693963375\n",
      "weighted average F1s: 0.5598035565437415 0.5507687767870367 0.5097918420571487\n",
      "unweighted average F1s(macro): 0.3431784477673051 0.3431784477673051 0.3431784477673051\n",
      "Test Categorical Accuracy: 0.5517107309486781\n",
      "Epoch 6/30\n",
      "19909/19909 [==============================] - 415s 21ms/step - loss: 1.1461 - categorical_accuracy: 0.6457 - val_loss: 1.1597 - val_categorical_accuracy: 0.6538\n",
      "Weighted AUCs: [0.9203650709764938, 0.9159838539463451, 0.89992892205008]\n",
      "weighted average Recalls: 0.6377015420161736 0.6537539936102237 0.6006998444790047\n",
      "unweighted average Recalls (macro): 0.3718916485157429 0.3718916485157429 0.3718916485157429\n",
      "weighted average Precisions: 0.6208682472474316 0.5996976244338057 0.5528569617649696\n",
      "unweighted average Precisions(macro): 0.4391096023882921 0.4391096023882921 0.4391096023882921\n",
      "weighted average F1s: 0.5960048085143881 0.6065380407473379 0.5473960588855175\n",
      "unweighted average F1s(macro): 0.3611484721545619 0.3611484721545619 0.3611484721545619\n",
      "Test Categorical Accuracy: 0.6006998444905919\n",
      "Epoch 7/30\n",
      "19909/19909 [==============================] - 415s 21ms/step - loss: 1.1308 - categorical_accuracy: 0.6505 - val_loss: 1.3715 - val_categorical_accuracy: 0.5855\n",
      "Weighted AUCs: [0.9102029791337731, 0.8994285604761149, 0.8900195259140877]\n",
      "weighted average Recalls: 0.6080164749610729 0.5854632587859425 0.5653188180404355\n",
      "unweighted average Recalls (macro): 0.2989379449257219 0.2989379449257219 0.2989379449257219\n",
      "weighted average Precisions: 0.6063883593614147 0.5490989863599403 0.5498138851333476\n",
      "unweighted average Precisions(macro): 0.44220363932114193 0.44220363932114193 0.44220363932114193\n",
      "weighted average F1s: 0.5512507517242937 0.5147693467715524 0.4968734965315544\n",
      "unweighted average F1s(macro): 0.3166930131566424 0.3166930131566424 0.3166930131566424\n",
      "Test Categorical Accuracy: 0.5653188180404355\n",
      "Epoch 8/30\n",
      "19909/19909 [==============================] - 416s 21ms/step - loss: 1.1023 - categorical_accuracy: 0.6586 - val_loss: 1.3975 - val_categorical_accuracy: 0.5819\n",
      "Weighted AUCs: [0.9088596969521193, 0.9022886958079496, 0.8884470733533035]\n",
      "weighted average Recalls: 0.5991762519463559 0.5818690095846646 0.5715396578538102\n",
      "unweighted average Recalls (macro): 0.26822751340998685 0.26822751340998685 0.26822751340998685\n",
      "weighted average Precisions: 0.6455249126041255 0.5583891255451946 0.5044160636458626\n",
      "unweighted average Precisions(macro): 0.4871200443152943 0.4871200443152943 0.4871200443152943\n",
      "weighted average F1s: 0.5450732538834957 0.5216010886406117 0.5069609227295419\n",
      "unweighted average F1s(macro): 0.27584441376985686 0.27584441376985686 0.27584441376985686\n",
      "Test Categorical Accuracy: 0.5715396578538102\n",
      "Epoch 9/30\n",
      "19909/19909 [==============================] - 417s 21ms/step - loss: 1.0978 - categorical_accuracy: 0.6598 - val_loss: 1.6653 - val_categorical_accuracy: 0.4984\n",
      "Weighted AUCs: [0.8905229276593182, 0.8922516875260634, 0.8632705929292291]\n",
      "weighted average Recalls: 0.4807373549650912 0.4984025559105431 0.46967340590979784\n",
      "unweighted average Recalls (macro): 0.29225152441106994 0.29225152441106994 0.29225152441106994\n",
      "weighted average Precisions: 0.5630468343593773 0.5550955659385391 0.48297688837438324\n",
      "unweighted average Precisions(macro): 0.34216018922120783 0.34216018922120783 0.34216018922120783\n",
      "weighted average F1s: 0.40676990823468734 0.4287442848160981 0.38883969221043746\n",
      "unweighted average F1s(macro): 0.24395297629449886 0.24395297629449886 0.24395297629449886\n",
      "Test Categorical Accuracy: 0.4696734060024956\n",
      "Epoch 10/30\n",
      "19909/19909 [==============================] - 417s 21ms/step - loss: 1.0796 - categorical_accuracy: 0.6645 - val_loss: 1.1161 - val_categorical_accuracy: 0.6633\n",
      "Weighted AUCs: [0.9279929272761146, 0.923690200653797, 0.9028322185496831]\n",
      "weighted average Recalls: 0.6646240393791752 0.6633386581469649 0.630248833592535\n",
      "unweighted average Recalls (macro): 0.38125042424449995 0.38125042424449995 0.38125042424449995\n",
      "weighted average Precisions: 0.656372193265063 0.621070689730995 0.5724085461790935\n",
      "unweighted average Precisions(macro): 0.4587547991569502 0.4587547991569502 0.4587547991569502\n",
      "weighted average F1s: 0.6325674847231355 0.6256565912986211 0.5813618956741867\n",
      "unweighted average F1s(macro): 0.3893811666799073 0.3893811666799073 0.3893811666799073\n",
      "Test Categorical Accuracy: 0.630248833592535\n",
      "Epoch 11/30\n",
      "19909/19909 [==============================] - 418s 21ms/step - loss: 1.0589 - categorical_accuracy: 0.6689 - val_loss: 1.1202 - val_categorical_accuracy: 0.6589\n",
      "Weighted AUCs: [0.9256820324024014, 0.9174894045711449, 0.902651104697344]\n",
      "weighted average Recalls: 0.6691948365061028 0.6589456869009584 0.6283048211508554\n",
      "unweighted average Recalls (macro): 0.3947223162898706 0.3947223162898706 0.3947223162898706\n",
      "weighted average Precisions: 0.6548996966553435 0.6222291530835528 0.5695353711642751\n",
      "unweighted average Precisions(macro): 0.47406028428671 0.47406028428671 0.47406028428671\n",
      "weighted average F1s: 0.6393827957964334 0.6265990184076168 0.5846399932038898\n",
      "unweighted average F1s(macro): 0.4043270419661712 0.4043270419661712 0.4043270419661712\n",
      "Test Categorical Accuracy: 0.6283048211508554\n",
      "Epoch 12/30\n",
      "19909/19909 [==============================] - 417s 21ms/step - loss: 1.0502 - categorical_accuracy: 0.6736 - val_loss: 1.1205 - val_categorical_accuracy: 0.6629\n",
      "Weighted AUCs: [0.9305977412751291, 0.9202503923552054, 0.8982517750328156]\n",
      "weighted average Recalls: 0.6776834597418253 0.6629392971246006 0.6135303265940902\n",
      "unweighted average Recalls (macro): 0.38931420172411557 0.38931420172411557 0.38931420172411557\n",
      "weighted average Precisions: 0.6882310668324124 0.631799835814511 0.5984349034562655\n",
      "unweighted average Precisions(macro): 0.5607327888309965 0.5607327888309965 0.5607327888309965\n",
      "weighted average F1s: 0.6505224595001008 0.6321636400805737 0.5764817857754412\n",
      "unweighted average F1s(macro): 0.3968362761426716 0.3968362761426716 0.3968362761426716\n",
      "Test Categorical Accuracy: 0.6135303265940902\n",
      "Epoch 13/30\n",
      "19909/19909 [==============================] - 417s 21ms/step - loss: 1.0250 - categorical_accuracy: 0.6798 - val_loss: 1.0802 - val_categorical_accuracy: 0.6713\n",
      "Weighted AUCs: [0.9378191502080373, 0.9260656547714133, 0.909568393463057]\n",
      "weighted average Recalls: 0.6945100205937014 0.6713258785942492 0.6185847589424572\n",
      "unweighted average Recalls (macro): 0.4404489660568484 0.4404489660568484 0.4404489660568484\n",
      "weighted average Precisions: 0.6842119143776416 0.6437283413974719 0.5921484476566871\n",
      "unweighted average Precisions(macro): 0.5149335051798837 0.5149335051798837 0.5149335051798837\n",
      "weighted average F1s: 0.6796871822190894 0.6499671430009547 0.5948381305658761\n",
      "unweighted average F1s(macro): 0.45290473966018097 0.45290473966018097 0.45290473966018097\n",
      "Test Categorical Accuracy: 0.6185847589424572\n",
      "Epoch 14/30\n",
      "19909/19909 [==============================] - 415s 21ms/step - loss: 1.0084 - categorical_accuracy: 0.6860 - val_loss: 1.4229 - val_categorical_accuracy: 0.5559\n",
      "Weighted AUCs: [0.9144177869535757, 0.8998005909983685, 0.8888014139078287]\n",
      "weighted average Recalls: 0.582651062333618 0.5559105431309904 0.5559875583203733\n",
      "unweighted average Recalls (macro): 0.29831265763871984 0.29831265763871984 0.29831265763871984\n",
      "weighted average Precisions: 0.6134825134788682 0.5656447538869017 0.5402408735372873\n",
      "unweighted average Precisions(macro): 0.47344936996755554 0.47344936996755554 0.47344936996755554\n",
      "weighted average F1s: 0.5177095172303832 0.4778982402273359 0.4820356846964967\n",
      "unweighted average F1s(macro): 0.30554753371360655 0.30554753371360655 0.30554753371360655\n",
      "Test Categorical Accuracy: 0.5559875583203733\n",
      "Epoch 15/30\n",
      "19909/19909 [==============================] - 412s 21ms/step - loss: 0.9901 - categorical_accuracy: 0.6855 - val_loss: 1.1204 - val_categorical_accuracy: 0.6621\n",
      "Weighted AUCs: [0.9376273455223498, 0.9167704885204615, 0.9049501526828039]\n",
      "weighted average Recalls: 0.6914963082023206 0.6621405750798722 0.6271384136858476\n",
      "unweighted average Recalls (macro): 0.4519842700945859 0.4519842700945859 0.4519842700945859\n",
      "weighted average Precisions: 0.6884485388880903 0.6336206233119295 0.6054772890166019\n",
      "unweighted average Precisions(macro): 0.5523427788373751 0.5523427788373751 0.5523427788373751\n",
      "weighted average F1s: 0.6728835725723068 0.6356737097320415 0.6079941187006161\n",
      "unweighted average F1s(macro): 0.4524456176232295 0.4524456176232295 0.4524456176232295\n",
      "Test Categorical Accuracy: 0.6271384136974348\n",
      "Epoch 16/30\n",
      "19909/19909 [==============================] - 412s 21ms/step - loss: 0.9782 - categorical_accuracy: 0.6930 - val_loss: 1.5233 - val_categorical_accuracy: 0.5427\n",
      "Weighted AUCs: [0.9063560288349641, 0.8931807585172367, 0.8830208794243914]\n",
      "weighted average Recalls: 0.5634637601084936 0.5427316293929713 0.5408242612752722\n",
      "unweighted average Recalls (macro): 0.27798202680276984 0.27798202680276984 0.27798202680276984\n",
      "weighted average Precisions: 0.6350904646007189 0.6037123823948309 0.5640087480098682\n",
      "unweighted average Precisions(macro): 0.48169587668710934 0.48169587668710934 0.48169587668710934\n",
      "weighted average F1s: 0.5321388825507815 0.5091051658181032 0.49525364606932293\n",
      "unweighted average F1s(macro): 0.3010463349082016 0.3010463349082016 0.3010463349082016\n",
      "Test Categorical Accuracy: 0.5408242612752722\n",
      "Epoch 17/30\n",
      "19909/19909 [==============================] - 413s 21ms/step - loss: 0.9610 - categorical_accuracy: 0.6964 - val_loss: 1.1262 - val_categorical_accuracy: 0.6609\n",
      "Weighted AUCs: [0.9375874705279743, 0.9235510936919044, 0.9062986531612615]\n",
      "weighted average Recalls: 0.6807976292129188 0.6609424920127795 0.6341368584758943\n",
      "unweighted average Recalls (macro): 0.4116739501842037 0.4116739501842037 0.4116739501842037\n",
      "weighted average Precisions: 0.6911808091138748 0.6216927454136786 0.6375261546904879\n",
      "unweighted average Precisions(macro): 0.519271350663802 0.519271350663802 0.519271350663802\n",
      "weighted average F1s: 0.6443893451343712 0.6157835055504655 0.5786344184427406\n",
      "unweighted average F1s(macro): 0.40596073125874044 0.40596073125874044 0.40596073125874044\n",
      "Test Categorical Accuracy: 0.6341368584758943\n",
      "Epoch 18/30\n",
      "19909/19909 [==============================] - 416s 21ms/step - loss: 0.9398 - categorical_accuracy: 0.7043 - val_loss: 1.2971 - val_categorical_accuracy: 0.6090\n",
      "Weighted AUCs: [0.9279757090811351, 0.9087288640270449, 0.8891415609038577]\n",
      "weighted average Recalls: 0.6311216032949922 0.6090255591054313 0.5719284603421462\n",
      "unweighted average Recalls (macro): 0.42755356280462853 0.42755356280462853 0.42755356280462853\n",
      "weighted average Precisions: 0.6798764743104873 0.6283390670223309 0.5979019394127456\n",
      "unweighted average Precisions(macro): 0.495536313355599 0.495536313355599 0.495536313355599\n",
      "weighted average F1s: 0.6196791690690043 0.5903494887684094 0.5548550930482161\n",
      "unweighted average F1s(macro): 0.4069541018597913 0.4069541018597913 0.4069541018597913\n",
      "Test Categorical Accuracy: 0.5719284602494484\n",
      "Epoch 19/30\n",
      "19909/19909 [==============================] - 416s 21ms/step - loss: 0.9235 - categorical_accuracy: 0.7064 - val_loss: 1.1000 - val_categorical_accuracy: 0.6669\n",
      "Weighted AUCs: [0.9472330069611008, 0.9257353880982406, 0.9059056741509518]\n",
      "weighted average Recalls: 0.7022452157315787 0.6669329073482428 0.6279160186625194\n",
      "unweighted average Recalls (macro): 0.45241738772850215 0.45241738772850215 0.45241738772850215\n",
      "weighted average Precisions: 0.6949719788461792 0.6251530927895741 0.5888058299320038\n",
      "unweighted average Precisions(macro): 0.6362071498862973 0.6362071498862973 0.6362071498862973\n",
      "weighted average F1s: 0.6812678869077489 0.6335146608082686 0.5897089439438509\n",
      "unweighted average F1s(macro): 0.4714799888916317 0.4714799888916317 0.4714799888916317\n",
      "Test Categorical Accuracy: 0.6279160186161705\n",
      "Epoch 20/30\n",
      "19909/19909 [==============================] - 417s 21ms/step - loss: 0.9038 - categorical_accuracy: 0.7114 - val_loss: 1.1507 - val_categorical_accuracy: 0.6558\n",
      "Weighted AUCs: [0.9458061064416711, 0.9184535687950256, 0.8972330993268888]\n",
      "weighted average Recalls: 0.7033502436084184 0.6557507987220448 0.6053654743390358\n",
      "unweighted average Recalls (macro): 0.46507274640030605 0.46507274640030605 0.46507274640030605\n",
      "weighted average Precisions: 0.7167045116424132 0.6357377046869962 0.5875763973598129\n",
      "unweighted average Precisions(macro): 0.6149931467964431 0.6149931467964431 0.6149931467964431\n",
      "weighted average F1s: 0.6854295500823966 0.6298422694775347 0.5756908374971607\n",
      "unweighted average F1s(macro): 0.4683998752689212 0.4683998752689212 0.4683998752689212\n",
      "Test Categorical Accuracy: 0.6053654743390358\n",
      "Epoch 21/30\n",
      "19909/19909 [==============================] - 417s 21ms/step - loss: 0.8907 - categorical_accuracy: 0.7184 - val_loss: 1.1569 - val_categorical_accuracy: 0.6486\n",
      "Weighted AUCs: [0.9492446445112788, 0.9182602722718974, 0.9075882916987889]\n",
      "weighted average Recalls: 0.7113365814455774 0.6485623003194888 0.6170295489891136\n",
      "unweighted average Recalls (macro): 0.44725015262084156 0.44725015262084156 0.44725015262084156\n",
      "weighted average Precisions: 0.7077490981957136 0.6247673877020643 0.5844024038355692\n",
      "unweighted average Precisions(macro): 0.6356227331671698 0.6356227331671698 0.6356227331671698\n",
      "weighted average F1s: 0.6863604040551414 0.6132251015075237 0.5736178330683783\n",
      "unweighted average F1s(macro): 0.47095725020719176 0.47095725020719176 0.47095725020719176\n",
      "Test Categorical Accuracy: 0.6170295489891136\n",
      "Epoch 22/30\n",
      "19909/19909 [==============================] - 417s 21ms/step - loss: 0.8637 - categorical_accuracy: 0.7246 - val_loss: 1.0947 - val_categorical_accuracy: 0.6773\n",
      "Weighted AUCs: [0.9514588305060261, 0.9226805349173552, 0.9030222245548943]\n",
      "weighted average Recalls: 0.7273092571198955 0.6773162939297125 0.6290824261275272\n",
      "unweighted average Recalls (macro): 0.4948385577009541 0.4948385577009541 0.4948385577009541\n",
      "weighted average Precisions: 0.7363603486723762 0.6571058833572054 0.6018354999657092\n",
      "unweighted average Precisions(macro): 0.6553555160992441 0.6553555160992441 0.6553555160992441\n",
      "weighted average F1s: 0.7081521039050152 0.6502996617102131 0.6010183153639286\n",
      "unweighted average F1s(macro): 0.493577430716456 0.493577430716456 0.493577430716456\n",
      "Test Categorical Accuracy: 0.6290824261275272\n",
      "Epoch 23/30\n",
      "19909/19909 [==============================] - 417s 21ms/step - loss: 0.8459 - categorical_accuracy: 0.7307 - val_loss: 1.3172 - val_categorical_accuracy: 0.6258\n",
      "Weighted AUCs: [0.9429998047381587, 0.9128694295627925, 0.9032676240969275]\n",
      "weighted average Recalls: 0.6873273393942438 0.6257987220447284 0.6049766718506998\n",
      "unweighted average Recalls (macro): 0.4167594205604191 0.4167594205604191 0.4167594205604191\n",
      "weighted average Precisions: 0.7151301137978229 0.6371570971962685 0.5956411240652022\n",
      "unweighted average Precisions(macro): 0.660239988398214 0.660239988398214 0.660239988398214\n",
      "weighted average F1s: 0.6657516941279364 0.5971600362610153 0.565045851181058\n",
      "unweighted average F1s(macro): 0.45874038106023435 0.45874038106023435 0.45874038106023435\n",
      "Test Categorical Accuracy: 0.6049766718622871\n",
      "Epoch 24/30\n",
      "19909/19909 [==============================] - 417s 21ms/step - loss: 0.8332 - categorical_accuracy: 0.7326 - val_loss: 1.1080 - val_categorical_accuracy: 0.6781\n",
      "Weighted AUCs: [0.962018148726183, 0.9241418623591524, 0.9089741465129896]\n",
      "weighted average Recalls: 0.7644281480737355 0.6781150159744409 0.6395800933125972\n",
      "unweighted average Recalls (macro): 0.5768514935274787 0.5768514935274787 0.5768514935274787\n",
      "weighted average Precisions: 0.7570379159960574 0.6489359532133322 0.6101720465544618\n",
      "unweighted average Precisions(macro): 0.6894404280724296 0.6894404280724296 0.6894404280724296\n",
      "weighted average F1s: 0.7506983074053187 0.6564593900174817 0.6110066200061232\n",
      "unweighted average F1s(macro): 0.5932708859185929 0.5932708859185929 0.5932708859185929\n",
      "Test Categorical Accuracy: 0.6395800933125972\n",
      "Epoch 25/30\n",
      "19909/19909 [==============================] - 418s 21ms/step - loss: 0.7992 - categorical_accuracy: 0.7426 - val_loss: 1.1528 - val_categorical_accuracy: 0.6593\n",
      "Weighted AUCs: [0.9609224345514855, 0.9184705679311321, 0.9081908662834233]\n",
      "weighted average Recalls: 0.7520719272690742 0.6593450479233227 0.6255832037325039\n",
      "unweighted average Recalls (macro): 0.5763833742984086 0.5763833742984086 0.5763833742984086\n",
      "weighted average Precisions: 0.7462657844550395 0.6314431411763187 0.5945403863931715\n",
      "unweighted average Precisions(macro): 0.6769080621858836 0.6769080621858836 0.6769080621858836\n",
      "weighted average F1s: 0.7393806270304409 0.6375027225281332 0.5991615895506763\n",
      "unweighted average F1s(macro): 0.5910664976721394 0.5910664976721394 0.5910664976721394\n",
      "Test Categorical Accuracy: 0.6255832037325039\n",
      "Epoch 26/30\n",
      "19909/19909 [==============================] - 418s 21ms/step - loss: 0.7817 - categorical_accuracy: 0.7468 - val_loss: 1.3914 - val_categorical_accuracy: 0.6258\n",
      "Weighted AUCs: [0.9416969854373194, 0.9098064245307441, 0.8969096489521459]\n",
      "weighted average Recalls: 0.6849665980209956 0.6257987220447284 0.6057542768273717\n",
      "unweighted average Recalls (macro): 0.36284276293674966 0.36284276293674966 0.36284276293674966\n",
      "weighted average Precisions: 0.698693494398716 0.5893049560412654 0.5686845227803236\n",
      "unweighted average Precisions(macro): 0.6422913278347671 0.6422913278347671 0.6422913278347671\n",
      "weighted average F1s: 0.6414239744516894 0.5687035691586776 0.5407164390281236\n",
      "unweighted average F1s(macro): 0.39596070969139957 0.39596070969139957 0.39596070969139957\n",
      "Test Categorical Accuracy: 0.6057542768273717\n",
      "Epoch 27/30\n",
      "19909/19909 [==============================] - 418s 21ms/step - loss: 0.7504 - categorical_accuracy: 0.7606 - val_loss: 1.2173 - val_categorical_accuracy: 0.6386\n",
      "Weighted AUCs: [0.9565654437791378, 0.9169489371745431, 0.8961152411796652]\n",
      "weighted average Recalls: 0.7167612637500628 0.6385782747603834 0.593701399688958\n",
      "unweighted average Recalls (macro): 0.5081646939391576 0.5081646939391576 0.5081646939391576\n",
      "weighted average Precisions: 0.7477682119217035 0.6256567166428668 0.5680502015766487\n",
      "unweighted average Precisions(macro): 0.7189417248003739 0.7189417248003739 0.7189417248003739\n",
      "weighted average F1s: 0.6995954175324653 0.6099151356719416 0.55639350666074\n",
      "unweighted average F1s(macro): 0.5080400107658383 0.5080400107658383 0.5080400107658383\n",
      "Test Categorical Accuracy: 0.5937013997121324\n",
      "Epoch 28/30\n",
      "19909/19909 [==============================] - 418s 21ms/step - loss: 0.7199 - categorical_accuracy: 0.7654 - val_loss: 1.1552 - val_categorical_accuracy: 0.6773\n",
      "Weighted AUCs: [0.9716893732982744, 0.9207538425840082, 0.9031597866080381]\n",
      "weighted average Recalls: 0.7955698427846702 0.6773162939297125 0.6388024883359253\n",
      "unweighted average Recalls (macro): 0.6319932681460492 0.6319932681460492 0.6319932681460492\n",
      "weighted average Precisions: 0.7958879920066041 0.6519011534800492 0.6108905335180559\n",
      "unweighted average Precisions(macro): 0.7754106213889284 0.7754106213889284 0.7754106213889284\n",
      "weighted average F1s: 0.7868645914860455 0.6574868524045979 0.6140278955520115\n",
      "unweighted average F1s(macro): 0.6603056895786953 0.6603056895786953 0.6603056895786953\n",
      "Test Categorical Accuracy: 0.6388024883359253\n",
      "Epoch 29/30\n",
      "19909/19909 [==============================] - 418s 21ms/step - loss: 0.6824 - categorical_accuracy: 0.7759 - val_loss: 1.1748 - val_categorical_accuracy: 0.6573\n",
      "Weighted AUCs: [0.9733762410463482, 0.9173202483901269, 0.9075327838031516]\n",
      "weighted average Recalls: 0.7939625295092672 0.6573482428115016 0.6508553654743391\n",
      "unweighted average Recalls (macro): 0.5926558476157083 0.5926558476157083 0.5926558476157083\n",
      "weighted average Precisions: 0.8027977477075224 0.6510575709652078 0.6498071066171796\n",
      "unweighted average Precisions(macro): 0.8320540728896321 0.8320540728896321 0.8320540728896321\n",
      "weighted average F1s: 0.7893206939661143 0.6446204094211831 0.6381611782483108\n",
      "unweighted average F1s(macro): 0.6404339833072523 0.6404339833072523 0.6404339833072523\n",
      "Test Categorical Accuracy: 0.6508553654743391\n",
      "Epoch 30/30\n",
      "19909/19909 [==============================] - 418s 21ms/step - loss: 0.6552 - categorical_accuracy: 0.7857 - val_loss: 1.2998 - val_categorical_accuracy: 0.6334\n",
      "Weighted AUCs: [0.9679936975495703, 0.913338453438765, 0.895422841170572]\n",
      "weighted average Recalls: 0.7426289617760812 0.6333865814696485 0.6018662519440124\n",
      "unweighted average Recalls (macro): 0.5470308311077444 0.5470308311077444 0.5470308311077444\n",
      "weighted average Precisions: 0.7588823544736972 0.6389555518105391 0.5821062756483726\n",
      "unweighted average Precisions(macro): 0.6841062803398064 0.6841062803398064 0.6841062803398064\n",
      "weighted average F1s: 0.7330228997859037 0.6150551698247617 0.5734034530799295\n",
      "unweighted average F1s(macro): 0.5703516614116156 0.5703516614116156 0.5703516614116156\n",
      "Test Categorical Accuracy: 0.6018662519555996\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output  (FMA)\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 30\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape,name='main_input')\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same',name='conv_1')(input_melS)\n",
    "bn1 = BatchNormalization(name='bn_1')(conv1)\n",
    "act1 = Activation('elu',name='act_1')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same',name='pool_1')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same',name='conv_2')(pool1)\n",
    "bn2 = BatchNormalization(name='bn_2')(conv2)\n",
    "act2 = Activation('elu',name='act_2')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same',name='pool_2')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same',name='conv_3')(pool2)\n",
    "bn3 = BatchNormalization(name='bn_3')(conv3)\n",
    "act3 = Activation('elu',name='act_3')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same',name='pool_3')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same',name='conv_4')(pool3)\n",
    "bn4 = BatchNormalization(name='bn_4')(conv4)\n",
    "act4 = Activation('elu',name='act_4')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same',name='pool_4')(act4)\n",
    "\n",
    "gru1_in = Reshape((6, 128*6),name='gru1_in')(pool4)\n",
    "gru1 = GRU(32,name='gru1')(gru1_in)\n",
    "\n",
    "gru2_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)},name='gru2_in_perm')(pool4)\n",
    "gru2_in = Reshape((6, 128*6),name='gru2_in')(gru2_in_perm)\n",
    "gru2 = GRU(32,name='gru2')(gru2_in)\n",
    "\n",
    "gru3_in_perm = Lambda(K.reverse,arguments={'axes':2},name='gru3_in_perm')(pool4)\n",
    "gru3_in = Reshape((6, 128*6),name='gru3_in')(gru3_in_perm)\n",
    "gru3 = GRU(32,name='gru3')(gru3_in)\n",
    "\n",
    "gru4_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)},name='gru4_in_perm')(gru3_in_perm)\n",
    "gru4_in = Reshape((6, 128*6),name='gru4_in')(gru4_in_perm)\n",
    "gru4 = GRU(32,name='gru4')(gru4_in)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1},name='gru5_in_perm')(pool4)\n",
    "gru5_in = Reshape((6, 128*6),name='gru5_in')(gru5_in_perm)\n",
    "gru5 = GRU(32,name='gru5')(gru5_in)\n",
    "\n",
    "gru6_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)},name='gru6_in_perm')(gru5_in_perm)\n",
    "gru6_in = Reshape((6, 128*6),name='gru6_in')(gru6_in_perm)\n",
    "gru6 = GRU(32,name='gru6')(gru6_in)\n",
    "\n",
    "gru7_in_perm = Lambda(K.reverse,arguments={'axes':2},name='gru7_in_perm')(gru5_in_perm)\n",
    "gru7_in = Reshape((6, 128*6),name='gru7_in')(gru7_in_perm)\n",
    "gru7 = GRU(32,name='gru7')(gru7_in)\n",
    "\n",
    "gru8_in_perm = Lambda(K.reverse,arguments={'axes':1},name='gru8_in_perm')(gru6_in_perm)\n",
    "gru8_in = Reshape((6, 128*6),name='gru8_in')(gru8_in_perm)\n",
    "gru8 = GRU(32,name='gru8')(gru8_in)\n",
    "\n",
    "gru = Concatenate(name='gru_conc')([gru1,gru2,gru3,gru4,gru5,gru6,gru7,gru8])\n",
    "gru_dropout = Dropout(0.5,name='gru_conc_dropout')(gru)\n",
    "fc = Dense(64, activation='elu',name='fc')(gru_dropout)\n",
    "pred = Dense(16, activation='softmax',name='pred')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(),metrics=['categorical_accuracy'])\n",
    "\n",
    "filepath='C:/DT/model_save/fma/cGrnn/'+\"{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "\n",
    "path = 'C:/DT/fma_medium'\n",
    "x_train = np.load(path+'\\\\x_train.npy')\n",
    "y_train = np.load(path+'\\\\train_y.npy')\n",
    "y_train_idx = np.argmax(y_train,axis = -1)\n",
    "x_val = np.load(path+'\\\\x_val.npy')\n",
    "y_val = np.load(path+'\\\\val_y.npy')\n",
    "y_val_idx = np.argmax(y_val,axis = -1)\n",
    "x_test = np.load(path+'\\\\x_test.npy')\n",
    "y_test = np.load(path+'\\\\test_y.npy')\n",
    "y_test_idx = np.argmax(y_test,axis = -1)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,recall_score,precision_score,f1_score\n",
    "class Histories(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # all evaluation metrics include train, val, test except accs\n",
    "        self.aucs = [] # weighted AUC\n",
    "        self.recalls = [] # 16 recalls on each class and 1 mean recall\n",
    "        self.precisions = [] # 16 precisions on each class and 1 mean precision\n",
    "        self.f1s = [] # 16 f1s on each class and 1 mean f1 \n",
    "        self.accs = [] # mean accuracy without take imblance into account\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred_train = self.model.predict(x_train)\n",
    "        y_pred_val = self.model.predict(x_val)\n",
    "        y_pred_test = self.model.predict(x_test)\n",
    "        \n",
    "        y_pred_train_idx = np.argmax(y_pred_train,axis = -1)\n",
    "        y_pred_val_idx = np.argmax(y_pred_val,axis = -1)\n",
    "        y_pred_test_idx = np.argmax(y_pred_test,axis = -1)\n",
    "                \n",
    "        auc = [] #[train,val,test]\n",
    "        auc_train = roc_auc_score(y_train, y_pred_train,'weighted')\n",
    "        auc.append(auc_train)\n",
    "        auc_val = roc_auc_score(y_val, y_pred_val,'weighted')\n",
    "        auc.append(auc_val)\n",
    "        auc_test = roc_auc_score(y_test, y_pred_test,'weighted')\n",
    "        auc.append(auc_test)\n",
    "        self.aucs.append(auc)\n",
    "        print(\"Weighted AUCs:\",auc)\n",
    "        \n",
    "        recall = []\n",
    "        recall_all = recall_score(y_train_idx,y_pred_train_idx,average=None)\n",
    "        recall.append(recall_all)\n",
    "        recall_mean = recall_score(y_train_idx,y_pred_train_idx,average='weighted')\n",
    "        recall.append(recall_mean)\n",
    "        recall_mean = recall_score(y_train_idx,y_pred_train_idx,average='macro')\n",
    "        recall.append(recall_mean)\n",
    "        recall_all = recall_score(y_val_idx,y_pred_val_idx,average=None)\n",
    "        recall.append(recall_all)\n",
    "        recall_mean = recall_score(y_val_idx,y_pred_val_idx,average='weighted')\n",
    "        recall.append(recall_mean)\n",
    "        recall_mean = recall_score(y_val_idx,y_pred_val_idx,average='macro')\n",
    "        recall.append(recall_mean)\n",
    "        recall_all = recall_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        recall.append(recall_all)\n",
    "        recall_mean = recall_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        recall.append(recall_mean)\n",
    "        recall_mean = recall_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        recall.append(recall_mean)\n",
    "        self.recalls.append(recall)\n",
    "        print(\"weighted average Recalls:\",recall[1],recall[4],recall[7])\n",
    "        print(\"unweighted average Recalls (macro):\",recall[2],recall[5],recall[8])\n",
    "        \n",
    "        precision = []\n",
    "        precision_all = precision_score(y_train_idx,y_pred_train_idx,average=None)\n",
    "        precision.append(precision_all)\n",
    "        precision_mean = precision_score(y_train_idx,y_pred_train_idx,average='weighted')\n",
    "        precision.append(precision_mean)\n",
    "        precision_mean = precision_score(y_train_idx,y_pred_train_idx,average='macro')\n",
    "        precision.append(precision_mean)\n",
    "        precision_all = precision_score(y_val_idx,y_pred_val_idx,average=None)\n",
    "        precision.append(precision_all)\n",
    "        precision_mean = precision_score(y_val_idx,y_pred_val_idx,average='weighted')\n",
    "        precision.append(precision_mean)\n",
    "        precision_mean = precision_score(y_val_idx,y_pred_val_idx,average='macro')\n",
    "        precision.append(precision_mean)\n",
    "        precision_all = precision_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        precision.append(precision_all)\n",
    "        precision_mean = precision_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        precision.append(precision_mean)\n",
    "        precision_mean = precision_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        precision.append(precision_mean)\n",
    "        self.precisions.append(precision)\n",
    "        print(\"weighted average Precisions:\",precision[1],precision[4],precision[7])\n",
    "        print(\"unweighted average Precisions(macro):\",precision[2],precision[5],precision[8])\n",
    "        \n",
    "        f1 = []\n",
    "        f1_all = f1_score(y_train_idx,y_pred_train_idx,average=None)\n",
    "        f1.append(f1_all)\n",
    "        f1_mean = f1_score(y_train_idx,y_pred_train_idx,average='weighted')\n",
    "        f1.append(f1_mean)\n",
    "        f1_mean = f1_score(y_train_idx,y_pred_train_idx,average='macro')\n",
    "        f1.append(f1_mean)\n",
    "        f1_all = f1_score(y_val_idx,y_pred_val_idx,average=None)\n",
    "        f1.append(f1_all)\n",
    "        f1_mean = f1_score(y_val_idx,y_pred_val_idx,average='weighted')\n",
    "        f1.append(f1_mean)\n",
    "        f1_mean = f1_score(y_val_idx,y_pred_val_idx,average='macro')\n",
    "        f1.append(f1_mean)\n",
    "        f1_all = f1_score(y_test_idx,y_pred_test_idx,average=None)\n",
    "        f1.append(f1_all)\n",
    "        f1_mean = f1_score(y_test_idx,y_pred_test_idx,average='weighted')\n",
    "        f1.append(f1_mean)\n",
    "        f1_mean = f1_score(y_test_idx,y_pred_test_idx,average='macro')\n",
    "        f1.append(f1_mean)\n",
    "        self.f1s.append(f1)\n",
    "        print(\"weighted average F1s:\",f1[1],f1[4],f1[7])\n",
    "        print(\"unweighted average F1s(macro):\",f1[2],f1[5],f1[8])\n",
    "        \n",
    "        loss, acc = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "        self.accs.append(acc)\n",
    "        print(\"Test Categorical Accuracy:\",acc)\n",
    "        return\n",
    "\n",
    "histories = Histories()\n",
    "history = model.fit(x_train, y_train, epochs = epochs, validation_data=(x_val,y_val), callbacks=[histories,checkpoint])\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "pickle.dump(histories.aucs,open(os.path.join(path,'metrics_save/cGrnn_aucs.pkl'),'wb'))\n",
    "pickle.dump(histories.recalls,open(os.path.join(path,'metrics_save/cGrnn_recalls.pkl'),'wb'))\n",
    "pickle.dump(histories.precisions,open(os.path.join(path,'metrics_save/cGrnn_precisions.pkl'),'wb'))\n",
    "pickle.dump(histories.f1s,open(os.path.join(path,'metrics_save/cGrnn_f1s.pkl'),'wb'))\n",
    "pickle.dump(histories.accs,open(os.path.join(path,'metrics_save/cGrnn_accs.pkl'),'wb'))\n",
    "pickle.dump(history.history,open(os.path.join(path,'metrics_save/cGrnn_history.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 96, 1360, 64) 640         main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn_1 (BatchNormalization)       (None, 96, 1360, 64) 256         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_1 (Activation)              (None, 96, 1360, 64) 0           bn_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_1 (MaxPooling2D)           (None, 48, 340, 64)  0           act_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 48, 340, 128) 73856       pool_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_2 (BatchNormalization)       (None, 48, 340, 128) 512         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_2 (Activation)              (None, 48, 340, 128) 0           bn_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_2 (MaxPooling2D)           (None, 24, 85, 128)  0           act_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 24, 85, 128)  147584      pool_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_3 (BatchNormalization)       (None, 24, 85, 128)  512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_3 (Activation)              (None, 24, 85, 128)  0           bn_3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_3 (MaxPooling2D)           (None, 12, 22, 128)  0           act_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 12, 22, 128)  147584      pool_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_4 (BatchNormalization)       (None, 12, 22, 128)  512         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_4 (Activation)              (None, 12, 22, 128)  0           bn_4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_4 (MaxPooling2D)           (None, 6, 6, 128)    0           act_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru5_in_perm (Lambda)           (None, 6, 6, 128)    0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru3_in_perm (Lambda)           (None, 6, 6, 128)    0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru6_in_perm (Lambda)           (None, 6, 6, 128)    0           gru5_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru2_in_perm (Lambda)           (None, 6, 6, 128)    0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru4_in_perm (Lambda)           (None, 6, 6, 128)    0           gru3_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru7_in_perm (Lambda)           (None, 6, 6, 128)    0           gru5_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru8_in_perm (Lambda)           (None, 6, 6, 128)    0           gru6_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru1_in (Reshape)               (None, 6, 768)       0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2_in (Reshape)               (None, 6, 768)       0           gru2_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru3_in (Reshape)               (None, 6, 768)       0           gru3_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru4_in (Reshape)               (None, 6, 768)       0           gru4_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru5_in (Reshape)               (None, 6, 768)       0           gru5_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru6_in (Reshape)               (None, 6, 768)       0           gru6_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru7_in (Reshape)               (None, 6, 768)       0           gru7_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru8_in (Reshape)               (None, 6, 768)       0           gru8_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 32)           76896       gru1_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 32)           76896       gru2_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru3 (GRU)                      (None, 32)           76896       gru3_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru4 (GRU)                      (None, 32)           76896       gru4_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru5 (GRU)                      (None, 32)           76896       gru5_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru6 (GRU)                      (None, 32)           76896       gru6_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru7 (GRU)                      (None, 32)           76896       gru7_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru8 (GRU)                      (None, 32)           76896       gru8_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_conc (Concatenate)          (None, 256)          0           gru1[0][0]                       \n",
      "                                                                 gru2[0][0]                       \n",
      "                                                                 gru3[0][0]                       \n",
      "                                                                 gru4[0][0]                       \n",
      "                                                                 gru5[0][0]                       \n",
      "                                                                 gru6[0][0]                       \n",
      "                                                                 gru7[0][0]                       \n",
      "                                                                 gru8[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gru_conc_dropout (Dropout)      (None, 256)          0           gru_conc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 64)           16448       gru_conc_dropout[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pred (Dense)                    (None, 16)           1040        fc[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 1,004,112\n",
      "Trainable params: 1,003,216\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Train on 19909 samples, validate on 2504 samples\n",
      "Epoch 1/10\n",
      "19909/19909 [==============================] - 429s 22ms/step - loss: 0.1501 - acc: 0.9487 - val_loss: 0.1272 - val_acc: 0.9571\n",
      "Epoch 2/10\n",
      "19909/19909 [==============================] - 415s 21ms/step - loss: 0.1271 - acc: 0.9560 - val_loss: 0.1391 - val_acc: 0.9518\n",
      "Epoch 3/10\n",
      "19909/19909 [==============================] - 415s 21ms/step - loss: 0.1197 - acc: 0.9585 - val_loss: 0.1195 - val_acc: 0.9590\n",
      "Epoch 4/10\n",
      "19909/19909 [==============================] - 417s 21ms/step - loss: 0.1160 - acc: 0.9595 - val_loss: 0.1153 - val_acc: 0.9616\n",
      "Epoch 5/10\n",
      "19909/19909 [==============================] - 418s 21ms/step - loss: 0.1128 - acc: 0.9604 - val_loss: 0.1299 - val_acc: 0.9549\n",
      "Epoch 6/10\n",
      "19909/19909 [==============================] - 416s 21ms/step - loss: 0.1109 - acc: 0.9611 - val_loss: 0.1553 - val_acc: 0.9472\n",
      "Epoch 7/10\n",
      "19909/19909 [==============================] - 417s 21ms/step - loss: 0.1080 - acc: 0.9620 - val_loss: 0.1229 - val_acc: 0.9566\n",
      "Epoch 8/10\n",
      "19909/19909 [==============================] - 418s 21ms/step - loss: 0.1071 - acc: 0.9623 - val_loss: 0.1177 - val_acc: 0.9575\n",
      "Epoch 9/10\n",
      "19909/19909 [==============================] - 419s 21ms/step - loss: 0.1053 - acc: 0.9630 - val_loss: 0.1383 - val_acc: 0.9548\n",
      "Epoch 10/10\n",
      "19909/19909 [==============================] - 418s 21ms/step - loss: 0.1039 - acc: 0.9633 - val_loss: 0.1247 - val_acc: 0.9568\n"
     ]
    }
   ],
   "source": [
    "#  4 CNNs + GridRNN + output  (FMA)\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Activation,Concatenate,Dense,Input,Dropout,Reshape,GRU,Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 10\n",
    "input_shape = (96,1360,1)\n",
    "input_melS = Input(input_shape,name='main_input')\n",
    "\n",
    "conv1 = Conv2D(64,(3,3),padding='same',name='conv_1')(input_melS)\n",
    "bn1 = BatchNormalization(name='bn_1')(conv1)\n",
    "act1 = Activation('elu',name='act_1')(bn1)\n",
    "pool1 = MaxPooling2D((2,4),padding='same',name='pool_1')(act1)\n",
    "\n",
    "conv2 = Conv2D(128,(3,3),padding='same',name='conv_2')(pool1)\n",
    "bn2 = BatchNormalization(name='bn_2')(conv2)\n",
    "act2 = Activation('elu',name='act_2')(bn2)\n",
    "pool2 = MaxPooling2D((2,4),padding='same',name='pool_2')(act2)\n",
    "\n",
    "conv3 = Conv2D(128,(3,3),padding='same',name='conv_3')(pool2)\n",
    "bn3 = BatchNormalization(name='bn_3')(conv3)\n",
    "act3 = Activation('elu',name='act_3')(bn3)\n",
    "pool3 = MaxPooling2D((2,4),padding='same',name='pool_3')(act3)\n",
    "\n",
    "conv4 = Conv2D(128,(3,3),padding='same',name='conv_4')(pool3)\n",
    "bn4 = BatchNormalization(name='bn_4')(conv4)\n",
    "act4 = Activation('elu',name='act_4')(bn4)\n",
    "pool4 = MaxPooling2D((2,4),padding='same',name='pool_4')(act4)\n",
    "\n",
    "gru1_in = Reshape((6, 128*6),name='gru1_in')(pool4)\n",
    "gru1 = GRU(32,name='gru1')(gru1_in)\n",
    "\n",
    "gru2_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)},name='gru2_in_perm')(pool4)\n",
    "gru2_in = Reshape((6, 128*6),name='gru2_in')(gru2_in_perm)\n",
    "gru2 = GRU(32,name='gru2')(gru2_in)\n",
    "\n",
    "gru3_in_perm = Lambda(K.reverse,arguments={'axes':2},name='gru3_in_perm')(pool4)\n",
    "gru3_in = Reshape((6, 128*6),name='gru3_in')(gru3_in_perm)\n",
    "gru3 = GRU(32,name='gru3')(gru3_in)\n",
    "\n",
    "gru4_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)},name='gru4_in_perm')(gru3_in_perm)\n",
    "gru4_in = Reshape((6, 128*6),name='gru4_in')(gru4_in_perm)\n",
    "gru4 = GRU(32,name='gru4')(gru4_in)\n",
    "\n",
    "gru5_in_perm = Lambda(K.reverse,arguments={'axes':1},name='gru5_in_perm')(pool4)\n",
    "gru5_in = Reshape((6, 128*6),name='gru5_in')(gru5_in_perm)\n",
    "gru5 = GRU(32,name='gru5')(gru5_in)\n",
    "\n",
    "gru6_in_perm = Lambda(K.permute_dimensions,arguments={'pattern':(0,2,1,3)},name='gru6_in_perm')(gru5_in_perm)\n",
    "gru6_in = Reshape((6, 128*6),name='gru6_in')(gru6_in_perm)\n",
    "gru6 = GRU(32,name='gru6')(gru6_in)\n",
    "\n",
    "gru7_in_perm = Lambda(K.reverse,arguments={'axes':2},name='gru7_in_perm')(gru5_in_perm)\n",
    "gru7_in = Reshape((6, 128*6),name='gru7_in')(gru7_in_perm)\n",
    "gru7 = GRU(32,name='gru7')(gru7_in)\n",
    "\n",
    "gru8_in_perm = Lambda(K.reverse,arguments={'axes':1},name='gru8_in_perm')(gru6_in_perm)\n",
    "gru8_in = Reshape((6, 128*6),name='gru8_in')(gru8_in_perm)\n",
    "gru8 = GRU(32,name='gru8')(gru8_in)\n",
    "\n",
    "gru = Concatenate(name='gru_conc')([gru1,gru2,gru3,gru4,gru5,gru6,gru7,gru8])\n",
    "gru_dropout = Dropout(0.5,name='gru_conc_dropout')(gru)\n",
    "fc = Dense(64, activation='elu',name='fc')(gru_dropout)\n",
    "pred = Dense(16, activation='sigmoid',name='pred')(fc)\n",
    "\n",
    "model = Model(inputs = [input_melS], outputs = [pred])\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = Adam(),metrics=['acc'])\n",
    "\n",
    "filepath='C:/DT/model_save/fma/cGrnn/'+\"{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath)\n",
    "\n",
    "path = 'C:/DT/fma_medium'\n",
    "x_train = np.load(path+'\\\\x_train.npy')\n",
    "y_train = np.load(path+'\\\\train_y.npy')\n",
    "x_val = np.load(path+'\\\\x_val.npy')\n",
    "y_val = np.load(path+'\\\\val_y.npy')\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs = epochs, validation_data=(x_val,y_val), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\zwang10\\AppData\\Local\\Continuum\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 96, 1360, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 96, 1360, 64) 640         main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn_1 (BatchNormalization)       (None, 96, 1360, 64) 256         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_1 (Activation)              (None, 96, 1360, 64) 0           bn_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_1 (MaxPooling2D)           (None, 48, 340, 64)  0           act_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 48, 340, 128) 73856       pool_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_2 (BatchNormalization)       (None, 48, 340, 128) 512         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_2 (Activation)              (None, 48, 340, 128) 0           bn_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_2 (MaxPooling2D)           (None, 24, 85, 128)  0           act_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 24, 85, 128)  147584      pool_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_3 (BatchNormalization)       (None, 24, 85, 128)  512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_3 (Activation)              (None, 24, 85, 128)  0           bn_3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_3 (MaxPooling2D)           (None, 12, 22, 128)  0           act_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 12, 22, 128)  147584      pool_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn_4 (BatchNormalization)       (None, 12, 22, 128)  512         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act_4 (Activation)              (None, 12, 22, 128)  0           bn_4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "pool_4 (MaxPooling2D)           (None, 6, 6, 128)    0           act_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru5_in_perm (Lambda)           (None, 6, 6, 128)    0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru3_in_perm (Lambda)           (None, 6, 6, 128)    0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru6_in_perm (Lambda)           (None, 6, 6, 128)    0           gru5_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru2_in_perm (Lambda)           (None, 6, 6, 128)    0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru4_in_perm (Lambda)           (None, 6, 6, 128)    0           gru3_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru7_in_perm (Lambda)           (None, 6, 6, 128)    0           gru5_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru8_in_perm (Lambda)           (None, 6, 6, 128)    0           gru6_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru1_in (Reshape)               (None, 6, 768)       0           pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2_in (Reshape)               (None, 6, 768)       0           gru2_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru3_in (Reshape)               (None, 6, 768)       0           gru3_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru4_in (Reshape)               (None, 6, 768)       0           gru4_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru5_in (Reshape)               (None, 6, 768)       0           gru5_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru6_in (Reshape)               (None, 6, 768)       0           gru6_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru7_in (Reshape)               (None, 6, 768)       0           gru7_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru8_in (Reshape)               (None, 6, 768)       0           gru8_in_perm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 32)           76896       gru1_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 32)           76896       gru2_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru3 (GRU)                      (None, 32)           76896       gru3_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru4 (GRU)                      (None, 32)           76896       gru4_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru5 (GRU)                      (None, 32)           76896       gru5_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru6 (GRU)                      (None, 32)           76896       gru6_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru7 (GRU)                      (None, 32)           76896       gru7_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru8 (GRU)                      (None, 32)           76896       gru8_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_conc (Concatenate)          (None, 256)          0           gru1[0][0]                       \n",
      "                                                                 gru2[0][0]                       \n",
      "                                                                 gru3[0][0]                       \n",
      "                                                                 gru4[0][0]                       \n",
      "                                                                 gru5[0][0]                       \n",
      "                                                                 gru6[0][0]                       \n",
      "                                                                 gru7[0][0]                       \n",
      "                                                                 gru8[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "gru_conc_dropout (Dropout)      (None, 256)          0           gru_conc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 64)           16448       gru_conc_dropout[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,003,072\n",
      "Trainable params: 1,002,176\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "(2572, 64)\n"
     ]
    }
   ],
   "source": [
    "# Extracting features from last fc layer (crnn)\n",
    "# from keras.models import Model\n",
    "# import keras\n",
    "# import numpy as np\n",
    "\n",
    "# model = keras.models.load_model('C:/DT/model_save/fma/crnn/13-1.09.hdf5')\n",
    "# fc = model.get_layer('gru2').output\n",
    "\n",
    "# features = Model(inputs=model.input, outputs=fc)\n",
    "# features.summary()\n",
    "\n",
    "# path = 'C:/DT/fma_medium'\n",
    "# x_test = np.load(path+'\\\\x_test.npy')\n",
    "# feats = features.predict(x_test)\n",
    "# print(feats.shape)\n",
    "# np.save(path+'/test_feats_crnn_13',feats)\n",
    "\n",
    "# Extracting features from last fc layer (cGrnn)\n",
    "from keras.models import Model\n",
    "import keras\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "\n",
    "model = keras.models.load_model('C:/DT/model_save/fma/cGrnn/29-1.17.hdf5',custom_objects={\n",
    "                                                'tf':tensorflow})\n",
    "fc = model.get_layer('fc').output\n",
    "\n",
    "features = Model(inputs=model.input, outputs=fc)\n",
    "features.summary()\n",
    "\n",
    "path = 'C:/DT/fma_medium'\n",
    "x_test = np.load(path+'\\\\x_test.npy')\n",
    "feats = features.predict(x_test)\n",
    "print(feats.shape)\n",
    "np.save(path+'/test_feats_cGrnn_29',feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
